:::{.callout-note}
## Learning objective:

- Use tidyverse functions for exploratory data analysis;
- Introduce and explore the Pima Indians Diabetes dataset;
- Impute missing data.
:::

```{r echo=FALSE, purl=FALSE}
knitr::opts_chunk$set(
  comment = NA,
  warning = FALSE,
  message = FALSE,
  cache = TRUE
)
```


## Pima Indians Diabetes

---

Today, we are going to be working with [Pima Indian Women’s diabetes dataset](https://en.wikipedia.org/wiki/Akimel_O%27odham) which contains information on 768 Pima Indian women’s diabetes status, as well as many predictive features:

1) pregnant - Number of times pregnant
2) glucose - Plasma glucose concentration a 2 hours in an [oral glucose tolerance test](https://en.wikipedia.org/wiki/Glucose_tolerance_test)
3) pressure - Diastolic blood pressure (mm Hg)
4) triceps - Triceps skin fold thickness (mm) - [a measure correlated with body fat](https://en.wikipedia.org/wiki/Anthropometry_of_the_upper_arm)
5) insulin - 2-Hour serum insulin (mu U/ml)
6) mass - Body mass index (weight in kg/(height in m)^2)
8) age - Age (years)
9) diabetes - diabetes status (pos - diabetic; neg - non-diabetic)
10) pedigree - diabetes pedigree function

The diabetes pedigree function was developed by [Smith 1988](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/) to provide a synthesis ofthe diabetes mellitus history in relatives and the genetic relationship of those relatives to the subject. It uses information from parents, grandparents, siblings, aunts and uncles, and first cousin to provide a measure of the expected genetic influence of affected and unaffected relatives on the subject’s eventual diabetes risk.

The Pima Indians are a group of Native Americans living in an area consisting of what is now central and southern Arizona. The short name, “Pima” is believed to have come from a phrase meaning “I don’t know,” which they used repeatedly in their initial meetings with Spanish colonists. Thanks Wikipedia!

### Let's Explore our data

---

```{r libraries, message=FALSE}
library(tidyverse)
library(tidymodels)
library(ggcorrplot)
library(GGally)
library(qs)
library(mlbench)
theme_set(theme_minimal())
```

Load data:

```{r loadInTheData}
# load the Pima Indians dataset from the mlbench dataset
data(PimaIndiansDiabetes)
# rename dataset to have shorter name because lazy
diabetes_data <- PimaIndiansDiabetes
# look at the variable names
names(diabetes_data)
# look at the data
glimpse(diabetes_data)
```
Look for missing data:

```{r EDA_NA}
anyNA(diabetes_data)
```

It seems like there is no missing data.


Get a summary of the data frame:

```{r EDAsummary}
summary(diabetes_data)
```

:::{.callout-tip}
## Exercise:

Look at the output of summary above and the table that explains what each of the variables are. 
Do the values make sense for all of:
- (a) Pregnancies and Glucose
- (b) Blood pressure and Skin thickness
- (c) Insulin and DiabetesPedigreeFunction, and
- (d) BMI and Age

If not, how do you think we should deal with them?
Can you hypothesise what the consequences of this approach would be?
:::

:::{.callout-caution collapse="true"}
### Solution
```{r solution}
#Possibly missing: 

colSums(diabetes_data == 0)

#Not missing:

colSums(diabetes_data != 0)
```

It is clear that the values of several variables are zero when it is impossible for them to be so (i.e. this value could not be zero if it was measured). 
Hence, we are dealing with "hidden" missing data, and should recode it as NA.

The following variables have zero "values" that are actually likely to be missing:

1. Glucose (a)
2. BloodPressure (b)
3. SkinThickness (b)
4. Insulin (c)
5. BMI (d)
:::

### Let's use visualisation to further explore the dataset

---

```{r plotIndividual}
ggplot(diabetes_data, aes(x = pregnant, fill = diabetes)) + geom_bar(position = "dodge")
```


```{r plotAPair}
ggplot(
  diabetes_data,
  aes(
    x = pressure,
    y = glucose,
    color = diabetes
  )
) + geom_point(alpha = 0.5)
```

If we wanted to look at all possible scatterplot pairs we would do something like:
```{r PairPlot, message=F, warning=FALSE}

# make a pair plot
ggpairs(data = diabetes_data, 
        mapping = aes(color = diabetes),
        upper = list(combo = "box"))

```

But it's easier to look at a correlation plot:

```{r CorPlot}
# get a correlation matrix of the variables in the diabetes dataset:
diabetes_corr <- diabetes_data %>%
  # recode outcome to be numeric (subtract 1 to return it to zero/one)
  mutate(diabetes = as.integer(diabetes) - 1) %>%
  cor()

ggcorrplot(diabetes_corr, type = "lower", lab = TRUE )
```

Let's create a new dataframe `d_na`, which has the missing values recoded as NA:

```{r RecodeNA}
d_na <- diabetes_data %>%
  mutate(glucose = na_if(glucose, 0)) %>%
  mutate(triceps = na_if(triceps, 0)) %>%
  mutate(insulin = na_if(insulin, 0)) %>%
  mutate(mass = na_if(mass, 0)) %>%
  mutate(pressure = na_if(pressure, 0))

# approximately half of the dataset is complete, whereas half is missing data
table(complete.cases(d_na))

naniar::gg_miss_var(d_na)
visdat::vis_dat(d_na)
```

Let's compare the correlation plot from before with another one now that we've correctly labelled the missing data:

```{r CorMissing}
diabetes_corr_na <-
  d_na %>%
  # recode outcome to be numeric (subtract 1 to return it to zero/one)
  mutate(diabetes = as.integer(diabetes) - 1) %>%
  # use pairwise complete observations for the two variables
  cor(use = "pairwise.complete.obs")

ggcorrplot(diabetes_corr_na,  type = "lower",lab = TRUE)

```

Notice that the correlation between some variables (eg. pregnant - insulin) changes quite substantially. (Negative before to Positive now).

## Train-Test Split

---

We're going to split our data into 70% training and 30% testing sets.

```{r test_train_split2}
set.seed(42) # so we all get the same results

diabetes_split <- initial_split(d_na , prop = 0.7, strata = "diabetes" )
d_na_train <- training(diabetes_split)
d_na_test <- testing(diabetes_split)

qsave(d_na_train, "../_models/d_na_train.qs")
qsave(d_na_test, "../_models/d_na_test.qs")
qsave(diabetes_split, "../_models/diabetes_split.qs")
```

### Some standard checks on the test/train split

Look how many examples we have in the training and testing sets.

```{r standard_checks}
dim(d_na_train)
dim(d_na_test)
```

Plot histograms of outputs to check we stratified appropriately
```{r}
together <- bind_rows(train = d_na_train,
                      test = d_na_test,
                      .id = "test_train" ) 

together %>%
  ggplot(aes(x = diabetes))+
  geom_bar()+
  facet_grid(test_train~., scales = "free")

together %>%
  {ggduo(., 
         setdiff( names(.), c("test_train", "diabetes") ), 
         # column names not including test_train or the outcome
         "test_train")} # faceted by test_train split
```
At some point we’re going to want to do some parameter tuning (explained later), and to do that we’re going to want to use cross-validation. So we can create a cross-validated version of the training set in preparation for that moment:

```{r cross-validation}
diabetes_folds <- vfold_cv(d_na_train, v=10, repeats = 5, strata = diabetes)

qsave(diabetes_folds, "../_models/diabetes_folds.qs")
```

### Impute missing data

---

Imputation is often used to handle missing data because many statistical methods and machine learning algorithms require complete data. When we do imputation, we aren’t adding new information to our dataset, but we are using the patterns in our dataset so that we don’t have to throw away the data that have some variables missing. 
We can impute the missing data using a recipe:

```{r impute_recipe}
# set seed to be 42 so everyone gets the same results
set.seed(42)
diabetes_rec <-
  d_na_train %>%
  recipe(diabetes ~ .) %>%
  # all our predictors are numeric so standardize them
  step_normalize(all_numeric_predictors()) %>%
  step_impute_median(all_predictors())

diabetes_rec  

qsave(diabetes_rec, "../_models/diabetes_rec.qs")
```

:::{.callout-note}
### Key Points

- Classification attempts to predict the class to which a particular observation belongs;
- There are many different metrics for assessing performance for a classification problem;
- Which metric you choose and optimise for should be considered carefully, and will be different depending on the problem;
- Exporatory data analysis is a time consuming but critical process that needs to be carried out prior to any modeling.
:::
