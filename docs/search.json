[
  {
    "objectID": "400_analysis/step1.html",
    "href": "400_analysis/step1.html",
    "title": "New SIH project",
    "section": "",
    "text": "This is step 1"
  },
  {
    "objectID": "400_analysis/step1.html#quarto",
    "href": "400_analysis/step1.html#quarto",
    "title": "New SIH project",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "400_analysis/step1.html#running-code",
    "href": "400_analysis/step1.html#running-code",
    "title": "New SIH project",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\nCode\nlibrary(ggplot2)\nggplot(data = mtcars, \n       aes(x = mpg, y = hp, \n           col = as.factor(cyl))) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\nCode\n2 * 2\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "400_analysis/step2.html",
    "href": "400_analysis/step2.html",
    "title": "New SIH project",
    "section": "",
    "text": "This is step 2"
  },
  {
    "objectID": "400_analysis/step2.html#quarto",
    "href": "400_analysis/step2.html#quarto",
    "title": "New SIH project",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "400_analysis/step2.html#running-code",
    "href": "400_analysis/step2.html#running-code",
    "title": "New SIH project",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\nCode\nlibrary(ggplot2)\nggplot(data = mtcars, \n       aes(x = mpg, y = hp, \n           col = as.factor(cyl))) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\nCode\n2 * 2\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine learning with R and the tidyverse",
    "section": "",
    "text": "This is the landing page for the Sydney Informatics Hub’s “Machine learning with R and the tidyverse”."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "The Sydney Informatics Hub is a Core Research Facility of the University of Sydney.\nThe use of the SIH services including the Artemis HPC and associated support and training warrants acknowledgement in any publications, conference proceedings or posters describing work facilitated by these services.\nThe continued acknowledgement of the use of SIH facilities ensures the sustainability of our services."
  },
  {
    "objectID": "about.html#suggested-wording",
    "href": "about.html#suggested-wording",
    "title": "Sydney Informatics Hub",
    "section": "Suggested wording",
    "text": "Suggested wording\n\nGeneral acknowledgement:\nThe authors acknowledge the technical assistance provided by the Sydney Informatics Hub, a Core Research Facility of the University of Sydney.\n\n\nAcknowledging specific staff:\nThe authors acknowledge the technical assistance of (name of staff) of the Sydney Informatics Hub, a Core Research Facility of the University of Sydney.\nFor further information about acknowledging the Sydney Informatics Hub, please contact us at sih.info@sydney.edu.au."
  },
  {
    "objectID": "100_data_cleaning_scripts_EDA/step1.html",
    "href": "100_data_cleaning_scripts_EDA/step1.html",
    "title": "New SIH project",
    "section": "",
    "text": "This is step 1"
  },
  {
    "objectID": "100_data_cleaning_scripts_EDA/step1.html#quarto",
    "href": "100_data_cleaning_scripts_EDA/step1.html#quarto",
    "title": "New SIH project",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "100_data_cleaning_scripts_EDA/step1.html#running-code",
    "href": "100_data_cleaning_scripts_EDA/step1.html#running-code",
    "title": "New SIH project",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\nCode\nlibrary(ggplot2)\nggplot(data = mtcars, \n       aes(x = mpg, y = hp, \n           col = as.factor(cyl))) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\nCode\n2 * 2\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "100_data_cleaning_scripts_EDA/step2.html",
    "href": "100_data_cleaning_scripts_EDA/step2.html",
    "title": "New SIH project",
    "section": "",
    "text": "This is step 2"
  },
  {
    "objectID": "100_data_cleaning_scripts_EDA/step2.html#quarto",
    "href": "100_data_cleaning_scripts_EDA/step2.html#quarto",
    "title": "New SIH project",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "100_data_cleaning_scripts_EDA/step2.html#running-code",
    "href": "100_data_cleaning_scripts_EDA/step2.html#running-code",
    "title": "New SIH project",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\nCode\nlibrary(ggplot2)\nggplot(data = mtcars, \n       aes(x = mpg, y = hp, \n           col = as.factor(cyl))) + \n  geom_point() + \n  theme_minimal()\n\n\n\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\nCode\n2 * 2\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "000_scoping/scoping.html",
    "href": "000_scoping/scoping.html",
    "title": "PIPE-XXX: PROJECT TITLE",
    "section": "",
    "text": "Clients: X, Y, Z\nFaculty: X\nSchool: ?\nResearch centre: ?\nCollaborators and their affilications: ?"
  },
  {
    "objectID": "000_scoping/scoping.html#project-scoping-details",
    "href": "000_scoping/scoping.html#project-scoping-details",
    "title": "PIPE-XXX: PROJECT TITLE",
    "section": "Project scoping details",
    "text": "Project scoping details\n\nScope prepared by X\nScope prepared on\nProject manager\n\n\nResearcher Availability\n\nWho is the active person helping?\nHow available are they to participate in this study?"
  },
  {
    "objectID": "000_scoping/scoping.html#project-summary",
    "href": "000_scoping/scoping.html#project-summary",
    "title": "PIPE-XXX: PROJECT TITLE",
    "section": "2. Project summary",
    "text": "2. Project summary\n\nResearch context\nThis research aims to:\n\nX\nB\n\n\n\nClient needs\n\nA\nB\nC\n\n\n\nCurrent data\n\nX"
  },
  {
    "objectID": "000_scoping/scoping.html#project-implementation",
    "href": "000_scoping/scoping.html#project-implementation",
    "title": "PIPE-XXX: PROJECT TITLE",
    "section": "3. Project Implementation",
    "text": "3. Project Implementation\n\nProject plan\n\nWhat needs to be done?\nWhat’s the timeline for each step?\n\n\n\nScheduling\n\nAny notes?\n\n\n\nDeliverables\n\nA\nB\nC\n\n\n\nSIH skills required\n\nPython/R/SQL?\nXXX\nyyyy\n\n\n\nIn scope\n\n\nOut of scope\n\nMore than X weeks FTE work\n\n\n\nAcceptance Criteria\n\nx\n\n\n\nHandover plan\n\nX"
  },
  {
    "objectID": "000_scoping/scoping.html#project-evaluation",
    "href": "000_scoping/scoping.html#project-evaluation",
    "title": "PIPE-XXX: PROJECT TITLE",
    "section": "4. Project Evaluation",
    "text": "4. Project Evaluation\n\nSIH Benefits (Summary)\n\nX/\n\n\n\nCost (FTE weeks)\n\nX weeks FTE\n\n\nSIH staff will fill out the below"
  },
  {
    "objectID": "000_scoping/scoping.html#essential-criteria",
    "href": "000_scoping/scoping.html#essential-criteria",
    "title": "PIPE-XXX: PROJECT TITLE",
    "section": "5. Essential criteria",
    "text": "5. Essential criteria\n\n\n\nSydney Researcher\nY:\n\n\nClear project statement\nY\n\n\nData quality\nY\n\n\nSolvable\nY\n\n\nDomain Expert\nY\n\n\nPlanned\nY\n\n\nStrategic Plan\nY\n\n\nData Science\nY\n\n\nPriority\nY: Health\n\n\nDeliverables\nY\n\n\nInfrastructure\nY"
  },
  {
    "objectID": "000_scoping/scoping.html#value-and-impact",
    "href": "000_scoping/scoping.html#value-and-impact",
    "title": "PIPE-XXX: PROJECT TITLE",
    "section": "6. Value and Impact",
    "text": "6. Value and Impact\n\nDrives the success of larger groups, larger collaborations or high-profile projects.\n\nScore: X/10\nDetails:\n\nName of Research Group/Centre:\nName of Collaboration:\n\n\n\n\nPublications that are high-impact - foundational, highly cited, with potential for wider adoption of methods and knock-on outcomes.\n\nScore: X/10\n\n\nTarget Journal: Nature (Impact Factor 40000)\n\n\nName of Authors: Amazing researcher, (name of SIH data analyst?)\nProposed Paper Title: How to write a Science paper in 5 days.\n\n\n\nPotential for patents, start-ups, open-source code, policy influence.\n\nPolicy influence X/10\n\n\n\nDevelop funding opportunities for the university and/or SIH, such as large CoE-scale grants and further involvement with successful and well funded groups.\n\nScore: X/10\nName of Grant Application:\nDate of Proposed Submission:\n\n\n\nTotal score\nX/40 (refer to Rubric for scoring guide)"
  },
  {
    "objectID": "000_scoping/scoping.html#kpi",
    "href": "000_scoping/scoping.html#kpi",
    "title": "PIPE-XXX: PROJECT TITLE",
    "section": "7. KPI",
    "text": "7. KPI\n\n\n\nPapers SIH Coauthors (*measure only, not KPI)\nN\n\n\nNumber of Papers: Papers SIH Acknowledged\nY - Number of Papers: 1000\n\n\nCollaborators who publish\nName: Amazing Researcher\n\n\nCollaborators who have grants\nName: Amazing Researcher\n\n\nGrant applications created\nY:\n\n\nGrants project supporting\nName of Grant:\n\n\nSoftware released for public use\nY/N: TBA\n\n\nNew Clients\nY\n\n\nKPI Score\n?/6"
  },
  {
    "objectID": "100_dataset1/step1.html",
    "href": "100_dataset1/step1.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\nUse tidyverse functions for exploratory data analysis;\nIntroduce and explore the Ames Housing dataset.\nFirst, let’s load the required packages. We will use the tidyverse for general data processing and visualisation.\nWe will use the Ames housing data to explore different ML approaches to regression. This dataset was “designed” by Dean De Cock as an alternative to the “classic” Boston housing dataset, and has been extensively used in ML teaching. It is also available from kaggle as part of its advanced regression practice competition.\nThe Ames Housing Data Documentation file describes the independent variables presented in the data. This includes:\nWe will explore both the “uncleaned” data available from kaggle/UCI, and the processed data available in the AmesHousing package in R, for which documentation is available here. It can be useful for understanding what each of the independent variables mean."
  },
  {
    "objectID": "100_dataset1/step1.html#quarto",
    "href": "100_dataset1/step1.html#quarto",
    "title": "Sydney Informatics Hub",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "100_dataset1/step1.html#running-code",
    "href": "100_dataset1/step1.html#running-code",
    "title": "Sydney Informatics Hub",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nlibrary(ggplot2)\nggplot(data = mtcars, \n       aes(x = mpg, y = hp, \n           col = as.factor(cyl))) + \n  geom_point() + \n  theme_minimal()\n\n\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n2 * 2\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "100_dataset1/step2.html",
    "href": "100_dataset1/step2.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\nFrom base R to tidymodels;\nSplit our data into training and test sets;\nPreprocess the training data;\nSpecify a linear regression model;\nTrain our model on the training data;\nTransform the test data and obtain predictions using our trained model.\nLoad in the packages we’ll be using for modelling:"
  },
  {
    "objectID": "100_dataset1/step2.html#quarto",
    "href": "100_dataset1/step2.html#quarto",
    "title": "Sydney Informatics Hub",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "100_dataset1/step2.html#running-code",
    "href": "100_dataset1/step2.html#running-code",
    "title": "Sydney Informatics Hub",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nlibrary(ggplot2)\nggplot(data = mtcars, \n       aes(x = mpg, y = hp, \n           col = as.factor(cyl))) + \n  geom_point() + \n  theme_minimal()\n\n\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n2 * 2\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "400_dataset4/step1.html",
    "href": "400_dataset4/step1.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Predict whether a cancer is malignant or benign from biopsy details\n\n\n\n\n\n\nExercise:\n\n\n\nThis dataset, called the Breast Cancer Wisconsin (Diagnostic) Data Set, includes features computed from digitized images of biopsies. If you want to predict whether a cancer is malignant or benign from biopsies details, which model can you build?\n\n\nLoad the libraries:\n\nlibrary(RCurl)\n\nLoad the data:\n\n#load the data into a tibble using the RCurl package\nUCI_data_URL <- getURL('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data') \n\n#create a list with the appropriate column names \nnames <- c('id_number', 'diagnosis', 'radius_mean', \n         'texture_mean', 'perimeter_mean', 'area_mean', \n         'smoothness_mean', 'compactness_mean', \n         'concavity_mean','concave_points_mean', \n         'symmetry_mean', 'fractal_dimension_mean',\n         'radius_se', 'texture_se', 'perimeter_se', \n         'area_se', 'smoothness_se', 'compactness_se', \n         'concavity_se', 'concave_points_se', \n         'symmetry_se', 'fractal_dimension_se', \n         'radius_worst', 'texture_worst', \n         'perimeter_worst', 'area_worst', \n         'smoothness_worst', 'compactness_worst', \n         'concavity_worst', 'concave_points_worst', \n         'symmetry_worst', 'fractal_dimension_worst') \n\n#load the column names into a data frame and set the column names\nbreast_cancer <- read.table(textConnection(UCI_data_URL), sep = ',', col.names = names) \n\n#discard id_number column\nbreast_cancer$id_number <- NULL"
  },
  {
    "objectID": "400_dataset4/step1.html#quarto",
    "href": "400_dataset4/step1.html#quarto",
    "title": "Sydney Informatics Hub Machine Learning with R and tidymodels",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "400_dataset4/step1.html#running-code",
    "href": "400_dataset4/step1.html#running-code",
    "title": "Sydney Informatics Hub Machine Learning with R and tidymodels",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nCodelibrary(ggplot2)\nggplot(data = mtcars, \n       aes(x = mpg, y = hp, \n           col = as.factor(cyl))) + \n  geom_point() + \n  theme_minimal()\n\n\n\nCode1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\nCode2 * 2\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "400_dataset4/step2.html",
    "href": "400_dataset4/step2.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:"
  },
  {
    "objectID": "400_dataset4/step2.html#quarto",
    "href": "400_dataset4/step2.html#quarto",
    "title": "Sydney Informatics Hub Machine Learning with R and tidymodels",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "400_dataset4/step2.html#running-code",
    "href": "400_dataset4/step2.html#running-code",
    "title": "Sydney Informatics Hub Machine Learning with R and tidymodels",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nCodelibrary(ggplot2)\nggplot(data = mtcars, \n       aes(x = mpg, y = hp, \n           col = as.factor(cyl))) + \n  geom_point() + \n  theme_minimal()\n\n\n\nCode1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\nCode2 * 2\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Machine learning with R and the tidyverse",
    "section": "Schedule",
    "text": "Schedule\nThis course is designed to be delivered either as 2 day face-to-face workshop or as four half day sessions delivered online.\n\n\n\nDay 1\n\n\n\nMorning\nIntroduction to machine learning\n\n\n\nExploratory data analysis (EDA) - Regression\n\n\nAfternoon\nGet started with tidymodels and workflows\n\n\nDay 2\n\n\n\nMorning\nEDA - Classification\n\n\nAfternoon\nTuning hyperparameters and compare multiple model workflows\n\n\n\n\n\n\n\n\n\nPrerequisites\n\n\n\n\nThis course assumes intermediate R knowledge. This workshop is for you if:\n\nYou can use the magrittr pipe %>%;\nYou are familiar with functions from dplyr, tidyr, and ggplot2;\nYou can read data into R, transform and reshape data, and make a wide variety of graphs.\n\nWe expect participants to have some exposure to basic statistical concepts, but NOT intermediate or expert familiarity with modeling or machine learning;\nYou need your own laptop with R and a few key packages installed. See setup instructions for more details."
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "",
    "text": "Learning objectives\n\n\n\n\nUnderstand what Machine Learning (ML) is;\nUnderstand which modeling approaches to use for different kinds of data;\nUnderstand how Tidymodels can help build and evaluate ML models."
  },
  {
    "objectID": "00_setup.html",
    "href": "00_setup.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Question\n\n\n\n\nWhat packages do I need to install in order to attend the SIH’s Machine Learning with R course?"
  },
  {
    "objectID": "00_setup.html#installation-instructions",
    "href": "00_setup.html#installation-instructions",
    "title": "Sydney Informatics Hub",
    "section": "Installation instructions",
    "text": "Installation instructions\n\nif (getRversion() < 3.6){\n  stop(\"You need R >= 3.6 to attend the workshop. Please update R!\")\n}\n\nlist_of_pkgs <- c(\n  \"AmesHousing\",\n  \"tidyverse\",\n  \"tidymodels\",\n  \"doParallel\",\n  \"vip\",\n  \"ggcorrplot\",\n  \"naniar\",\n  \"parallelly\",\n  \"GGally\",\n  \"mlbench\",\n  \"usemodels\")\n\nau_repo <- \"https://mirror.aarnet.edu.au/pub/CRAN/\"\n\n#install installr and rtools if windows\nif (.Platform$OS.type == \"windows\"){\n  install.packages(c(\"installr\"), repos = au_repo)\n  installr::install.Rtools(choose_version = F,\n                           check = T,\n                           GUI = T)\n  win_only <- c(\"installr\")\n} else {\n  win_only <- c()\n}\n\n# run the following line of code to install the packages you currently do not have\nnew_pkgs <- list_of_pkgs[!(list_of_pkgs %in% installed.packages()[,\"Package\"])]\nif(length(new_pkgs)) install.packages(new_pkgs,repos = au_repo)\n\n# install helper function to plot metrics\nlist_of_pkgs <- c(list_of_pkgs,\n                  win_only)\n\n#check everything is installed and write out an error message if it ain't.\nmissing_pkg <- list_of_pkgs[!(list_of_pkgs %in% installed.packages()[,\"Package\"])]\nif(length(missing_pkg)) {\n  print(\"=======================================================\")\n  print(\"Packages which didn't install properly:\")\n  print(missing_pkg)\n  print(\"Try to install them again or ask a helper for assistance.\")\n  print(\"=======================================================\")\n} else {\n  print(\"=======================================================\")\n  print(\"All packages installed properly! :)\")\n  print(\"=======================================================\")\n}\n\n[1] \"=======================================================\"\n[1] \"All packages installed properly! :)\"\n[1] \"=======================================================\"\n\n\n\n\n\n\n\n\nTo do before the workshop begins\n\n\n\n\nPlease join the workshop with a computer that has the following installed (all available for free):\n\nA recent version of R, available at https://cran.r-project.org/;\nA recent version of RStudio Desktop (RStudio Desktop Open Source License, at least v2022.02), available at https://www.rstudio.com/download;\n\n\nPlease copy and paste the code above in your Rstudio, run it and if there are any errors please let us know via email (sih.training@sydney.edu.au) BEFORE the workshop begins"
  },
  {
    "objectID": "300_dataset3/step1.html",
    "href": "300_dataset3/step1.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Predict which wine features are the best quality wine indicators\n\n\n\n\n\n\nExercise:\n\n\n\nThe Wine Quality dataset contains information about various chemical properties of different wines, including their acidity, residual sugar, and alcohol content. This dataset can be used to build a model to predict which features are the best quality red wine indicators. What kind of model will you build?\n\n\nLoad the libraries:\n\nlibrary(readr)\n\nLoad the data:\n\nlibrary(readr)\nwine_data <- read_delim(\"../datasets/winequality-red.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "200_dataset2/step1.html",
    "href": "200_dataset2/step1.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\nUse tidyverse functions for exploratory data analysis;\nIntroduce and explore the Pima Indians Diabetes dataset;\nImpute missing data."
  },
  {
    "objectID": "200_dataset2/step2.html",
    "href": "200_dataset2/step2.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\nBuild a ML model for predicting whether a person has diabetes or not;"
  },
  {
    "objectID": "300_dataset3/step2.html",
    "href": "300_dataset3/step2.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\ntune model hyperparameters;\nworkflow();"
  },
  {
    "objectID": "100_dataset1/step1.html#exploratory-data-analysis",
    "href": "100_dataset1/step1.html#exploratory-data-analysis",
    "title": "Sydney Informatics Hub",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nExploratory data analysis involves looking at:\n\nThe distribution of variables in your dataset;\nWhether any data is missing;\nData skewness;\nCorrelated variables.\n\n\n\n\n\n\n\nChallenge 1\n\n\n\n\nExplore the Ames Housing dataset.\n\nWhat can you figure out about the different variables?\nWhich do you think are more or less important?\n\n\nCompare the ameshousing variable, which is from the AmesHousing package in R and has been cleaned, with the ameshousing_uncleaned dataset, which is the raw data from the UCI machine learning repository.\n\nWhat was missing in the raw data?\nWhat are some of the approaches that have been taken to deal with missingness?\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can see that the “uncleaned” dataset has a lot of missing data, whereas it has been cleaned up for us in the “cleaned” one. In the interests of time, we will not focus here on how every variable in that dataset has been explored and cleaned up - however, it presents a good example of “messy” real-world data, so we would encourage you to try and look at a handful of variables at home, to see how they’ve been processed.\n\ndim(ameshousing)\n\n[1] 2930   81\n\nglimpse(ameshousing)\n\nRows: 2,930\nColumns: 81\n$ MS_SubClass        <fct> One_Story_1946_and_Newer_All_Styles, One_Story_1946…\n$ MS_Zoning          <fct> Residential_Low_Density, Residential_High_Density, …\n$ Lot_Frontage       <dbl> 141, 80, 81, 93, 74, 78, 41, 43, 39, 60, 75, 0, 63,…\n$ Lot_Area           <int> 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005…\n$ Street             <fct> Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pav…\n$ Alley              <fct> No_Alley_Access, No_Alley_Access, No_Alley_Access, …\n$ Lot_Shape          <fct> Slightly_Irregular, Regular, Slightly_Irregular, Re…\n$ Land_Contour       <fct> Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, HLS, Lvl, Lvl, L…\n$ Utilities          <fct> AllPub, AllPub, AllPub, AllPub, AllPub, AllPub, All…\n$ Lot_Config         <fct> Corner, Inside, Corner, Corner, Inside, Inside, Ins…\n$ Land_Slope         <fct> Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, G…\n$ Neighborhood       <fct> North_Ames, North_Ames, North_Ames, North_Ames, Gil…\n$ Condition_1        <fct> Norm, Feedr, Norm, Norm, Norm, Norm, Norm, Norm, No…\n$ Condition_2        <fct> Norm, Norm, Norm, Norm, Norm, Norm, Norm, Norm, Nor…\n$ Bldg_Type          <fct> OneFam, OneFam, OneFam, OneFam, OneFam, OneFam, Twn…\n$ House_Style        <fct> One_Story, One_Story, One_Story, One_Story, Two_Sto…\n$ Overall_Qual       <fct> Above_Average, Average, Above_Average, Good, Averag…\n$ Overall_Cond       <fct> Average, Above_Average, Above_Average, Average, Ave…\n$ Year_Built         <int> 1960, 1961, 1958, 1968, 1997, 1998, 2001, 1992, 199…\n$ Year_Remod_Add     <int> 1960, 1961, 1958, 1968, 1998, 1998, 2001, 1992, 199…\n$ Roof_Style         <fct> Hip, Gable, Hip, Hip, Gable, Gable, Gable, Gable, G…\n$ Roof_Matl          <fct> CompShg, CompShg, CompShg, CompShg, CompShg, CompSh…\n$ Exterior_1st       <fct> BrkFace, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Exterior_2nd       <fct> Plywood, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Mas_Vnr_Type       <fct> Stone, None, BrkFace, None, None, BrkFace, None, No…\n$ Mas_Vnr_Area       <dbl> 112, 0, 108, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6…\n$ Exter_Qual         <fct> Typical, Typical, Typical, Good, Typical, Typical, …\n$ Exter_Cond         <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Foundation         <fct> CBlock, CBlock, CBlock, CBlock, PConc, PConc, PConc…\n$ Bsmt_Qual          <fct> Typical, Typical, Typical, Typical, Good, Typical, …\n$ Bsmt_Cond          <fct> Good, Typical, Typical, Typical, Typical, Typical, …\n$ Bsmt_Exposure      <fct> Gd, No, No, No, No, No, Mn, No, No, No, No, No, No,…\n$ BsmtFin_Type_1     <fct> BLQ, Rec, ALQ, ALQ, GLQ, GLQ, GLQ, ALQ, GLQ, Unf, U…\n$ BsmtFin_SF_1       <dbl> 2, 6, 1, 1, 3, 3, 3, 1, 3, 7, 7, 1, 7, 3, 3, 1, 3, …\n$ BsmtFin_Type_2     <fct> Unf, LwQ, Unf, Unf, Unf, Unf, Unf, Unf, Unf, Unf, U…\n$ BsmtFin_SF_2       <dbl> 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1120, 0…\n$ Bsmt_Unf_SF        <dbl> 441, 270, 406, 1045, 137, 324, 722, 1017, 415, 994,…\n$ Total_Bsmt_SF      <dbl> 1080, 882, 1329, 2110, 928, 926, 1338, 1280, 1595, …\n$ Heating            <fct> GasA, GasA, GasA, GasA, GasA, GasA, GasA, GasA, Gas…\n$ Heating_QC         <fct> Fair, Typical, Typical, Excellent, Good, Excellent,…\n$ Central_Air        <fct> Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, …\n$ Electrical         <fct> SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SB…\n$ First_Flr_SF       <int> 1656, 896, 1329, 2110, 928, 926, 1338, 1280, 1616, …\n$ Second_Flr_SF      <int> 0, 0, 0, 0, 701, 678, 0, 0, 0, 776, 892, 0, 676, 0,…\n$ Low_Qual_Fin_SF    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Gr_Liv_Area        <int> 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616…\n$ Bsmt_Full_Bath     <dbl> 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, …\n$ Bsmt_Half_Bath     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Full_Bath          <int> 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, …\n$ Half_Bath          <int> 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ Bedroom_AbvGr      <int> 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 1, 4, 4, …\n$ Kitchen_AbvGr      <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Kitchen_Qual       <fct> Typical, Typical, Good, Excellent, Typical, Good, G…\n$ TotRms_AbvGrd      <int> 7, 5, 6, 8, 6, 7, 6, 5, 5, 7, 7, 6, 7, 5, 4, 12, 8,…\n$ Functional         <fct> Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, T…\n$ Fireplaces         <int> 2, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, …\n$ Fireplace_Qu       <fct> Good, No_Fireplace, No_Fireplace, Typical, Typical,…\n$ Garage_Type        <fct> Attchd, Attchd, Attchd, Attchd, Attchd, Attchd, Att…\n$ Garage_Finish      <fct> Fin, Unf, Unf, Fin, Fin, Fin, Fin, RFn, RFn, Fin, F…\n$ Garage_Cars        <dbl> 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, …\n$ Garage_Area        <dbl> 528, 730, 312, 522, 482, 470, 582, 506, 608, 442, 4…\n$ Garage_Qual        <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Garage_Cond        <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Paved_Drive        <fct> Partial_Pavement, Paved, Paved, Paved, Paved, Paved…\n$ Wood_Deck_SF       <int> 210, 140, 393, 0, 212, 360, 0, 0, 237, 140, 157, 48…\n$ Open_Porch_SF      <int> 62, 0, 36, 0, 34, 36, 0, 82, 152, 60, 84, 21, 75, 0…\n$ Enclosed_Porch     <int> 0, 0, 0, 0, 0, 0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Three_season_porch <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Screen_Porch       <int> 0, 120, 0, 0, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 140, …\n$ Pool_Area          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Pool_QC            <fct> No_Pool, No_Pool, No_Pool, No_Pool, No_Pool, No_Poo…\n$ Fence              <fct> No_Fence, Minimum_Privacy, No_Fence, No_Fence, Mini…\n$ Misc_Feature       <fct> None, None, Gar2, None, None, None, None, None, Non…\n$ Misc_Val           <int> 0, 0, 12500, 0, 0, 0, 0, 0, 0, 0, 0, 500, 0, 0, 0, …\n$ Mo_Sold            <int> 5, 6, 6, 4, 3, 6, 4, 1, 3, 6, 4, 3, 5, 2, 6, 6, 6, …\n$ Year_Sold          <int> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 201…\n$ Sale_Type          <fct> WD , WD , WD , WD , WD , WD , WD , WD , WD , WD , W…\n$ Sale_Condition     <fct> Normal, Normal, Normal, Normal, Normal, Normal, Nor…\n$ Sale_Price         <int> 215000, 105000, 172000, 244000, 189900, 195500, 213…\n$ Longitude          <dbl> -93.61975, -93.61976, -93.61939, -93.61732, -93.638…\n$ Latitude           <dbl> 42.05403, 42.05301, 42.05266, 42.05125, 42.06090, 4…\n\ncolSums(is.na(ameshousing_uncleaned))\n\n          Order             PID     MS SubClass       MS Zoning    Lot Frontage \n              0               0               0               0             490 \n       Lot Area          Street           Alley       Lot Shape    Land Contour \n              0               0            2732               0               0 \n      Utilities      Lot Config      Land Slope    Neighborhood     Condition 1 \n              0               0               0               0               0 \n    Condition 2       Bldg Type     House Style    Overall Qual    Overall Cond \n              0               0               0               0               0 \n     Year Built  Year Remod/Add      Roof Style       Roof Matl    Exterior 1st \n              0               0               0               0               0 \n   Exterior 2nd    Mas Vnr Type    Mas Vnr Area      Exter Qual      Exter Cond \n              0              23              23               0               0 \n     Foundation       Bsmt Qual       Bsmt Cond   Bsmt Exposure  BsmtFin Type 1 \n              0              80              80              83              80 \n   BsmtFin SF 1  BsmtFin Type 2    BsmtFin SF 2     Bsmt Unf SF   Total Bsmt SF \n              1              81               1               1               1 \n        Heating      Heating QC     Central Air      Electrical      1st Flr SF \n              0               0               0               1               0 \n     2nd Flr SF Low Qual Fin SF     Gr Liv Area  Bsmt Full Bath  Bsmt Half Bath \n              0               0               0               2               2 \n      Full Bath       Half Bath   Bedroom AbvGr   Kitchen AbvGr    Kitchen Qual \n              0               0               0               0               0 \n  TotRms AbvGrd      Functional      Fireplaces    Fireplace Qu     Garage Type \n              0               0               0            1422             157 \n  Garage Yr Blt   Garage Finish     Garage Cars     Garage Area     Garage Qual \n            159             159               1               1             159 \n    Garage Cond     Paved Drive    Wood Deck SF   Open Porch SF  Enclosed Porch \n            159               0               0               0               0 \n     3Ssn Porch    Screen Porch       Pool Area         Pool QC           Fence \n              0               0               0            2917            2358 \n   Misc Feature        Misc Val         Mo Sold         Yr Sold       Sale Type \n           2824               0               0               0               0 \n Sale Condition       SalePrice \n              0               0 \n\ncolSums(is.na(ameshousing))\n\n       MS_SubClass          MS_Zoning       Lot_Frontage           Lot_Area \n                 0                  0                  0                  0 \n            Street              Alley          Lot_Shape       Land_Contour \n                 0                  0                  0                  0 \n         Utilities         Lot_Config         Land_Slope       Neighborhood \n                 0                  0                  0                  0 \n       Condition_1        Condition_2          Bldg_Type        House_Style \n                 0                  0                  0                  0 \n      Overall_Qual       Overall_Cond         Year_Built     Year_Remod_Add \n                 0                  0                  0                  0 \n        Roof_Style          Roof_Matl       Exterior_1st       Exterior_2nd \n                 0                  0                  0                  0 \n      Mas_Vnr_Type       Mas_Vnr_Area         Exter_Qual         Exter_Cond \n                 0                  0                  0                  0 \n        Foundation          Bsmt_Qual          Bsmt_Cond      Bsmt_Exposure \n                 0                  0                  0                  0 \n    BsmtFin_Type_1       BsmtFin_SF_1     BsmtFin_Type_2       BsmtFin_SF_2 \n                 0                  0                  0                  0 \n       Bsmt_Unf_SF      Total_Bsmt_SF            Heating         Heating_QC \n                 0                  0                  0                  0 \n       Central_Air         Electrical       First_Flr_SF      Second_Flr_SF \n                 0                  0                  0                  0 \n   Low_Qual_Fin_SF        Gr_Liv_Area     Bsmt_Full_Bath     Bsmt_Half_Bath \n                 0                  0                  0                  0 \n         Full_Bath          Half_Bath      Bedroom_AbvGr      Kitchen_AbvGr \n                 0                  0                  0                  0 \n      Kitchen_Qual      TotRms_AbvGrd         Functional         Fireplaces \n                 0                  0                  0                  0 \n      Fireplace_Qu        Garage_Type      Garage_Finish        Garage_Cars \n                 0                  0                  0                  0 \n       Garage_Area        Garage_Qual        Garage_Cond        Paved_Drive \n                 0                  0                  0                  0 \n      Wood_Deck_SF      Open_Porch_SF     Enclosed_Porch Three_season_porch \n                 0                  0                  0                  0 \n      Screen_Porch          Pool_Area            Pool_QC              Fence \n                 0                  0                  0                  0 \n      Misc_Feature           Misc_Val            Mo_Sold          Year_Sold \n                 0                  0                  0                  0 \n         Sale_Type     Sale_Condition         Sale_Price          Longitude \n                 0                  0                  0                  0 \n          Latitude \n                 0 \n\n\n\n\n\nVisualise missingness\n\nWhen working with missing data, it can be helpful to look for “co-missingness”, i.e. multiple variables missing together. For example, when working with patient data, number of pregnancies, age at onset of menstruation and menopause may all be missing - which, when observed together, may indicate that these samples come from male patients for whom this data is irrelevant. “Gender” may or may not be a variable coded in the dataset.\nA way of visualising missing data in the tidy context has been proposed @tierney2018expanding. See this web page for more options for your own data.\nLet’s look at the missing variables in our housing data:\n\ngg_miss_var(ameshousing_uncleaned)\n\n\n\n\nWe can see that the most missingness is observed in the Pool_QC, Misc_Feature, Alley, Fence and Fireplace_QC variables. This is most likely due to many houses not having pools, alleys, fences, and fireplaces, and not having any features that the real estate agent considers to be notable enough to be added to the “miscellaneous” category.\nAn upset plot will give us more idea about the co-missingness of these variables:\n\ngg_miss_upset(ameshousing_uncleaned, nsets = 10)\n\n\n\n\n\n\n\n\n\n\nChallenge 2\n\n\n\n\nWhich variables are most frequently missing together?\nDoes this “co-missingness” make sense?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nFence, Alley, Misc feature and Pool QC are most often missing together. This probably means that a house doesn’t have an alley, a fence, a pool or any other miscellaneous features.\nSimilarly, the second most frequent “co-missingess” involves these plus missing “fireplace quality”, most likely due to the house not having fireplace.\nWe can also see that Garage_Yr_Blt, Garage_Finish, Garage_Qual and Garage Cond “co-miss” the same number of times - probably because these represent houses without garages.\n\n\n\n\nNext, let’s create two “helper” vectors with the names of the numeric and categorical variables from the ameshousing dataset, which we can then use to batch subset our dataset prior to EDA/visualisation:\n\n# pull out all of the numerical variables\nnumVars <- ameshousing %>% \n  select_if(is.numeric) %>%\n  names()\n\n# use Negate(is.numeric) to pull out all of the categorical variables\ncatVars <- ameshousing %>% \n  select_if(Negate(is.numeric)) %>%\n  names()\n\nLet’s then use the ggpairs() function to generate a plot of the first 10 numeric variables (and sale price, which is 33) against each other. We can repeat this for variables 11-20 and 21-33.\n\nggpairs(data = ameshousing, \n        columns = numVars[c(1:10, 33)], \n        title = \"Numeric variables 1 - 10\")\n\n\n\n# ggpairs(ameshousing, numVars[c(11:20, 33)], title = \"Numeric variables 11 - 20\")\n# ggpairs(ameshousing, numVars[c(21:33)], title = \"Numeric variables 21 - 33\")\nggpairs(data = ameshousing, \n        columns = c(catVars[2:5], \"Sale_Price\"), \n        title = \"Some categorical variables\")\n\n\n\n\nNext, we can generate a correlation plot between all of our numeric variables. By default, the cor() method will calculate the Pearson correlation between the Sale_Price and the other variables, and we can specify how we’d like to handle missing data when calculating this correlation.\nIn this case, we use pairwise.complete.obs, which calculates the correlation between each pair of variables using all complete pairs of observations on those variables.\nWe then plot the correlation using the corrplot library, which has several options for how to visualise a correlation plot. See here for some examples of the visualisations it can produce.\n\n# pairs.panels(ameshousing[ , names(ameshousing)[c(3, 16, 23, 27,37)]], scale=TRUE)\nameshousingCor <- cor(ameshousing[,numVars],\n                      use = \"pairwise.complete.obs\")\n\nameshousingCor_pvalues <- cor_pmat(ameshousingCor)\nggcorrplot(ameshousingCor, type = \"lower\")\n\n\n\n\nWe can also make a dynamic visualisation using plotly.\n\n#Bonus: interactive corrplot with zoom and mouseover\nggcorrplot(ameshousingCor, type = \"lower\") %>% ggplotly()\n\n\n\n\n\n\n\n\n\n\n\nChallenge 3\n\n\n\n\nWhat variables are the most correlated with SalePrice?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nas_tibble(ameshousingCor, rownames = \"rowname\") %>%\n  gather(pair, value, -rowname) %>%\n  filter(rowname != pair) %>% #remove self correlation\n  filter(rowname == \"Sale_Price\") %>%\n  arrange(desc(abs(value))) %>%\n  head()\n\n# A tibble: 6 × 3\n  rowname    pair          value\n  <chr>      <chr>         <dbl>\n1 Sale_Price Gr_Liv_Area   0.707\n2 Sale_Price Garage_Cars   0.648\n3 Sale_Price Garage_Area   0.640\n4 Sale_Price Total_Bsmt_SF 0.633\n5 Sale_Price First_Flr_SF  0.622\n6 Sale_Price Year_Built    0.558\n\n\nWe can also plot this, using a slightly different representation:\n\nCircles instead of only colour to represent correlation levels\nFilter out correlations less than 0.5\n\n\nall_numVar <- ameshousing[, numVars]\ncor_numVar <- cor(all_numVar, use=\"pairwise.complete.obs\") \nCorHigh <- as_tibble(\n  data.frame(correlation = cor_numVar[,'Sale_Price']), rownames = \"rownames\")  %>% \n  filter(abs(correlation) >= 0.5) %>% \n  .$rownames\nggcorrplot(cor_numVar[CorHigh, CorHigh], type = \"lower\", \"circle\")\n\n\n\n\n\n\n\nLet’s plot one of these relationships:\n\ngra <- ameshousing %>%\n  ggplot(aes(x = Gr_Liv_Area, y = Sale_Price/1000)) + \n  geom_point(alpha = 0.1) + \n  labs(y = \"Sale Price/$1000\",\n       x = \"Living Area (sq.ft)\",\n       title = \"Ames Housing Data\") +\n  geom_smooth(method= \"lm\")  +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ngra %>% \n  ggplotly()\n\n\n\n\n\nWe can see that there are five houses with an area > 4000 square feet that seem to be outliers in the data. We should filter them out. Next, let’s generate a violin and boxplot by Quality:\n\nameshousing_filt <-\n  ameshousing %>%\n  filter(Gr_Liv_Area <= 4000)\n\np <- ameshousing_filt %>%\n  ggplot(aes(x = Overall_Qual, y = Sale_Price)) +\n  geom_violin() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nggplotly(p)\n\n\n\n\np <-ameshousing_filt %>%\n  mutate(Quality = as.factor(Overall_Qual)) %>%\n  ggplot(aes(x = Quality,\n             y = Sale_Price / 1000,\n             fill = Quality)) +\n  labs(y = \"Sale Price in $k's\",\n       x = \"Overall Quality of House\",\n       title = \"Ames Housing Data\") +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \nggplotly(p)"
  },
  {
    "objectID": "100_dataset1/step1.html#eda-of-outcome-variable",
    "href": "100_dataset1/step1.html#eda-of-outcome-variable",
    "title": "Sydney Informatics Hub",
    "section": "EDA of outcome variable",
    "text": "EDA of outcome variable\n\nYou also need to do EDA on the outcome variable to:\n\nidentify outliers\nexplore whether there is any skew in its distribution\nidentify a transformation to use when modelling the data (if appropriate)\n\nThis is because many models, including ordinary linear regression, assume that prediction errors (and hence the response) are normally distributed.\n\nameshousing_filt %>% \n  ggplot(aes(x = Sale_Price/1000)) + \n  geom_histogram(bins = 50) + \n  labs(x = \"Sale Price in $k's\",\n       y = \"Number of Houses sold\")\n\n\n\n\nLet’s explore different ways of transforming the Sale Price.\n\n#No transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = Sale_Price)) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#Sqrt transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = sqrt(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#natural log transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = log(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#log10 transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = log10(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nChallenge 4\n\n\n\n\nIf you were working with this dataset, which of the above would you prefer?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe log10 transformation seems best, as it both helps the distribution look more normal and helps keep our error metrics and final predictions easily interpretable. It also means that the errors of predicting the values of inexpensive and expensive houses will affect the prediction equally.\n\nbestNormalize::bestNormalize(\n  ameshousing_filt$Sale_Price,\n  allow_orderNorm = FALSE)\n\nBest Normalizing transformation with 2925 Observations\n Estimated Normality Statistics (Pearson P / df, lower => more normal):\n - arcsinh(x): 1.5968\n - Box-Cox: 1.6314\n - Center+scale: 5.2811\n - Log_b(x+a): 1.5968\n - sqrt(x + a): 2.7969\n - Yeo-Johnson: 1.6314\nEstimation method: Out-of-sample via CV with 10 folds and 5 repeats\nBased off these, bestNormalize chose:\nStandardized asinh(x) Transformation with 2925 nonmissing obs.:\n Relevant statistics:\n - mean (before standardization) = 12.71303 \n - sd (before standardization) = 0.4060161 \n\n\nThe bestNormalize library can be used to identify the best normalising transformation. Note that in this case, the arcsinh(x) and logarithmic transformations both achieve best normalisation results. To make interpretation a bit easier, we choose the logarithmic transformation.\n\n\n\n\nameshousing_filt <- ameshousing_filt %>% mutate(Sale_Price = log10(Sale_Price))"
  },
  {
    "objectID": "100_dataset1/step1.html#feature-engineering",
    "href": "100_dataset1/step1.html#feature-engineering",
    "title": "Sydney Informatics Hub",
    "section": "Feature engineering",
    "text": "Feature engineering\nThe year in which the house was built and the year when it was remodelled are not really the most relevant parameters we look at when buying a house: instead, buyers usually care a lot more about the age of the house and the time since the last remodel. Let’s engineer these features:\n\nameshousing_filt_engineered <-\n  ameshousing_filt %>%\n  mutate(Time_Since_Remodel = Year_Sold - Year_Remod_Add, \n         House_Age = Year_Sold - Year_Built) %>%\n  select(-Year_Remod_Add, -Year_Built)\n\nsaveRDS(ameshousing_filt_engineered, \"../_models/ames_dataset_filt.rds\")\n\nNote\nMake sure to create a “models” folder in your project working directory!\nBefore you can save your data as .Rds objects, you will actually need to create a folder for these files to go into. Do this by clicking on the “new folder” button in the files window in R studio. Rename your new folder to “models”."
  },
  {
    "objectID": "Introduction.html#what-is-machine-learning",
    "href": "Introduction.html#what-is-machine-learning",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "What is Machine Learning",
    "text": "What is Machine Learning\n\nMachine Learning (ML) is the field of study that gives computers the ability to learn from data without being explicitly programmed\n\nA ML system is trained rather than explicitly programmed;\nIt is a subset of the Artificial Intelligence;\nAlso known as predictive modeling/statistical learning."
  },
  {
    "objectID": "Introduction.html#learning-by-experience",
    "href": "Introduction.html#learning-by-experience",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "Learning by experience",
    "text": "Learning by experience\nWe are never certain something will happen, but we usually know (or can estimate rather well) how likely it is to happen or, at least, what is most likely to happen, based on the experience we have acquired throughout our life.\nExperience in ML means: Data in the form of examples\nWe explore data to find patterns to understand the hidden laws that regulates the domain/make predictions about the world around us."
  },
  {
    "objectID": "Introduction.html#what-do-we-mean-by-learning",
    "href": "Introduction.html#what-do-we-mean-by-learning",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "What do we mean by learning?",
    "text": "What do we mean by learning?\nLearning is our means of attaining the ability to perform automatically a task.\n\nThe main goal of the ML process is to find an algorithm \\(f(x)\\) that most accurately predicts future values \\(y\\) (or outcome) based on a set of inputs \\(X\\) (or predictors), where each entry \\(x^{i}\\) is a different feature:\n\n\nFeatures of an image are usually the values of the pixels in the image;\nWe want to predict the price of an house on the basis of some characteristics (n° rooms, garden, position, floor, etc..) that are the features of each house predictors from which we learn."
  },
  {
    "objectID": "Introduction.html#tidyverse",
    "href": "Introduction.html#tidyverse",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "Tidyverse",
    "text": "Tidyverse\nA hugely important part of any modeling approach is exploratory data analysis. In this course, we’ll be using tidyverse packages for getting to know your data, manipulating it, and visualizing it. The tidyverse is a collection of R packages designed for data science that share common APIs and an underlying philosophy. When you type library(tidyverse), what you’re doing is loading this collection of related packages for handling data using tidy data principles. These packages include ggplot2 for data visualization, and dplyr and tidyr for data manipulation and transformation. During this course, we’ll point out when we use functions from these different packages.\nVisit this page to learn more about tidyverse: https://www.tidyverse.org/learn/"
  },
  {
    "objectID": "Introduction.html#tidymodels",
    "href": "Introduction.html#tidymodels",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "Tidymodels",
    "text": "Tidymodels\nTidymodels is a collection of R packages that provides a modern and consistent approach to building and validating machine learning models. Compared to older packages such as caret, tidymodels offers several benefits:\n\nit uses a consistent and intuitive syntax across all of its packages, which makes it easier to learn and use compared to the varied and sometimes complex syntax of older packages;\nit is built on top of the tidyverse (dplyr, ggplot2), for a seamless data analysis workflow;\nit includes a number of packages (recipes, rsample) that provide tools for data preprocessing, making it easy to perform common data preprocessing tasks, such as feature engineering, and to integrate these tasks into the machine learning workflow;\nit includes packages (parsnip, tune) that provide a more flexible and modern approach to model tuning and selection. These packages allow for easy cross-validation, hyperparameter tuning, and model selection, and provide a more transparent and reproducible workflow;\nit is actively developed and has a growing community of users and contributors. This means that there are many resources available for learning and troubleshooting, and that the packages are likely to continue to evolve and improve over time.\n\nOverall, tidymodels offers a more modern and consistent approach to building and validating machine learning models, and provides a number of tools for data preprocessing, model tuning and selection, and workflow integration. These features make it a powerful and user-friendly tool."
  },
  {
    "objectID": "100_dataset1/step2.html#feature-engineering",
    "href": "100_dataset1/step2.html#feature-engineering",
    "title": "Sydney Informatics Hub",
    "section": "Feature engineering",
    "text": "Feature engineering\nIn tidymodels, you can preprocess your data using the recipes package. Typical preprocessing steps include:\n\nScaling and centering numeric predictors;\nRemoving skewness from numeric variables;\nOne-hot and dummy variable encoding for categorical variables;\nRemoving correlated predictors and zero variance variables;\nImputing missing data.\n\nEach successive step() function adds a preprocessing step to our recipe object in the order that they are provided:\n\names_rec <-\n  recipe(Sale_Price ~ ., data = ames_train) %>%\n  step_other(all_nominal(), threshold = 0.01) %>% #useful when you have some factor levels with very few observations, all_nominal selects both characters and factors, pools infrequently occurring values (frequency less than 0.01) into an \"other\" category\n  step_nzv(all_nominal()) %>% #remove variables that are highly sparse and unbalanced\n  step_center(all_numeric(), -all_outcomes()) %>% #subtracts the column mean from a variable\n  step_scale(all_numeric(), -all_outcomes()) %>% #divides by the standard deviation\n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) #create dummy variables for all nominal variables except the outcome variable \n\names_rec\n\nRecipe\nInputs:\n      role #variables\n   outcome          1\n predictor         80\nOperations:\nCollapsing factor levels for all_nominal()\nSparse, unbalanced variable filter on all_nominal()\nCentering for all_numeric(), -all_outcomes()\nScaling for all_numeric(), -all_outcomes()\nDummy variables from all_nominal(), -all_outcomes()\n\n\nThe preprocessing recipe ames_rec has been defined but no values have been estimated.\n\nThe prep() function takes that defined object and computes everything so that the preprocessing steps can be executed. Note that This is done with the training data.\n\n\names_prep <- prep(ames_rec)\n\names_prep\n\nRecipe\nInputs:\n      role #variables\n   outcome          1\n predictor         80\nTraining data contained 2339 data points and no missing data.\nOperations:\nCollapsing factor levels for MS_SubClass, MS_Zoning, Street, Lot_Shape, Util... [trained]\nSparse, unbalanced variable filter removed Street, Alley, Land_Contour, Utilities,... [trained]\nCentering for Lot_Frontage, Lot_Area, Mas_Vnr_Area, BsmtFin_S... [trained]\nScaling for Lot_Frontage, Lot_Area, Mas_Vnr_Area, BsmtFin_S... [trained]\nDummy variables from MS_SubClass, MS_Zoning, Lot_Shape, Lot_Config, Neighborho... [trained]\n\n\nThe bake() and juice() functions both return data, not a preprocessing recipe object.  - Thebake()function takes a prepped recipe (one that has had all quantities estimated from training data) and applies it tonew_data`. That new_data could be the training data again or it could be the testing data (with the TRAINING parameters)\n\names_test_proc <- bake(ames_prep, new_data = ames_test)\n\n\nThe juice() function is a nice little shortcut. When we juice() the recipe, we squeeze that training data back out, transformed in the ways we specified. Let’s compare the bake() and juice() outputs:\n\n\nbake(ames_prep, new_data = ames_train)\n\n# A tibble: 2,339 × 231\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       0.374   -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2       0.374    0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3      -0.137   -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4      -1.01    -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5      -0.0770  -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6      -0.227   -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7       0.374   -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8       0.314   -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9      -1.73    -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10      -1.73    -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 222 more variables: Low_Qual_Fin_SF <dbl>,\n#   Gr_Liv_Area <dbl>, Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>,\n#   Full_Bath <dbl>, Half_Bath <dbl>, Bedroom_AbvGr <dbl>, Kitchen_AbvGr <dbl>,\n#   TotRms_AbvGrd <dbl>, Fireplaces <dbl>, Garage_Cars <dbl>,\n#   Garage_Area <dbl>, Wood_Deck_SF <dbl>, Open_Porch_SF <dbl>,\n#   Enclosed_Porch <dbl>, Three_season_porch <dbl>, Screen_Porch <dbl>,\n#   Pool_Area <dbl>, Misc_Val <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, …\n\njuice(ames_prep) \n\n# A tibble: 2,339 × 231\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       0.374   -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2       0.374    0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3      -0.137   -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4      -1.01    -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5      -0.0770  -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6      -0.227   -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7       0.374   -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8       0.314   -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9      -1.73    -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10      -1.73    -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 222 more variables: Low_Qual_Fin_SF <dbl>,\n#   Gr_Liv_Area <dbl>, Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>,\n#   Full_Bath <dbl>, Half_Bath <dbl>, Bedroom_AbvGr <dbl>, Kitchen_AbvGr <dbl>,\n#   TotRms_AbvGrd <dbl>, Fireplaces <dbl>, Garage_Cars <dbl>,\n#   Garage_Area <dbl>, Wood_Deck_SF <dbl>, Open_Porch_SF <dbl>,\n#   Enclosed_Porch <dbl>, Three_season_porch <dbl>, Screen_Porch <dbl>,\n#   Pool_Area <dbl>, Misc_Val <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, …\n\n\nIt is the same as bake(ames_rep, new_data = ames_train) and is just a shortcut that we are going to use later.\n\n\n\n\n\n\nChallenge X\n\n\n\nDoes it make sense to apply these preprocessing steps to the test set?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNo, it doesn’t. You want the set test to look like new data that your model will see in the future, so you don’t want to mess with the class balance there; you want to see how your model will perform on imbalanced data, even if you have trained it on artificially balanced data.\n\n\n\nBuild the model\nIn tidymodels, you specify models using three concepts.\n\nModel type differentiates models such as logistic regression, decision tree models, and so forth;\nModel mode includes common options like regression and classification, some model types support either of these while some only have one mode;\nModel engine is the computational tool which will be used to fit the model.\n\nWe will specify the model using the parsnip package - Many functions have different interfaces and arguments names and parsnip standardizes the interface for fitting models as well as the return values.\n\n#a linear regression model specification\names_model <- linear_reg() %>% #pick a model\n  set_engine(\"lm\")           #set the engine\n                             #set_mode(\"regression\") we don't need this as the model linear_reg() only does regression\n\n#view model properties\names_model\n\nLinear Regression Model Specification (regression)\nComputational engine: lm \n\n\nNow we are ready to train our model object on the training data. We can do this using the fit() function from the parsnip package. The fit() function takes the following arguments:\n\na parnsip model object specification;\na model formula\na data frame with the training data\n\nThe code below trains our linear regression model on the prepped training data. In our formula, we have specified that Sale_Price is the response variable and included all the rest as our predictor variables.\n\names_fit <- ames_model %>%\n  fit(Sale_Price ~ .,\n      data=juice(ames_prep))\n\n# View lm_fit properties\names_fit\n\nparsnip model object\nCall:\nstats::lm(formula = Sale_Price ~ ., data = data)\nCoefficients:\n                                          (Intercept)  \n                                            4.2344150  \n                                         Lot_Frontage  \n                                            0.0010509  \n                                             Lot_Area  \n                                            0.0056766  \n                                         Mas_Vnr_Area  \n                                            0.0033526  \n                                         BsmtFin_SF_1  \n                                            0.0288579  \n                                         BsmtFin_SF_2  \n                                           -0.0024142  \n                                          Bsmt_Unf_SF  \n                                           -0.0096332  \n                                        Total_Bsmt_SF  \n                                            0.0293221  \n                                         First_Flr_SF  \n                                            0.0428570  \n                                        Second_Flr_SF  \n                                            0.0514152  \n                                      Low_Qual_Fin_SF  \n                                            0.0043645  \n                                          Gr_Liv_Area  \n                                                   NA  \n                                       Bsmt_Full_Bath  \n                                            0.0046797  \n                                       Bsmt_Half_Bath  \n                                            0.0008760  \n                                            Full_Bath  \n                                            0.0075337  \n                                            Half_Bath  \n                                            0.0063545  \n                                        Bedroom_AbvGr  \n                                           -0.0042524  \n                                        Kitchen_AbvGr  \n                                           -0.0032240  \n                                        TotRms_AbvGrd  \n                                            0.0010374  \n                                           Fireplaces  \n                                            0.0048444  \n                                          Garage_Cars  \n                                            0.0088917  \n                                          Garage_Area  \n                                            0.0054821  \n                                         Wood_Deck_SF  \n                                            0.0028177  \n                                        Open_Porch_SF  \n                                            0.0018956  \n                                       Enclosed_Porch  \n                                            0.0035592  \n                                   Three_season_porch  \n                                            0.0006254  \n                                         Screen_Porch  \n                                            0.0057138  \n                                            Pool_Area  \n                                           -0.0001730  \n                                             Misc_Val  \n                                            0.0008810  \n                                              Mo_Sold  \n                                           -0.0003984  \n                                            Year_Sold  \n                                           -0.0019209  \n                                            Longitude  \n                                           -0.0097179  \n                                             Latitude  \n                                           -0.0059391  \n                                   Time_Since_Remodel  \n                                           -0.0057059  \n                                            House_Age  \n                                           -0.0214642  \n      MS_SubClass_One_Story_1946_and_Newer_All_Styles  \n                                            0.0061643  \n                 MS_SubClass_One_Story_1945_and_Older  \n                                           -0.0206969  \n     MS_SubClass_One_and_Half_Story_Finished_All_Ages  \n                                            0.0282382  \n                 MS_SubClass_Two_Story_1946_and_Newer  \n                                           -0.0138448  \n                 MS_SubClass_Two_Story_1945_and_Older  \n                                            0.0158489  \n                      MS_SubClass_Split_or_Multilevel  \n                                           -0.0153464  \n                              MS_SubClass_Split_Foyer  \n                                            0.0073930  \n               MS_SubClass_Duplex_All_Styles_and_Ages  \n                                            0.0123223  \n             MS_SubClass_One_Story_PUD_1946_and_Newer  \n                                            0.0186726  \n             MS_SubClass_Two_Story_PUD_1946_and_Newer  \n                                           -0.0290154  \nMS_SubClass_Two_Family_conversion_All_Styles_and_Ages  \n                                            0.0126693  \n                                    MS_SubClass_other  \n                                                   NA  \n               MS_Zoning_Floating_Village_Residential  \n                                            0.0369229  \n                    MS_Zoning_Residential_Low_Density  \n                                            0.0295723  \n                 MS_Zoning_Residential_Medium_Density  \n                                            0.0224024  \n                                      MS_Zoning_other  \n                                                   NA  \n                                    Lot_Shape_Regular  \n                                            0.0047757  \n                         Lot_Shape_Slightly_Irregular  \n                                            0.0045442  \n                       Lot_Shape_Moderately_Irregular  \n                                            0.0167009  \n                                      Lot_Shape_other  \n                                                   NA  \n                                    Lot_Config_Corner  \n                                            0.0061984  \n                                   Lot_Config_CulDSac  \n                                            0.0124304  \n                                       Lot_Config_FR2  \n                                           -0.0034930  \n                                    Lot_Config_Inside  \n                                            0.0041820  \n                                     Lot_Config_other  \n                                                   NA  \n                              Neighborhood_North_Ames  \n                                           -0.0144052  \n                           Neighborhood_College_Creek  \n                                           -0.0403143  \n                                Neighborhood_Old_Town  \n                                           -0.0395437  \n                                 Neighborhood_Edwards  \n                                           -0.0485293  \n                                Neighborhood_Somerset  \n                                            0.0158820  \n                      Neighborhood_Northridge_Heights  \n                                            0.0152055  \n                                 Neighborhood_Gilbert  \n                                           -0.0076228  \n                                  Neighborhood_Sawyer  \n                                           -0.0245480  \n                          Neighborhood_Northwest_Ames  \n                                           -0.0147878  \n                             Neighborhood_Sawyer_West  \n                                           -0.0382249  \n                                Neighborhood_Mitchell  \n                                           -0.0254694  \n                               Neighborhood_Brookside  \n                                           -0.0110661  \n                                Neighborhood_Crawford  \n                                            0.0154749  \n                  Neighborhood_Iowa_DOT_and_Rail_Road  \n                                           -0.0481840  \n                              Neighborhood_Timberland  \n                                           -0.0246553  \n                              Neighborhood_Northridge  \n                                            0.0109785  \n                             Neighborhood_Stone_Brook  \n                                            0.0376989  \n Neighborhood_South_and_West_of_Iowa_State_University  \n                                           -0.0339271  \n                             Neighborhood_Clear_Creek  \n                                           -0.0170590  \n                          Neighborhood_Meadow_Village  \n                                           -0.0629992  \n                                   Neighborhood_other  \n                                                   NA  \n                                   Condition_1_Artery  \n                                           -0.0179882  \n                                    Condition_1_Feedr  \n                                           -0.0119543  \n                                     Condition_1_Norm  \n                                            0.0063617  \n                                     Condition_1_PosN  \n                                            0.0101914  \n                                     Condition_1_RRAn  \n                                           -0.0142278  \n                                    Condition_1_other  \n                                                   NA  \n                                     Bldg_Type_OneFam  \n                                            0.0352264  \n                                   Bldg_Type_TwoFmCon  \n                                            0.0217637  \n                                     Bldg_Type_Duplex  \n                                                   NA  \n                                      Bldg_Type_Twnhs  \n                                           -0.0164880  \n                                     Bldg_Type_TwnhsE  \n                                                   NA  \n                         House_Style_One_and_Half_Fin  \n                                           -0.0334739  \n                                House_Style_One_Story  \n                                           -0.0113905  \n                                   House_Style_SFoyer  \n                                           -0.0045098  \n                                     House_Style_SLvl  \n                                            0.0080461  \n                                House_Style_Two_Story  \n                                           -0.0068768  \n                                    House_Style_other  \n                                                   NA  \n                                    Overall_Qual_Fair  \n                                           -0.0090491  \n                           Overall_Qual_Below_Average  \n                                           -0.0081678  \n                                 Overall_Qual_Average  \n                                            0.0135609  \n                           Overall_Qual_Above_Average  \n                                            0.0228156  \n                                    Overall_Qual_Good  \n                                            0.0317333  \n                               Overall_Qual_Very_Good  \n                                            0.0506332  \n                               Overall_Qual_Excellent  \n                                            0.0543703  \n                                   Overall_Qual_other  \n                                                   NA  \n                                    Overall_Cond_Fair  \n                                            0.0861003  \n                           Overall_Cond_Below_Average  \n                                            0.1382136  \n                                 Overall_Cond_Average  \n                                            0.1659276  \n                           Overall_Cond_Above_Average  \n                                            0.1795836  \n                                    Overall_Cond_Good  \n                                            0.1982810  \n                               Overall_Cond_Very_Good  \n                                            0.2021602  \n                               Overall_Cond_Excellent  \n                                            0.2216273  \n                                   Overall_Cond_other  \n                                                   NA  \n                                     Roof_Style_Gable  \n                                            0.0041041  \n                                       Roof_Style_Hip  \n                                            0.0013475  \n                                     Roof_Style_other  \n                                                   NA  \n                                 Exterior_1st_AsbShng  \n                                           -0.0197379  \n                                 Exterior_1st_BrkFace  \n                                            0.0218545  \n                                 Exterior_1st_CemntBd  \n                                           -0.0675824  \n                                 Exterior_1st_HdBoard  \n                                           -0.0177946  \n                                 Exterior_1st_MetalSd  \n                                           -0.0041764  \n                                 Exterior_1st_Plywood  \n                                           -0.0147857  \n                                  Exterior_1st_Stucco  \n                                           -0.0150856  \n                                 Exterior_1st_VinylSd  \n                                           -0.0269952  \n                                 Exterior_1st_Wd.Sdng  \n                                           -0.0127229  \n                                 Exterior_1st_WdShing  \n                                           -0.0219538  \n                                   Exterior_1st_other  \n                                                   NA  \n                                 Exterior_2nd_AsbShng  \n                                           -0.0294565  \n                                 Exterior_2nd_BrkFace  \n                                           -0.0252434  \n                                 Exterior_2nd_CmentBd  \n                                            0.0511306  \n                                 Exterior_2nd_HdBoard  \n                                           -0.0066992  \n                                 Exterior_2nd_MetalSd  \n                                           -0.0094713  \n                                 Exterior_2nd_Plywood  \n                                           -0.0088774  \n                                  Exterior_2nd_Stucco  \n                                            0.0028778  \n                                 Exterior_2nd_VinylSd  \n                                            0.0061450  \n                                 Exterior_2nd_Wd.Sdng  \n                                           -0.0049424  \n                                 Exterior_2nd_Wd.Shng  \n                                           -0.0005624  \n                                   Exterior_2nd_other  \n                                                   NA  \n                                 Mas_Vnr_Type_BrkFace  \n                                            0.0119788  \n                                    Mas_Vnr_Type_None  \n                                            0.0132996  \n                                   Mas_Vnr_Type_Stone  \n                                            0.0202174  \n                                   Mas_Vnr_Type_other  \n                                                   NA  \n                                 Exter_Qual_Excellent  \n                                            0.0412905  \n                                      Exter_Qual_Fair  \n                                           -0.0100946  \n                                      Exter_Qual_Good  \n                                            0.0067359  \n                                   Exter_Qual_Typical  \n                                                   NA  \n                                      Exter_Cond_Fair  \n                                           -0.0537435  \n                                      Exter_Cond_Good  \n                                           -0.0271431  \n                                   Exter_Cond_Typical  \n                                           -0.0190455  \n                                     Exter_Cond_other  \n                                                   NA  \n                                    Foundation_BrkTil  \n                                           -0.0221335  \n                                    Foundation_CBlock  \n                                           -0.0197832  \n                                     Foundation_PConc  \n                                           -0.0113600  \n                                      Foundation_Slab  \n                                           -0.0024282  \n                                     Foundation_other  \n                                                   NA  \n                                  Bsmt_Qual_Excellent  \n                                            0.0296809  \n                                       Bsmt_Qual_Fair  \n                                            0.0030970  \n                                       Bsmt_Qual_Good  \n                                            0.0160700  \n                                Bsmt_Qual_No_Basement  \n                                            0.0188896  \n                                    Bsmt_Qual_Typical  \n                                            0.0147692  \n                                      Bsmt_Qual_other  \n                                                   NA  \n                                     Bsmt_Exposure_Av  \n                                            0.0038457  \n                                     Bsmt_Exposure_Gd  \n                                            0.0268377  \n                                     Bsmt_Exposure_Mn  \n                                            0.0001947  \n                                     Bsmt_Exposure_No  \n                                           -0.0028258  \n                            Bsmt_Exposure_No_Basement  \n                                                   NA  \n                                   BsmtFin_Type_1_ALQ  \n                                            0.0837734  \n                                   BsmtFin_Type_1_BLQ  \n                                            0.0662634  \n                                   BsmtFin_Type_1_GLQ  \n                                            0.0596601  \n                                   BsmtFin_Type_1_LwQ  \n                                            0.0329057  \n                           BsmtFin_Type_1_No_Basement  \n                                                   NA  \n                                   BsmtFin_Type_1_Rec  \n                                            0.0072722  \n                                   BsmtFin_Type_1_Unf  \n                                                   NA  \n                                 Heating_QC_Excellent  \n                                            0.7700744  \n                                      Heating_QC_Fair  \n                                            0.7444348  \n                                      Heating_QC_Good  \n                                            0.7633523  \n                                   Heating_QC_Typical  \n                                            0.7575195  \n                                     Heating_QC_other  \n                                                   NA  \n                                        Central_Air_N  \n                                           -0.0232337  \n                                        Central_Air_Y  \n                                                   NA  \n                                     Electrical_FuseA  \n                                           -0.0134919  \n                                     Electrical_FuseF  \n                                           -0.0188211  \n                                     Electrical_SBrkr  \n                                           -0.0171300  \n                                     Electrical_other  \n                                                   NA  \n                               Kitchen_Qual_Excellent  \n                                            0.0303544  \n                                    Kitchen_Qual_Fair  \n                                           -0.0005397  \n                                    Kitchen_Qual_Good  \n                                            0.0050291  \n                                 Kitchen_Qual_Typical  \n                                                   NA  \n                                   Kitchen_Qual_other  \n                                                   NA  \n                               Fireplace_Qu_Excellent  \n                                           -0.0115950  \n                                    Fireplace_Qu_Fair  \n                                           -0.0047983  \n                                    Fireplace_Qu_Good  \n                                            0.0043227  \n                            Fireplace_Qu_No_Fireplace  \n                                           -0.0029386  \n                                    Fireplace_Qu_Poor  \n                                           -0.0089229  \n                                 Fireplace_Qu_Typical  \n                                                   NA  \n                                   Garage_Type_Attchd  \n                                            0.0277848  \n                                  Garage_Type_Basment  \n                                            0.0183001  \n                                  Garage_Type_BuiltIn  \n                                            0.0259155  \n                                   Garage_Type_Detchd  \n                                            0.0246522  \n                                Garage_Type_No_Garage  \n                                            0.0012371  \n                                    Garage_Type_other  \n                                                   NA  \n                                    Garage_Finish_Fin  \n                                            0.0004798  \n                              Garage_Finish_No_Garage  \n                                           -0.0064210  \n                                    Garage_Finish_RFn  \n                                           -0.0033819  \n                                    Garage_Finish_Unf  \n                                                   NA  \n                                     Garage_Qual_Fair  \n                                           -0.0243010  \n                                Garage_Qual_No_Garage  \n                                                   NA  \n                                  Garage_Qual_Typical  \n                                           -0.0147644  \n                                    Garage_Qual_other  \n                                                   NA  \n                                     Garage_Cond_Fair  \n                                           -0.0288340  \n                                Garage_Cond_No_Garage  \n                                                   NA  \n                                  Garage_Cond_Typical  \n                                           -0.0058730  \n                                    Garage_Cond_other  \n                                                   NA  \n                              Paved_Drive_Dirt_Gravel  \n                                           -0.0044010  \n                         Paved_Drive_Partial_Pavement  \n                                           -0.0080910  \n                                    Paved_Drive_Paved  \n                                                   NA  \n                                   Fence_Good_Privacy  \n                                           -0.0068390  \n                                      Fence_Good_Wood  \n                                           -0.0129793  \n                                Fence_Minimum_Privacy  \n                                           -0.0040916  \n                                       Fence_No_Fence  \n                                           -0.0050151  \n                                          Fence_other  \n                                                   NA  \n                                        Sale_Type_COD  \n                                           -0.0202250  \n                                        Sale_Type_New  \n                                            0.0181473  \n                                        Sale_Type_WD.  \n                                           -0.0182848  \n                                      Sale_Type_other  \n                                                   NA  \n                               Sale_Condition_Abnorml  \n                                           -0.0451496  \n                                Sale_Condition_Family  \n                                           -0.0225266  \n                                Sale_Condition_Normal  \n                                           -0.0017995  \n                               Sale_Condition_Partial  \n                                           -0.0222955  \n                                 Sale_Condition_other  \n                                                   NA  \n\n\nTo obtain the detailed results from our trained linear regression model in a data frame, we can use the tidy() and glance() functions directly on our trained parsnip model, ames_fit. - The tidy() function takes a linear regression object and returns a data frame of the estimated model coefficients and their associated F-statistics and p-values; - The glance() function will return performance metrics obtained on the training data such as the R2 value (r.squared) and the RMSE (sigma). - We can also use the vip() function to plot the variable importance for each predictor in our model. The importance value is determined based on the F-statistics and estimate coefficents in our trained model object.\n\n# Data frame of estimated coefficients\ntidy(ames_fit)\n\n# A tibble: 231 × 5\n   term          estimate std.error statistic   p.value\n   <chr>            <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)    4.23      0.0959     44.2   1.44e-303\n 2 Lot_Frontage   0.00105   0.00121     0.868 3.85e-  1\n 3 Lot_Area       0.00568   0.00129     4.40  1.12e-  5\n 4 Mas_Vnr_Area   0.00335   0.00167     2.01  4.50e-  2\n 5 BsmtFin_SF_1   0.0289    0.0247      1.17  2.42e-  1\n 6 BsmtFin_SF_2  -0.00241   0.00118    -2.04  4.13e-  2\n 7 Bsmt_Unf_SF   -0.00963   0.00208    -4.63  3.82e-  6\n 8 Total_Bsmt_SF  0.0293    0.00325     9.03  3.65e- 19\n 9 First_Flr_SF   0.0429    0.00291    14.7   7.55e- 47\n10 Second_Flr_SF  0.0514    0.00354    14.5   9.84e- 46\n# … with 221 more rows\n\n# Performance metrics on training data\nglance(ames_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.sq…¹  sigma stati…² p.value    df logLik    AIC    BIC devia…³\n      <dbl>      <dbl>  <dbl>   <dbl>   <dbl> <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n1     0.935      0.929 0.0476    161.       0   191  3905. -7424. -6313.    4.86\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\n# Plot variable importance\nvip(ames_fit)\n\n\n\n\n#Evaluating the model\nTo assess the accuracy of our trained linear regression model, ames_fit, we must use it to make predictions on our test data, ames_test_proc. This is done with the predict() function from parnsip. This function takes two important arguments:\n\na trained parnsip model object;\nnew_data for which to generate predictions.\n\nThe code below uses the predict() function to generate a data frame with a single column, .pred, which contains the predicted Sale Price values on the ames_test data.\n\npredict(ames_fit, new_data = ames_test_proc)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 586 × 1\n   .pred\n   <dbl>\n 1  5.04\n 2  5.22\n 3  5.39\n 4  5.14\n 5  5.23\n 6  4.99\n 7  4.99\n 8  4.98\n 9  5.14\n10  5.76\n# … with 576 more rows\n\n\nWarning: prediction from a rank-deficient fit may be misleading\nOne reason this warning occurs is that you have more model parameters than observations in the dataset. We refer to this as high dimensional data. With high dimensional data, it becomes impossible to find a model that can describe the relationship between the predictor variables and the response variable because we don’t have enough observations to train the model on. The easiest way to resolve this issue is to use a simpler model with less coefficients to estimate.We are not worrying about this today.\nGenerally it’s best to combine the test data set and the predictions into a single data frame. We create a data frame with the predictions on the ames_test data and then use bind_cols() to add the ames_test data to the results.\n\names_test_results <- predict(ames_fit, new_data = ames_test_proc) %>% \n  bind_cols(ames_test_proc)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n# View results\names_test_results\n\n# A tibble: 586 × 232\n   .pred Lot_F…¹ Lot_A…² Mas_V…³ BsmtF…⁴ BsmtF…⁵ Bsmt_…⁶ Total…⁷ First…⁸ Secon…⁹\n   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  5.04   0.675   0.172 -0.569    0.819   0.552 -0.657  -0.388   -0.689  -0.786\n 2  5.22   0.705   0.488  0.0527  -1.42   -0.298 -0.347   0.670    0.456  -0.786\n 3  5.39   0.916   0.145  1.45    -0.523  -0.298 -0.336   1.92     1.85   -0.786\n 4  5.14   0.224  -0.207 -0.569   -0.970  -0.298 -0.632   0.0242  -0.266  -0.786\n 5  5.23  -0.949  -0.516 -0.569   -0.523  -0.298 -0.466   0.850    0.477  -0.786\n 6  4.99  -1.10   -1.01   2.33     0.819  -0.298 -0.527  -1.33    -1.78    0.392\n 7  4.99  -1.10   -1.01   2.26     0.819  -0.298 -0.759  -1.23    -1.67    0.539\n 8  4.98  -1.10   -1.01   1.62     1.27   -0.298 -0.0770 -1.23    -1.67    0.539\n 9  5.14  -1.01   -0.943 -0.569   -1.42   -0.298 -0.495  -0.452   -0.797   0.618\n10  5.76   1.58    0.492  5.74    -0.523  -0.298  2.08    4.26     4.07   -0.786\n# … with 576 more rows, 222 more variables: Low_Qual_Fin_SF <dbl>,\n#   Gr_Liv_Area <dbl>, Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>,\n#   Full_Bath <dbl>, Half_Bath <dbl>, Bedroom_AbvGr <dbl>, Kitchen_AbvGr <dbl>,\n#   TotRms_AbvGrd <dbl>, Fireplaces <dbl>, Garage_Cars <dbl>,\n#   Garage_Area <dbl>, Wood_Deck_SF <dbl>, Open_Porch_SF <dbl>,\n#   Enclosed_Porch <dbl>, Three_season_porch <dbl>, Screen_Porch <dbl>,\n#   Pool_Area <dbl>, Misc_Val <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, …\n\n\nNow we have the model results and the test data in a single data frame.\nCalculating rmse and rsq on the Test Data\nTo obtain the rmse and rsq values on our test set results, we can use the rmse() and rsq() functions. Both functions take the following arguments:\n\na data frame with columns that have the true values and predictions;\nthe column with the true response values;\nthe column with predicted values.\n\nIn the examples below we pass our ames_test_results to these functions to obtain these values for our test set. Results are always returned as a data frame with the following columns: .metric, .estimator, and .estimate.\n\n#RMSE on test set\ntest_rmse <- rmse(ames_test_results, \n     truth = Sale_Price,\n     estimate = .pred)\n\n#rsq on test set\ntest_rsq<- rsq(ames_test_results,\n    truth = Sale_Price,\n    estimate = .pred)\n\n\n\n\n\n\n\nChallenge X\n\n\n\nWe mentioned earlier that the bake() function takes a prepped recipe (ames_prep) and applies it to new_data. The new_data could be the training data again or it could be the testing data. We just evaluated our model on the test data, let’s try to apply the bake() and predict() functions on the training data and compare the results.\nInstructions\n\n#bake() training data\n\n#predict() selling price on the training data\n\n#combine the training data set and the predictions into a single data frame\n\n#RMSE on training set\n\n#rsq on training set\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#bake() training data\names_train_proc <- bake(ames_prep, new_data = ames_train)\n#predict() selling price on the training data\names_train_results <-predict(ames_fit, new_data = ames_train_proc)\n#combine the training data set and the predictions into a single data frame\names_train_results <- ames_train_results %>%\n  bind_cols(ames_train_proc)\n#RMSE on training set\ntrain_rmse <- rmse(ames_train_results, \n     truth = Sale_Price,\n     estimate = .pred)\n#rsq on training set\ntrain_rsq <- rsq(ames_train_results,\n    truth = Sale_Price,\n    estimate = .pred)\n\n\n\n\nLet’s have a look at all the metrics for both our training and test datasets:\n\n#plot metrics for training and test datasets\ntrain_rsq %>%\n  mutate(dataset = \"training\") %>%\n  bind_rows(train_rmse %>%\n              mutate(dataset = \"training\")) %>%\n  bind_rows(test_rsq %>%\n              mutate(dataset = \"test\") %>%\n              bind_rows(test_rmse %>%\n                          mutate(dataset = \"test\")))\n\n# A tibble: 4 × 4\n  .metric .estimator .estimate dataset \n  <chr>   <chr>          <dbl> <chr>   \n1 rsq     standard      0.935  training\n2 rmse    standard      0.0456 training\n3 rsq     standard      0.862  test    \n4 rmse    standard      0.0647 test    \n\n\nIf we look at the testing data, the rmse is higher than the training data. Our training data is not giving us a good idea of how our model is going to perform. In this situation, our algorithm fits our existing data very well, but doesn’t generalise well on new data.\nLet’s visualise the situation with an R2 plot:\n\names_test_results %>%\n  mutate(train = \"testing\") %>%\n  bind_rows(ames_train_results %>%\n              mutate(train = \"training\")) %>%\n  ggplot(aes(Sale_Price, .pred, color = train)) +\n  geom_abline(intercept = 0, slope = 1, color = \"black\", size = 0.5, linetype=\"dotted\") +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Actual Selling Price\",\n    y = \"Predicted Selling Price\",\n    color = \"Test/Training data\"\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nThis is a plot that can be used for any regression model. It plots the actual values (Sale Prices) versus the model predictions (.pred) as a scatter plot. It also plot the line y = x through the origin. This line is a visually representation of the perfect model where all predicted values are equal to the true values in the test set. The farther the points are from this line, the worse the model fit. The reason this plot is called an R2 plot, is because the R2 is the squared correlation between the true and predicted values, which are plotted as paired in the plot.\nResampling\nWe made not such a great decision in the previous section; we expected the model evaluated once on the whole training set to help us understand something about how it would perform on new data. Fortunately, we have some options. We can resample the training set to produce an estimate of how the model will perform.The idea of resampling is to create simulated data sets that can be used to estimate the performance of your model, say, because you want to compare models. You can create these resampled data sets instead of using either your training set (which can give overly optimistic results, especially for powerful ML algorithms) or your testing set (which is extremely valuable and can only be used once or at most twice). One of these resampling methods is cross-validation.\nCross-validation means taking your training set and randomly dividing it up evenly into subsets, sometimes called “folds”. A fold here means a group or subset or partition.\nYou use one of the folds for validation and the rest for training, then you repeat these steps with all the subsets and combine the results, usually by taking the mean. Cross-validation allows you to get a more accurate estimate of how your model will perform on new data.\n\n\n\n\n\n\nChallenge X\n\n\n\nWhen you implement 10-fold cross-validation repeated 5 times, you:\n\nrandomly divide your training data into 50 subsets and train on 49 at a time (assessing on the other subset), iterating through all 50 subsets for assessment.\nrandomly divide your training data into 10 subsets and train on 9 at a time (assessing on the other subset), iterating through all 10 subsets for assessment. Then you repeat that process 5 times.\nrandomly divide your training data into 5 subsets and train on 4 at a time (assessing on the other subset), iterating through all 5 subsets. Then you repeat that process 10 times.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimulations and practical experience show that 10-fold cross-validation repeated 5 times is a great resampling approach for many situations. This approach involves randomly dividing your training data into 10 folds, or subsets or groups, and training on only 9 while using the other fold for assessment. You iterate through all 10 folds being used for assessment; this is one round of cross-validation. You can then repeat the whole process multiple, perhaps 5, times.\n\n\n\n\names_folds <- vfold_cv(ames_train, v=10, repeats = 5)\n\nglimpse(ames_folds)\n\nRows: 50\nColumns: 3\n$ splits <list> [<vfold_split[2105 x 234 x 2339 x 81]>], [<vfold_split[2105 x …\n$ id     <chr> \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1…\n$ id2    <chr> \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06\", \"Fo…\n\n\nIn the next steps, we won’t not use prep() or bake(). The ames_rec recipe will be automatically applied in a later step using the workflow() and last_fit() functions.\nCreate a Workflow\nIn the previous section, we trained a linear regression model to the housing data step-by-step. In this section, we will go over how to combine all of the modeling steps into a single workflow. The workflow package was designed to combine models and recipes into a single object. To create a workflow, we start with workflow() to create an empty workflow and then add out model and recipe with add_model() and add_recipe().\n\names_wf <- workflow() %>%\n  add_model(ames_model) %>% \n  add_recipe(ames_rec)\n\names_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n• step_other()\n• step_nzv()\n• step_center()\n• step_scale()\n• step_dummy()\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\nComputational engine: lm \n\n\nOnce we have created a set of resamples, we can use the function fit_resamples() to fit a model to each resample and compute performance metrics for each.\n\nset.seed(234)\names_res <- ames_wf %>%\n  fit_resamples(\n    ames_folds,\n    control = control_resamples(save_pred = TRUE)\n  )\n\n! Fold01, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\nglimpse(ames_res)\n\nRows: 50\nColumns: 6\n$ splits       <list> [<vfold_split[2105 x 234 x 2339 x 81]>], [<vfold_split[2…\n$ id           <chr> \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"R…\n$ id2          <chr> \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06…\n$ .metrics     <list> [<tbl_df[2 x 4]>], [<tbl_df[2 x 4]>], [<tbl_df[2 x 4]>],…\n$ .notes       <list> [<tbl_df[1 x 3]>], [<tbl_df[1 x 3]>], [<tbl_df[1 x 3]>],…\n$ .predictions <list> [<tbl_df[234 x 4]>], [<tbl_df[234 x 4]>], [<tbl_df[234 x…\n\nsaveRDS(ames_res, \"../_models/ames_res.rds\")\n\nThe column .metric contains the performance statistics created from the 10 assessment sets. These can be manually unnested but the tune package contains a number of simple functions that can extract these data:\n\n# Obtain performance metrics on resampled training data\names_res %>% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.0537    50 0.00122 Preprocessor1_Model1\n2 rsq     standard   0.909     50 0.00383 Preprocessor1_Model1\n\n\n\n\nvfold_cv() creates folds for cross-validation;\n\nfit_resamples() fits models to resamples;\n\ncollect_metrics() obtains performance metrics from the results.\n\nNotice that now we have a realistic estimate from the training data that is closer to the testing data!\nIf we wanted to try different model types for this data set, we could more confidently compare performance metrics computed using resampling to choose between models. Also, remember that at the end of our project, we return to our test set to estimate final model performance.\nLet’s use the last_fit() function to evaluate once on the testing set:\n\n#Final fit on test dataset\names_final <- ames_wf %>%\n  last_fit(ames_split)\n\n! train/test split: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n# Obtain performance metrics on test data\ncollect_metrics(ames_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard      0.0647 Preprocessor1_Model1\n2 rsq     standard      0.862  Preprocessor1_Model1\n\n\nThe R-squared (rsq) and root mean squared error (RMSE) metrics are similar for both the training and testing datasets in our linear regression model. This is a good sign that the model is not over-fitting and can be used for making predictions on new data.\nWe can save the test set predictions by using the collect_predictions() function. This function returns a data frame which will have the response variables values from the test set and a column named .pred with the model predictions.\n\n# Obtain test set predictions data frame\names_results_final <- ames_final %>% \n                 collect_predictions()\n# View results\names_results_final\n\n# A tibble: 586 × 5\n   id               .pred  .row Sale_Price .config             \n   <chr>            <dbl> <int>      <dbl> <chr>               \n 1 train/test split  5.04     2       5.02 Preprocessor1_Model1\n 2 train/test split  5.22     3       5.24 Preprocessor1_Model1\n 3 train/test split  5.39    18       5.60 Preprocessor1_Model1\n 4 train/test split  5.14    26       5.15 Preprocessor1_Model1\n 5 train/test split  5.23    29       5.26 Preprocessor1_Model1\n 6 train/test split  4.99    30       4.98 Preprocessor1_Model1\n 7 train/test split  4.99    31       5.02 Preprocessor1_Model1\n 8 train/test split  4.98    32       4.94 Preprocessor1_Model1\n 9 train/test split  5.14    34       5.18 Preprocessor1_Model1\n10 train/test split  5.76    47       5.70 Preprocessor1_Model1\n# … with 576 more rows\n\n\nFinally, let’s use this data frame to make an R2 plot to visualize our model performance on the test data set:\n\nggplot(data = ames_results_final,\n       mapping = aes(x = .pred, y = Sale_Price)) +\n  geom_point(color = '#006EA1', alpha = 0.25) +\n  geom_abline(intercept = 0, slope = 1, color = 'black', size=0.5, linetype=\"dotted\") +\n  labs(title = 'Linear Regression Results - Ames Test Set',\n       x = 'Predicted Selling Price',\n       y = 'Actual Selling Price')"
  },
  {
    "objectID": "Introduction.html#exploratory-data-analysis-eda-with-the-tidyverse",
    "href": "Introduction.html#exploratory-data-analysis-eda-with-the-tidyverse",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "Exploratory Data Analysis (EDA) with the Tidyverse",
    "text": "Exploratory Data Analysis (EDA) with the Tidyverse\n\nA hugely important part of any modeling approach is exploratory data analysis. In this course, we’ll be using tidyverse packages for getting to know your data, manipulating it, and visualizing it. The tidyverse is a collection of R packages designed for data science that share common APIs and an underlying philosophy. When you type library(tidyverse), what you’re doing is loading this collection of related packages for handling data using tidy data principles. These packages include ggplot2 for data visualization, and dplyr and tidyr for data manipulation and transformation. During this course, we’ll point out when we use functions from these different packages.\nVisit this page to learn more about tidyverse: https://www.tidyverse.org/learn/"
  },
  {
    "objectID": "Introduction.html#machine-learning-ml-with-tidymodels",
    "href": "Introduction.html#machine-learning-ml-with-tidymodels",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "Machine Learning (ML) with Tidymodels",
    "text": "Machine Learning (ML) with Tidymodels\n\nTidymodels is a collection of R packages that provides a modern and consistent approach to building and validating machine learning models. Compared to older packages such as caret, tidymodels offers several benefits:\n\nit uses a consistent and intuitive syntax across all of its packages, which makes it easier to learn and use compared to the varied and sometimes complex syntax of older packages;\nit is built on top of the tidyverse (dplyr, ggplot2), for a seamless data analysis workflow;\nit includes a number of packages (recipes, rsample) that provide tools for data preprocessing, making it easy to perform common data preprocessing tasks, such as feature engineering, and to integrate these tasks into the machine learning workflow;\nit includes packages (parsnip, tune) that provide a more flexible and modern approach to model tuning and selection. These packages allow for easy cross-validation, hyperparameter tuning, and model selection, and provide a more transparent and reproducible workflow;\nit is actively developed and has a growing community of users and contributors. This means that there are many resources available for learning and troubleshooting, and that the packages are likely to continue to evolve and improve over time.\n\nOverall, tidymodels offers a more modern and consistent approach to building and validating machine learning models, and provides a number of tools for data preprocessing, model tuning and selection, and workflow integration. These features make it a powerful and user-friendly tool."
  },
  {
    "objectID": "Introduction.html#supervised-ml",
    "href": "Introduction.html#supervised-ml",
    "title": "Introduction to Machine Learning with R and tidymodels",
    "section": "Supervised ML",
    "text": "Supervised ML\n\nThe dataset contains a series of inputs, based on which we are trying to predict a predifined outcome, which we know for the original data in the dataset. The outcome can be numerical (in which case the problem is called regression) or categorical (classification).\n\nRegression:\nThink of regression as predicting numbers (or divide the ties by length). You are asking to predict a numerical value given some input. For example:\n\nGiven the house features we want to predict the price. It is a pure numerical and unbounded value (at least positive unbounded);\nTemperature of a city considering several factors (pulling, humidity, season,etc..);\nTo solve this task, the learning algorithm is asked to produce a function so that the model takes an example x as input and after some processing \\(f(x)\\) it returns a value y that can be any real value. \n\n\n\nClassification:\nThink of classification as predicting a category (or divide the socks by color). For example:\n\nGiven a sentence (maybe a tweet) the system should determines if it express a positive or negative or neutral feeling;\nGiven an image where it can be a dog or a cat, we want to determine with the system which one is present;\nTo solve this task, the learning algorithm is usually asked to produce a function \\(y= f(x)\\)\nSo the model takes an example x as input and after some processing \\(f(x)\\) it returns a value y that is one of the categories the example x should belong to. \n\n\n\nData splitting and spending\n\nFor machine learning, we typically split data into training and test sets:\n\nThe training set is used to estimate model parameters;\nThe test set is used to find an independent assessment of model performance.\n\nOnce we have built a ML model we might want to measure its performance, for example the accuracy in classification task (proportion of correct predicted examples) or the average error in a regression task. Our goal is to build a model that is able to really understand the task and that is able to generalize. For this reason we need to separate our dataset into training and testing sets.  The relative proportions of the training and testing set depend on the total of number of observations, and the variability observed in the data. The trade off to be considered is:\n\nif there is too much data in the training set, the assessment of the prediction error will be carried out on a very small test set, therefore we might find a model that fits the existing data very well, but generalizes very poorly;\nif there is too much data in the testing set, this means that we might not have enough data in the training set to accurately estimate the model parameters - so the model won’t be very accurate.\n\nSome commonly used cutoffs include:\n\n60% training / 40% testing\n70% training / 30% testing\n80% training / 20% testing"
  },
  {
    "objectID": "100_dataset1/step2.html#build-a-simple-linear-regression-model-using-base-r",
    "href": "100_dataset1/step2.html#build-a-simple-linear-regression-model-using-base-r",
    "title": "Sydney Informatics Hub",
    "section": "Build a simple linear regression model using base R",
    "text": "Build a simple linear regression model using base R\n\nIn a linear model, we assume that there is a linear relationship between the input variable(s) and the output variable. This means that as the input variable(s) increase or decrease, the output variable changes in a straight line.\nImagine you have a scatter plot with your data points all over it. A linear model is like drawing a straight line through the scatter plot that best fits all the points. The slope and intercept of this line are chosen in such a way that the distance between the line and all the points is minimized. This line is then used to predict the output for new input values.\n\n\nExample of a linear model\n\n\nThe straight red dotted line represents the linear model equation \\(y=mx+c\\), where \\(c\\) is the y-intercept of the regression line, \\(m\\) is the slope of the regression line, and \\(y\\) is the expected value for y for the given \\(x\\) value.\n\n#fit a linear model\names_lm <- lm(Sale_Price ~ Gr_Liv_Area, data = ames_data)\n\n#Print the summary of the model\nsummary(ames_lm)\n\n\nCall:\nlm(formula = Sale_Price ~ Gr_Liv_Area, data = ames_data)\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.94258 -0.06622  0.01359  0.07298  0.39246 \nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 4.835e+00  7.406e-03  652.80   <2e-16 ***\nGr_Liv_Area 2.579e-04  4.714e-06   54.72   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nResidual standard error: 0.124 on 2923 degrees of freedom\nMultiple R-squared:  0.506, Adjusted R-squared:  0.5058 \nF-statistic:  2994 on 1 and 2923 DF,  p-value: < 2.2e-16\n\n\nR-squared value explains the variability of y with respect to x:\n\nvaries between 0 to 1 (0-100%);\nR-squared values closer to 0 mean the regression relationship is very low;\nR-squared values closer to 1 mean the regression relationship is very strong.\n\nLet’s plot our linear regression model:\n\nplot(ames_data$Gr_Liv_Area, ames_data$Sale_Price,\n     xlab=\"Gr_Liv_Area\",\n     ylab=\"Sale_Price\", \n     col = \"blue\")\nabline(ames_lm, col = \"red\")"
  },
  {
    "objectID": "100_dataset1/step2.html#build-a-linear-regression-model-using-tidymodels",
    "href": "100_dataset1/step2.html#build-a-linear-regression-model-using-tidymodels",
    "title": "Sydney Informatics Hub",
    "section": "Build a linear regression model using Tidymodels",
    "text": "Build a linear regression model using Tidymodels\n\nWhen you type library(tidymodels), you load a collection of packages for modeling and machine learning using tidyverse principles. All the packages are designed to be consistent, modular, and to support good modeling practices. The first thing we are going to practice is splitting your data into a training set and a testing set. The tidymodels package rsample has functions that help you specify training and testing sets.\n\nset.seed(42) #so we all get the same results\names_split <- ames_data %>%\n    initial_split(prop = 0.8,\n                  strata = Sale_Price) #stratification\n\names_train <- training(ames_split)\names_test <- testing(ames_split)\n\nsaveRDS(ames_train, \"../_models/ames_train.Rds\")\nsaveRDS(ames_test, \"../_models/ames_test.Rds\")\n\nStratified sampling would split within each quartile: \nThe code here takes an input data set and puts 80% of it into a training dataset and 20% of it into a testing dataset; it chooses the individual cases so that both sets are balanced in selling price.\nLet’s check if the distribution of the selling price is the same in the testing and training datasets:\n\names_train %>% \n  ggplot(aes(x = log(Sale_Price),  col = \"red\", fill = NULL)) + \n  geom_density() + theme_minimal() +\n  geom_line(data = ames_test,\n            stat = \"density\",\n            col = \"blue\") + theme(legend.position=\"none\")\n\n\n\n\nFeature engineering\n\nWe might want to modify our predictors columns for a few reasons:\n\nThe model requires them in a different format;\nThe model needs certain data qualities;\nThe outcome is better predicted when one or more columns are transformed in some way (a.k.a “feature engineering”).\n\n\nIn tidymodels, you can use the recipes package, an extensible framework for pipeable sequences of feature engineering steps that provide preprocessing tools to be applied to data.\n\nSome of these steps can include:\n\nScaling and centering numeric predictors;\nRemoving skewness from numeric variables;\nOne-hot and dummy variable encoding for categorical variables;\nRemoving correlated predictors and zero variance variables;\nImputing missing data.\n\n\nStatistical parameters for the steps can be estimated from an initial data set and then applied to other data sets.\n\n\nThe resulting processed output can be used as inputs for statistical or machine learning models.\n\n\names_rec <-\n  recipe(Sale_Price ~ ., data = ames_train) %>% #assigns columns to roles of “outcome” or “predictor” using the formula\n  step_other(all_nominal(), threshold = 0.01) %>% #useful when you have some factor levels with very few observations, all_nominal selects both characters and factors, pools infrequently occurring values (frequency less than 0.01) into an \"other\" category\n  step_nzv(all_predictors()) %>% #remove predictors that are highly sparse and unbalanced\n  step_center(all_numeric_predictors()) %>% #subtracts the column mean from predictors\n  step_scale(all_numeric_predictors()) %>% #divides by the standard deviation\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% #for any nominal predictor, make binary indicators\n  step_lincomb(all_numeric_predictors()) #remove redundancies in the predictors, if present\n\names_rec\n\nRecipe\nInputs:\n      role #variables\n   outcome          1\n predictor         80\nOperations:\nCollapsing factor levels for all_nominal()\nSparse, unbalanced variable filter on all_predictors()\nCentering for all_numeric_predictors()\nScaling for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nLinear combination filter on all_numeric_predictors()\n\n\nNote that each successive step() function adds a preprocessing step to our recipe object in the order that they are provided. The preprocessing recipe ames_rec has been defined but no values have been estimated.\n\n\nThe prep() function takes that defined object and computes everything so that the preprocessing steps can be executed. Note that This is done with the training data.\n\n\n\names_prep <- prep(ames_rec)\n\names_prep\n\nRecipe\nInputs:\n      role #variables\n   outcome          1\n predictor         80\nTraining data contained 2339 data points and no missing data.\nOperations:\nCollapsing factor levels for MS_SubClass, MS_Zoning, Street, Lot_Shape, Util... [trained]\nSparse, unbalanced variable filter removed Street, Alley, Land_Contour, Utilities,... [trained]\nCentering for Lot_Frontage, Lot_Area, Mas_Vnr_Area, BsmtFin_S... [trained]\nScaling for Lot_Frontage, Lot_Area, Mas_Vnr_Area, BsmtFin_S... [trained]\nDummy variables from MS_SubClass, MS_Zoning, Lot_Shape, Lot_Config, Neighborho... [trained]\nLinear combination filter removed MS_Zoning_other, Lot_Shape_other, Lot_Con... [trained]\n\n\nThe bake() and juice() functions both return data, not a preprocessing recipe object.\n\n\nThe bake() function takes a prepped recipe (one that has had all quantities estimated from training data) and applies it to new_data. That new_data could be the training data again or it could be the testing data (with the TRAINING parameters)\n\n\n\nbake(ames_prep, new_data = ames_test)\n\n# A tibble: 586 × 187\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1        0.675    0.172 -0.569    0.819   0.552 -0.657  -0.388   -0.689  -0.786\n 2        0.705    0.488  0.0527  -1.42   -0.298 -0.347   0.670    0.456  -0.786\n 3        0.916    0.145  1.45    -0.523  -0.298 -0.336   1.92     1.85   -0.786\n 4        0.224   -0.207 -0.569   -0.970  -0.298 -0.632   0.0242  -0.266  -0.786\n 5       -0.949   -0.516 -0.569   -0.523  -0.298 -0.466   0.850    0.477  -0.786\n 6       -1.10    -1.01   2.33     0.819  -0.298 -0.527  -1.33    -1.78    0.392\n 7       -1.10    -1.01   2.26     0.819  -0.298 -0.759  -1.23    -1.67    0.539\n 8       -1.10    -1.01   1.62     1.27   -0.298 -0.0770 -1.23    -1.67    0.539\n 9       -1.01    -0.943 -0.569   -1.42   -0.298 -0.495  -0.452   -0.797   0.618\n10        1.58     0.492  5.74    -0.523  -0.298  2.08    4.26     4.07   -0.786\n# … with 576 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\n\n\n\nThe juice() function is a nice little shortcut. When we juice() the recipe, we squeeze that training data back out, transformed in the ways we specified.\n\n\nLet’s compare the bake() and juice() outputs:\n\nbake(ames_prep, new_data = ames_train)\n\n# A tibble: 2,339 × 187\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       0.374   -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2       0.374    0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3      -0.137   -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4      -1.01    -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5      -0.0770  -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6      -0.227   -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7       0.374   -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8       0.314   -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9      -1.73    -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10      -1.73    -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\njuice(ames_prep) \n\n# A tibble: 2,339 × 187\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       0.374   -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2       0.374    0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3      -0.137   -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4      -1.01    -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5      -0.0770  -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6      -0.227   -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7       0.374   -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8       0.314   -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9      -1.73    -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10      -1.73    -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\n\nNote that the juice() output is the same as bake(ames_rep, new_data = ames_train) and is just a shortcut that we are going to use later.\n\n\n\n\n\n\nChallenge X\n\n\n\nDoes it make sense to apply these preprocessing steps to the test set?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNo, it doesn’t. You want the set test to look like new data that your model will see in the future, so you don’t want to mess with the class balance there; you want to see how your model will perform on imbalanced data, even if you have trained it on artificially balanced data.\n\n\n\nBuild the model\n\nIn tidymodels, you specify models using three concepts.\n\nModel type differentiates models such as logistic regression, decision tree models, and so forth;\nModel mode includes common options like regression and classification, some model types support either of these while some only have one mode;\nModel engine is the computational tool which will be used to fit the model.\n\nWe will specify the model using the parsnip package - Many functions have different interfaces and arguments names and parsnip standardizes the interface for fitting models as well as the return values.\n\n#a linear regression model specification\names_model <- linear_reg() %>% #pick a model\n  set_engine(\"lm\")           #set the engine\n                             #set_mode(\"regression\") we don't need this as the model linear_reg() only does regression\n\n#view model properties\names_model\n\nLinear Regression Model Specification (regression)\nComputational engine: lm \n\n\nNow we are ready to train our model object on the training data. We can do this using the fit() function from the parsnip package. The fit() function takes the following arguments:\n\na parnsip model object specification;\na model formula\na data frame with the training data\n\nThe code below trains our linear regression model on the prepped training data. In our formula, we have specified that Sale_Price is the response variable and included all the rest as our predictor variables.\n\names_fit <- ames_model %>%\n  fit(Sale_Price ~ .,\n      data=juice(ames_prep))\n\n# View lm_fit properties\names_fit\n\nparsnip model object\nCall:\nstats::lm(formula = Sale_Price ~ ., data = data)\nCoefficients:\n                                          (Intercept)  \n                                            4.225e+00  \n                                         Lot_Frontage  \n                                            1.510e-03  \n                                             Lot_Area  \n                                            5.634e-03  \n                                         Mas_Vnr_Area  \n                                            3.178e-03  \n                                         BsmtFin_SF_1  \n                                            2.910e-02  \n                                         BsmtFin_SF_2  \n                                           -2.438e-03  \n                                          Bsmt_Unf_SF  \n                                           -9.865e-03  \n                                        Total_Bsmt_SF  \n                                            3.052e-02  \n                                         First_Flr_SF  \n                                            4.657e-03  \n                                        Second_Flr_SF  \n                                            9.635e-03  \n                                          Gr_Liv_Area  \n                                            4.895e-02  \n                                       Bsmt_Full_Bath  \n                                            4.946e-03  \n                                       Bsmt_Half_Bath  \n                                            1.160e-03  \n                                            Full_Bath  \n                                            7.528e-03  \n                                            Half_Bath  \n                                            6.568e-03  \n                                        Bedroom_AbvGr  \n                                           -3.780e-03  \n                                        TotRms_AbvGrd  \n                                           -4.477e-05  \n                                           Fireplaces  \n                                            5.691e-03  \n                                          Garage_Cars  \n                                            8.626e-03  \n                                          Garage_Area  \n                                            6.286e-03  \n                                         Wood_Deck_SF  \n                                            1.943e-03  \n                                        Open_Porch_SF  \n                                            1.901e-03  \n                                              Mo_Sold  \n                                           -3.097e-04  \n                                            Year_Sold  \n                                           -2.016e-03  \n                                            Longitude  \n                                           -8.325e-03  \n                                             Latitude  \n                                           -4.980e-03  \n                                   Time_Since_Remodel  \n                                           -5.556e-03  \n                                            House_Age  \n                                           -1.929e-02  \n      MS_SubClass_One_Story_1946_and_Newer_All_Styles  \n                                            6.196e-03  \n                 MS_SubClass_One_Story_1945_and_Older  \n                                           -2.177e-02  \n     MS_SubClass_One_and_Half_Story_Finished_All_Ages  \n                                            2.813e-02  \n                 MS_SubClass_Two_Story_1946_and_Newer  \n                                           -1.093e-02  \n                 MS_SubClass_Two_Story_1945_and_Older  \n                                            1.847e-02  \n                      MS_SubClass_Split_or_Multilevel  \n                                           -2.027e-02  \n                              MS_SubClass_Split_Foyer  \n                                            3.816e-03  \n               MS_SubClass_Duplex_All_Styles_and_Ages  \n                                           -2.177e-03  \n             MS_SubClass_One_Story_PUD_1946_and_Newer  \n                                            2.046e-02  \n             MS_SubClass_Two_Story_PUD_1946_and_Newer  \n                                           -2.533e-02  \nMS_SubClass_Two_Family_conversion_All_Styles_and_Ages  \n                                            2.991e-03  \n                                    MS_SubClass_other  \n                                                   NA  \n               MS_Zoning_Floating_Village_Residential  \n                                            3.984e-02  \n                    MS_Zoning_Residential_Low_Density  \n                                            3.224e-02  \n                 MS_Zoning_Residential_Medium_Density  \n                                            2.443e-02  \n                                    Lot_Shape_Regular  \n                                            4.462e-03  \n                         Lot_Shape_Slightly_Irregular  \n                                            4.294e-03  \n                       Lot_Shape_Moderately_Irregular  \n                                            1.805e-02  \n                                    Lot_Config_Corner  \n                                            5.998e-03  \n                                   Lot_Config_CulDSac  \n                                            1.298e-02  \n                                       Lot_Config_FR2  \n                                           -5.176e-03  \n                                    Lot_Config_Inside  \n                                            3.934e-03  \n                              Neighborhood_North_Ames  \n                                           -1.547e-02  \n                           Neighborhood_College_Creek  \n                                           -3.736e-02  \n                                Neighborhood_Old_Town  \n                                           -3.894e-02  \n                                 Neighborhood_Edwards  \n                                           -4.494e-02  \n                                Neighborhood_Somerset  \n                                            1.495e-02  \n                      Neighborhood_Northridge_Heights  \n                                            1.344e-02  \n                                 Neighborhood_Gilbert  \n                                           -8.690e-03  \n                                  Neighborhood_Sawyer  \n                                           -2.252e-02  \n                          Neighborhood_Northwest_Ames  \n                                           -1.568e-02  \n                             Neighborhood_Sawyer_West  \n                                           -3.405e-02  \n                                Neighborhood_Mitchell  \n                                           -2.449e-02  \n                               Neighborhood_Brookside  \n                                           -1.037e-02  \n                                Neighborhood_Crawford  \n                                            1.911e-02  \n                  Neighborhood_Iowa_DOT_and_Rail_Road  \n                                           -4.515e-02  \n                              Neighborhood_Timberland  \n                                           -2.225e-02  \n                              Neighborhood_Northridge  \n                                            1.195e-02  \n                             Neighborhood_Stone_Brook  \n                                            3.834e-02  \n Neighborhood_South_and_West_of_Iowa_State_University  \n                                           -3.175e-02  \n                             Neighborhood_Clear_Creek  \n                                           -1.395e-02  \n                          Neighborhood_Meadow_Village  \n                                           -6.325e-02  \n                                   Condition_1_Artery  \n                                           -1.792e-02  \n                                    Condition_1_Feedr  \n                                           -1.227e-02  \n                                     Condition_1_Norm  \n                                            6.575e-03  \n                                     Condition_1_PosN  \n                                            1.180e-02  \n                                     Condition_1_RRAn  \n                                           -1.178e-02  \n                                     Bldg_Type_OneFam  \n                                            3.635e-02  \n                                   Bldg_Type_TwoFmCon  \n                                            2.470e-02  \n                                      Bldg_Type_Twnhs  \n                                           -1.657e-02  \n                         House_Style_One_and_Half_Fin  \n                                           -3.279e-02  \n                                House_Style_One_Story  \n                                           -9.496e-03  \n                                   House_Style_SFoyer  \n                                            5.423e-04  \n                                     House_Style_SLvl  \n                                            1.420e-02  \n                                House_Style_Two_Story  \n                                           -8.472e-03  \n                                    Overall_Qual_Fair  \n                                           -9.709e-03  \n                           Overall_Qual_Below_Average  \n                                           -7.711e-03  \n                                 Overall_Qual_Average  \n                                            1.465e-02  \n                           Overall_Qual_Above_Average  \n                                            2.453e-02  \n                                    Overall_Qual_Good  \n                                            3.288e-02  \n                               Overall_Qual_Very_Good  \n                                            5.065e-02  \n                               Overall_Qual_Excellent  \n                                            5.328e-02  \n                                    Overall_Cond_Fair  \n                                            8.424e-02  \n                           Overall_Cond_Below_Average  \n                                            1.386e-01  \n                                 Overall_Cond_Average  \n                                            1.647e-01  \n                           Overall_Cond_Above_Average  \n                                            1.786e-01  \n                                    Overall_Cond_Good  \n                                            1.976e-01  \n                               Overall_Cond_Very_Good  \n                                            2.004e-01  \n                               Overall_Cond_Excellent  \n                                            2.172e-01  \n                                     Roof_Style_Gable  \n                                            3.064e-03  \n                                       Roof_Style_Hip  \n                                            1.400e-03  \n                                 Exterior_1st_AsbShng  \n                                           -2.269e-02  \n                                 Exterior_1st_BrkFace  \n                                            1.762e-02  \n                                 Exterior_1st_CemntBd  \n                                           -6.648e-02  \n                                 Exterior_1st_HdBoard  \n                                           -2.029e-02  \n                                 Exterior_1st_MetalSd  \n                                           -9.188e-03  \n                                 Exterior_1st_Plywood  \n                                           -1.778e-02  \n                                  Exterior_1st_Stucco  \n                                           -2.030e-02  \n                                 Exterior_1st_VinylSd  \n                                           -3.227e-02  \n                                 Exterior_1st_Wd.Sdng  \n                                           -1.530e-02  \n                                 Exterior_1st_WdShing  \n                                           -2.727e-02  \n                                 Exterior_2nd_AsbShng  \n                                           -2.730e-02  \n                                 Exterior_2nd_BrkFace  \n                                           -2.295e-02  \n                                 Exterior_2nd_CmentBd  \n                                            4.882e-02  \n                                 Exterior_2nd_HdBoard  \n                                           -5.905e-03  \n                                 Exterior_2nd_MetalSd  \n                                           -5.823e-03  \n                                 Exterior_2nd_Plywood  \n                                           -7.550e-03  \n                                  Exterior_2nd_Stucco  \n                                            7.010e-03  \n                                 Exterior_2nd_VinylSd  \n                                            9.093e-03  \n                                 Exterior_2nd_Wd.Sdng  \n                                           -3.418e-03  \n                                 Exterior_2nd_Wd.Shng  \n                                            3.114e-03  \n                                 Mas_Vnr_Type_BrkFace  \n                                            1.391e-02  \n                                    Mas_Vnr_Type_None  \n                                            1.470e-02  \n                                   Mas_Vnr_Type_Stone  \n                                            2.233e-02  \n                                 Exter_Qual_Excellent  \n                                            4.355e-02  \n                                      Exter_Qual_Fair  \n                                           -1.018e-02  \n                                      Exter_Qual_Good  \n                                            7.081e-03  \n                                      Exter_Cond_Fair  \n                                           -5.441e-02  \n                                      Exter_Cond_Good  \n                                           -2.790e-02  \n                                   Exter_Cond_Typical  \n                                           -2.038e-02  \n                                    Foundation_BrkTil  \n                                           -2.178e-02  \n                                    Foundation_CBlock  \n                                           -1.965e-02  \n                                     Foundation_PConc  \n                                           -1.085e-02  \n                                      Foundation_Slab  \n                                            6.116e-05  \n                                  Bsmt_Qual_Excellent  \n                                            3.459e-02  \n                                       Bsmt_Qual_Fair  \n                                            6.404e-03  \n                                       Bsmt_Qual_Good  \n                                            2.045e-02  \n                                Bsmt_Qual_No_Basement  \n                                            2.428e-02  \n                                    Bsmt_Qual_Typical  \n                                            1.874e-02  \n                                     Bsmt_Exposure_Av  \n                                            3.624e-03  \n                                     Bsmt_Exposure_Gd  \n                                            2.669e-02  \n                                     Bsmt_Exposure_Mn  \n                                            5.688e-05  \n                                     Bsmt_Exposure_No  \n                                           -4.150e-03  \n                                   BsmtFin_Type_1_ALQ  \n                                            8.386e-02  \n                                   BsmtFin_Type_1_BLQ  \n                                            6.682e-02  \n                                   BsmtFin_Type_1_GLQ  \n                                            5.941e-02  \n                                   BsmtFin_Type_1_LwQ  \n                                            3.318e-02  \n                                   BsmtFin_Type_1_Rec  \n                                            7.956e-03  \n                                 Heating_QC_Excellent  \n                                            7.722e-01  \n                                      Heating_QC_Fair  \n                                            7.472e-01  \n                                      Heating_QC_Good  \n                                            7.654e-01  \n                                   Heating_QC_Typical  \n                                            7.598e-01  \n                                        Central_Air_N  \n                                           -2.408e-02  \n                                     Electrical_FuseA  \n                                           -1.545e-02  \n                                     Electrical_FuseF  \n                                           -1.968e-02  \n                                     Electrical_SBrkr  \n                                           -1.951e-02  \n                               Kitchen_Qual_Excellent  \n                                            3.178e-02  \n                                    Kitchen_Qual_Fair  \n                                           -3.273e-03  \n                                    Kitchen_Qual_Good  \n                                            5.608e-03  \n                               Fireplace_Qu_Excellent  \n                                           -1.090e-02  \n                                    Fireplace_Qu_Fair  \n                                           -5.742e-03  \n                                    Fireplace_Qu_Good  \n                                            3.799e-03  \n                            Fireplace_Qu_No_Fireplace  \n                                           -2.870e-03  \n                                    Fireplace_Qu_Poor  \n                                           -8.559e-03  \n                                   Garage_Type_Attchd  \n                                            2.717e-02  \n                                  Garage_Type_Basment  \n                                            1.841e-02  \n                                  Garage_Type_BuiltIn  \n                                            2.514e-02  \n                                   Garage_Type_Detchd  \n                                            2.309e-02  \n                                Garage_Type_No_Garage  \n                                            4.121e-04  \n                                    Garage_Finish_Fin  \n                                            9.351e-04  \n                              Garage_Finish_No_Garage  \n                                           -5.710e-03  \n                                    Garage_Finish_RFn  \n                                           -2.171e-03  \n                                     Garage_Qual_Fair  \n                                           -2.731e-02  \n                                  Garage_Qual_Typical  \n                                           -1.877e-02  \n                                     Garage_Cond_Fair  \n                                           -2.552e-02  \n                                  Garage_Cond_Typical  \n                                           -1.678e-03  \n                              Paved_Drive_Dirt_Gravel  \n                                           -4.599e-03  \n                         Paved_Drive_Partial_Pavement  \n                                           -7.736e-03  \n                                   Fence_Good_Privacy  \n                                           -4.646e-03  \n                                      Fence_Good_Wood  \n                                           -1.104e-02  \n                                Fence_Minimum_Privacy  \n                                           -1.837e-03  \n                                       Fence_No_Fence  \n                                           -3.494e-03  \n                                        Sale_Type_COD  \n                                           -1.792e-02  \n                                        Sale_Type_New  \n                                            1.829e-02  \n                                        Sale_Type_WD.  \n                                           -1.673e-02  \n                               Sale_Condition_Abnorml  \n                                           -4.424e-02  \n                                Sale_Condition_Family  \n                                           -2.159e-02  \n                                Sale_Condition_Normal  \n                                           -1.563e-03  \n                               Sale_Condition_Partial  \n                                           -2.112e-02  \n\n\nTo obtain the detailed results from our trained linear regression model in a data frame, we can use the tidy() and glance() functions directly on our trained parsnip model, ames_fit. - The tidy() function takes a linear regression object and returns a data frame of the estimated model coefficients and their associated F-statistics and p-values; - The glance() function will return performance metrics obtained on the training data such as the R2 value (r.squared) and the RMSE (sigma). - We can also use the vip() function to plot the variable importance for each predictor in our model. The importance value is determined based on the F-statistics and estimate coefficents in our trained model object.\n\n# Data frame of estimated coefficients\ntidy(ames_fit)\n\n# A tibble: 187 × 5\n   term          estimate std.error statistic   p.value\n   <chr>            <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)    4.22      0.0965     43.8   8.49e-300\n 2 Lot_Frontage   0.00151   0.00121     1.24  2.14e-  1\n 3 Lot_Area       0.00563   0.00129     4.35  1.42e-  5\n 4 Mas_Vnr_Area   0.00318   0.00168     1.89  5.90e-  2\n 5 BsmtFin_SF_1   0.0291    0.0248      1.17  2.41e-  1\n 6 BsmtFin_SF_2  -0.00244   0.00119    -2.05  4.03e-  2\n 7 Bsmt_Unf_SF   -0.00986   0.00209    -4.71  2.61e-  6\n 8 Total_Bsmt_SF  0.0305    0.00326     9.36  2.01e- 20\n 9 First_Flr_SF   0.00466   0.00910     0.512 6.09e-  1\n10 Second_Flr_SF  0.00963   0.0100      0.960 3.37e-  1\n# … with 177 more rows\n\n# Performance metrics on training data\nglance(ames_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.sq…¹  sigma stati…² p.value    df logLik    AIC    BIC devia…³\n      <dbl>      <dbl>  <dbl>   <dbl>   <dbl> <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n1     0.934      0.928 0.0479    164.       0   185  3884. -7395. -6318.    4.94\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\n# Plot variable importance\nvip(ames_fit)\n\n\n\n\nEvaluating the model\n\nTo assess the accuracy of our trained linear regression model, ames_fit, we must use it to make predictions on our test data, ames_test_proc. This is done with the predict() function from parnsip. This function takes two important arguments:\n\na trained parnsip model object;\nnew_data for which to generate predictions.\n\nThe code below uses the predict() function to generate a data frame with a single column, .pred, which contains the predicted Sale Price values on the ames_train data.\n\npredict(ames_fit, new_data = juice(ames_prep))\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 2,339 × 1\n   .pred\n   <dbl>\n 1  5.09\n 2  5.01\n 3  5.13\n 4  5.06\n 5  5.08\n 6  5.07\n 7  4.90\n 8  5.10\n 9  5.06\n10  5.16\n# … with 2,329 more rows\n\n\nGenerally it’s best to combine the test data set and the predictions into a single data frame. We create a data frame with the predictions on the ames_test data and then use bind_cols() to add the ames_test data to the results.\n\names_train_results <- predict(ames_fit, new_data = juice(ames_prep)) %>% \n  bind_cols(juice(ames_prep))\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n# View results\names_train_results\n\n# A tibble: 2,339 × 188\n   .pred Lot_F…¹ Lot_A…² Mas_V…³ BsmtF…⁴ BsmtF…⁵ Bsmt_…⁶ Total…⁷ First…⁸ Secon…⁹\n   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  5.09  0.374  -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2  5.01  0.374   0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3  5.13 -0.137  -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4  5.06 -1.01   -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5  5.08 -0.0770 -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6  5.07 -0.227  -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7  4.90  0.374  -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8  5.10  0.314  -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9  5.06 -1.73   -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10  5.16 -1.73   -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\n\nNow we have the model results and the training data in a single data frame.\nMetrics for model performance\n\n\n\n\nR-squared (rsq): squared correlation between the predicted and observed values;\n\nRoot Mean Square Error (RMSE): difference between the predicted and observed values (loss of function);\n\n\nTo obtain the rmse and rsq values on our test set results, we can use the rmse() and rsq() functions. Both functions take the following arguments:\n\na data frame with columns that have the true values and predictions;\nthe column with the true response values;\nthe column with predicted values.\n\nIn the examples below we pass our ames_test_results to these functions to obtain these values for our test set. Results are always returned as a data frame with the following columns: .metric, .estimator, and .estimate.\n\n#RMSE on train set\ntrain_rmse <- rmse(ames_train_results, \n     truth = Sale_Price,\n     estimate = .pred)\n\n#rsq on train set\ntrain_rsq<- rsq(ames_train_results,\n    truth = Sale_Price,\n    estimate = .pred)\n\n\n\n\n\n\n\nChallenge X\n\n\n\nWe mentioned earlier that the bake() function takes a prepped recipe (ames_prep) and applies it to new_data. The new_data could be the training data again or it could be the testing data. We just evaluated our model on the training data, let’s try to apply the bake() and predict() functions on the test data and compare the results.\nInstructions\n\n#bake() test data\n\n#predict() selling price on the test data\n\n#combine the test data set and the predictions into a single data frame\n\n#RMSE on test set\n\n#rsq on test set\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#bake() test data\names_test_proc <- bake(ames_prep, new_data = ames_test)\n#predict() selling price on the test data\names_test_results <-predict(ames_fit, new_data = ames_test_proc)\n#combine the training data set and the predictions into a single data frame\names_test_results <- ames_test_results %>%\n  bind_cols(ames_test_proc)\n#RMSE on training set\ntest_rmse <- rmse(ames_test_results, \n     truth = Sale_Price,\n     estimate = .pred)\n#rsq on training set\ntest_rsq <- rsq(ames_test_results,\n    truth = Sale_Price,\n    estimate = .pred)\n\n\n\n\nLet’s have a look at all the metrics for both our training and test datasets:\n\n#plot metrics for training and test datasets\ntrain_rsq %>%\n  mutate(dataset = \"training\") %>%\n  bind_rows(train_rmse %>%\n              mutate(dataset = \"training\")) %>%\n  bind_rows(test_rsq %>%\n              mutate(dataset = \"test\") %>%\n              bind_rows(test_rmse %>%\n                          mutate(dataset = \"test\")))\n\n# A tibble: 4 × 4\n  .metric .estimator .estimate dataset \n  <chr>   <chr>          <dbl> <chr>   \n1 rsq     standard      0.934  training\n2 rmse    standard      0.0460 training\n3 rsq     standard      0.858  test    \n4 rmse    standard      0.0656 test    \n\n\nLet’s visualise the situation with an R2 plot:\n\names_test_results %>%\n  mutate(train = \"testing\") %>%\n  bind_rows(ames_train_results %>%\n              mutate(train = \"training\")) %>%\n  ggplot(aes(Sale_Price, .pred, color = train)) +\n  geom_abline(intercept = 0, slope = 1, color = \"black\", linewidth = 0.5, linetype=\"dotted\") +\n  geom_point(alpha = 0.15) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Actual Selling Price\",\n    y = \"Predicted Selling Price\",\n    color = \"Test/Training data\"\n  )\n\n\n\n\nThis is a plot that can be used for any regression model. It plots the actual values (Sale Prices) versus the model predictions (.pred) as a scatter plot. It also plot the line y = x through the origin. This line is a visually representation of the perfect model where all predicted values are equal to the true values in the test set. The farther the points are from this line, the worse the model fit. The reason this plot is called an R2 plot, is because the R2 is the squared correlation between the true and predicted values, which are plotted as paired in the plot.\nResampling\n\nYou just trained models one time on the whole training set and then evaluated them on the testing set. Statisticians have come up with a slew of approaches to evaluate models in better ways than this; many important ones fall under the category of resampling.\nWe can resample the training set to produce an estimate of how the model will perform.The idea of resampling is to create simulated data sets that can be used to estimate the performance of your model, say, because you want to compare models. You can create these resampled data sets instead of using either your training set (which can give overly optimistic results, especially for powerful ML algorithms) or your testing set (which is extremely valuable and can only be used once or at most twice). One of these resampling methods is cross-validation.\nCross-validation means taking your training set and randomly dividing it up evenly into subsets, sometimes called “folds”. A fold here means a group or subset or partition.\nYou use one of the folds for validation and the rest for training, then you repeat these steps with all the subsets and combine the results, usually by taking the mean. Cross-validation allows you to get a more accurate estimate of how your model will perform on new data.\n\n\n\n\n\n\nChallenge X\n\n\n\nWhen you implement 10-fold cross-validation repeated 5 times, you:\n\nrandomly divide your training data into 50 subsets and train on 49 at a time (assessing on the other subset), iterating through all 50 subsets for assessment.\nrandomly divide your training data into 10 subsets and train on 9 at a time (assessing on the other subset), iterating through all 10 subsets for assessment. Then you repeat that process 5 times.\nrandomly divide your training data into 5 subsets and train on 4 at a time (assessing on the other subset), iterating through all 5 subsets. Then you repeat that process 10 times.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimulations and practical experience show that 10-fold cross-validation repeated 5 times is a great resampling approach for many situations. This approach involves randomly dividing your training data into 10 folds, or subsets or groups, and training on only 9 while using the other fold for assessment. You iterate through all 10 folds being used for assessment; this is one round of cross-validation. You can then repeat the whole process multiple, perhaps 5, times.\n\n\n\n\nset.seed(9)\n\names_folds <- vfold_cv(ames_train, v=10, repeats = 5, strata = Sale_Price)\n\nglimpse(ames_folds)\n\nRows: 50\nColumns: 3\n$ splits <list> [<vfold_split[2103 x 236 x 2339 x 81]>], [<vfold_split[2103 x …\n$ id     <chr> \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1…\n$ id2    <chr> \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06\", \"Fo…\n\n\nIn the next steps, we won’t not use prep() or bake(). The ames_rec recipe will be automatically applied in a later step using the workflow() and last_fit() functions.\nCreate a Workflow\n\nIn the previous section, we trained a linear regression model to the housing data step-by-step. In this section, we will go over how to combine all of the modeling steps into a single workflow.\nThe workflow package was designed to capture the entire modeling process and combine models and recipes into a single object. To create a workflow, we start with workflow() to create an empty workflow and then add out model and recipe with add_model() and add_recipe().\n\names_wf <- workflow() %>%\n  add_model(ames_model) %>% \n  add_recipe(ames_rec)\n\names_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n• step_other()\n• step_nzv()\n• step_center()\n• step_scale()\n• step_dummy()\n• step_lincomb()\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\nComputational engine: lm \n\n\nOnce we have created a set of resamples, we can use the function fit_resamples() to fit a model to each resample and compute performance metrics for each.\n\nset.seed(234)\names_res <- ames_wf %>%\n  fit_resamples(\n    ames_folds,\n    control = control_resamples(save_pred = TRUE)\n  )\n\n! Fold01, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\nglimpse(ames_res)\n\nRows: 50\nColumns: 6\n$ splits       <list> [<vfold_split[2103 x 236 x 2339 x 81]>], [<vfold_split[2…\n$ id           <chr> \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"R…\n$ id2          <chr> \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06…\n$ .metrics     <list> [<tbl_df[2 x 4]>], [<tbl_df[2 x 4]>], [<tbl_df[2 x 4]>],…\n$ .notes       <list> [<tbl_df[1 x 3]>], [<tbl_df[1 x 3]>], [<tbl_df[1 x 3]>],…\n$ .predictions <list> [<tbl_df[236 x 4]>], [<tbl_df[236 x 4]>], [<tbl_df[236 x…\n\nsaveRDS(ames_res, \"../_models/ames_res.rds\")\n\nThe column .metric contains the performance statistics created from the 10 assessment sets. These can be manually unnested but the tune package contains a number of simple functions that can extract these data:\n\n# Obtain performance metrics on resampled training data\names_res %>% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.0540    50 0.00129 Preprocessor1_Model1\n2 rsq     standard   0.909     50 0.00368 Preprocessor1_Model1\n\n\n\n\nvfold_cv() creates folds for cross-validation;\n\nfit_resamples() fits models to resamples;\n\ncollect_metrics() obtains performance metrics from the results.\n\nWe can see that the regression relationship is very strong: 90.8% of the variability in the selling price can be explained by the predictors and, on average, each element in the predicted selling price differs from the actual selling price by 0.05.\nWe can reliably measure performance using only the training data.\nIf we wanted to try different model types for this data set, we could more confidently compare performance metrics computed using resampling to choose between models. Also, remember that at the end of our project, we return to our test set to estimate final model performance.\n\names_res %>%\n  collect_predictions() %>%\n  ggplot(aes(Sale_Price, .pred, color = id)) + \n  geom_abline(lty = 2, col = \"gray\", linewidth = 1.5) +\n  geom_point(alpha = 0.15) +\n  coord_obs_pred()\n\n\n\n\nBack to the testing data\n\nLet’s use the last_fit() function to evaluate once on the testing set:\n\n#Final fit on test dataset\names_final <- ames_wf %>%\n  last_fit(ames_split)\n\n! train/test split: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n# Obtain performance metrics on test data\ncollect_metrics(ames_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard      0.0656 Preprocessor1_Model1\n2 rsq     standard      0.858  Preprocessor1_Model1\n\n\nThe R2 and RMSE metrics are similar for both the training and testing datasets in our linear regression model. This is a good sign that the model is not over-fitting and can be used for making predictions on new data.\nWe can save the test set predictions by using the collect_predictions() function. This function returns a data frame which will have the response variables values from the test set and a column named .pred with the model predictions.\n\n# Obtain test set predictions data frame\names_results_final <- ames_final %>% \n                 collect_predictions()\n# View results\names_results_final\n\n# A tibble: 586 × 5\n   id               .pred  .row Sale_Price .config             \n   <chr>            <dbl> <int>      <dbl> <chr>               \n 1 train/test split  5.03     2       5.02 Preprocessor1_Model1\n 2 train/test split  5.19     3       5.24 Preprocessor1_Model1\n 3 train/test split  5.39    18       5.60 Preprocessor1_Model1\n 4 train/test split  5.13    26       5.15 Preprocessor1_Model1\n 5 train/test split  5.23    29       5.26 Preprocessor1_Model1\n 6 train/test split  4.99    30       4.98 Preprocessor1_Model1\n 7 train/test split  4.99    31       5.02 Preprocessor1_Model1\n 8 train/test split  4.98    32       4.94 Preprocessor1_Model1\n 9 train/test split  5.14    34       5.18 Preprocessor1_Model1\n10 train/test split  5.77    47       5.70 Preprocessor1_Model1\n# … with 576 more rows\n\n\nFinally, let’s use this data frame to make an R2 plot to visualize our model performance on the test data set:\n\nggplot(data = ames_results_final,\n       mapping = aes(x = .pred, y = Sale_Price)) +\n  geom_point(color = '#006EA1', alpha = 0.25) +\n  geom_abline(intercept = 0, slope = 1, color = 'black', linewidth=0.5, linetype=\"dotted\") +\n  labs(title = 'Linear Regression Results - Ames Test Set',\n       x = 'Predicted Selling Price',\n       y = 'Actual Selling Price')"
  },
  {
    "objectID": "100_dataset1/step1.html#feature-transformation",
    "href": "100_dataset1/step1.html#feature-transformation",
    "title": "Sydney Informatics Hub",
    "section": "Feature transformation",
    "text": "Feature transformation\n\nThe year in which the house was built and the year when it was remodelled are not really the most relevant parameters we look at when buying a house: instead, buyers usually care a lot more about the age of the house and the time since the last remodel. Let’s transform these features:\n\nameshousing_filt_engineered <-\n  ameshousing_filt %>%\n  mutate(Time_Since_Remodel = Year_Sold - Year_Remod_Add, \n         House_Age = Year_Sold - Year_Built) %>%\n  select(-Year_Remod_Add, -Year_Built)\n\nsaveRDS(ameshousing_filt_engineered, \"../_models/ames_dataset_filt.rds\")\n\n\nNote Make sure to create a “models” folder in your project working directory! Before you can save your data as .Rds objects, you will actually need to create a folder for these files to go into. Do this by clicking on the “new folder” button in the files window in R studio. Rename your new folder to “models”."
  },
  {
    "objectID": "200_dataset2/step1.html#pima-indians-diabetes",
    "href": "200_dataset2/step1.html#pima-indians-diabetes",
    "title": "Sydney Informatics Hub",
    "section": "Pima Indians Diabetes",
    "text": "Pima Indians Diabetes\n\nToday, we are going to be working with Pima Indian Women’s diabetes dataset which contains information on 768 Pima Indian women’s diabetes status, as well as many predictive features:\n\npregnant - Number of times pregnant\nglucose - Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\npressure - Diastolic blood pressure (mm Hg)\ntriceps - Triceps skin fold thickness (mm) - a measure correlated with body fat\n\ninsulin - 2-Hour serum insulin (mu U/ml)\nmass - Body mass index (weight in kg/(height in m)^2)\nage - Age (years)\ndiabetes - diabetes status (pos - diabetic; neg - non-diabetic)\npedigree - diabetes pedigree function\n\nThe diabetes pedigree function was developed by Smith 1988 to provide a synthesis ofthe diabetes mellitus history in relatives and the genetic relationship of those relatives to the subject. It uses information from parents, grandparents, siblings, aunts and uncles, and first cousin to provide a measure of the expected genetic influence of affected and unaffected relatives on the subject’s eventual diabetes risk.\nThe Pima Indians are a group of Native Americans living in an area consisting of what is now central and southern Arizona. The short name, “Pima” is believed to have come from a phrase meaning “I don’t know,” which they used repeatedly in their initial meetings with Spanish colonists. Thanks Wikipedia!\nLet’s Explore our data\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggcorrplot)\nlibrary(GGally)\ntheme_set(theme_minimal())\n\nLoad data:\n\n# load the Pima Indians dataset from the mlbench dataset\nlibrary(mlbench)\ndata(PimaIndiansDiabetes)\n# rename dataset to have shorter name because lazy\ndiabetes_data <- PimaIndiansDiabetes\n# look at the variable names\nnames(diabetes_data)\n\n[1] \"pregnant\" \"glucose\"  \"pressure\" \"triceps\"  \"insulin\"  \"mass\"     \"pedigree\"\n[8] \"age\"      \"diabetes\"\n\n# look at the data\nglimpse(diabetes_data)\n\nRows: 768\nColumns: 9\n$ pregnant <dbl> 6, 1, 8, 1, 0, 5, 3, 10, 2, 8, 4, 10, 10, 1, 5, 7, 0, 7, 1, 1…\n$ glucose  <dbl> 148, 85, 183, 89, 137, 116, 78, 115, 197, 125, 110, 168, 139,…\n$ pressure <dbl> 72, 66, 64, 66, 40, 74, 50, 0, 70, 96, 92, 74, 80, 60, 72, 0,…\n$ triceps  <dbl> 35, 29, 0, 23, 35, 0, 32, 0, 45, 0, 0, 0, 0, 23, 19, 0, 47, 0…\n$ insulin  <dbl> 0, 0, 0, 94, 168, 0, 88, 0, 543, 0, 0, 0, 0, 846, 175, 0, 230…\n$ mass     <dbl> 33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.5, 0.0, 37…\n$ pedigree <dbl> 0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.134, 0.158…\n$ age      <dbl> 50, 31, 32, 21, 33, 30, 26, 29, 53, 54, 30, 34, 57, 59, 51, 3…\n$ diabetes <fct> pos, neg, pos, neg, pos, neg, pos, neg, pos, pos, neg, pos, n…\n\n\nLook for missing data:\n\nanyNA(diabetes_data)\n\n[1] FALSE\n\n\nIt seems like there is no missing data.\nGet a summary of the data frame:\n\nsummary(diabetes_data)\n\n    pregnant         glucose         pressure         triceps     \n Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  \n 1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  \n Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  \n Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  \n 3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  \n Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  \n    insulin           mass          pedigree           age        diabetes \n Min.   :  0.0   Min.   : 0.00   Min.   :0.0780   Min.   :21.00   neg:500  \n 1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437   1st Qu.:24.00   pos:268  \n Median : 30.5   Median :32.00   Median :0.3725   Median :29.00            \n Mean   : 79.8   Mean   :31.99   Mean   :0.4719   Mean   :33.24            \n 3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262   3rd Qu.:41.00            \n Max.   :846.0   Max.   :67.10   Max.   :2.4200   Max.   :81.00            \n\n\n\n\n\n\n\n\nExercise:\n\n\n\nLook at the output of summary above and the table that explains what each of the variables are. Do the values make sense for all of: - (a) Pregnancies and Glucose - (b) Blood pressure and Skin thickness - (c) Insulin and DiabetesPedigreeFunction, and - (d) BMI and Age\nIf not, how do you think we should deal with them? Can you hypothesise what the consequences of this approach would be?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#Possibly missing: \n\ncolSums(diabetes_data == 0)\n\npregnant  glucose pressure  triceps  insulin     mass pedigree      age \n     111        5       35      227      374       11        0        0 \ndiabetes \n       0 \n\n#Not missing:\n\ncolSums(diabetes_data != 0)\n\npregnant  glucose pressure  triceps  insulin     mass pedigree      age \n     657      763      733      541      394      757      768      768 \ndiabetes \n     768 \n\n\nIt is clear that the values of several variables are zero when it is impossible for them to be so (i.e. this value could not be zero if it was measured). Hence, we are dealing with “hidden” missing data, and should recode it as NA.\nThe following variables have zero “values” that are actually likely to be missing:\n\nGlucose (a)\nBloodPressure (b)\nSkinThickness (b)\nInsulin (c)\nBMI (d)\n\n\n\n\nLet’s use visualisation to further explore the dataset\n\n\nggplot(diabetes_data, aes(x = pregnant, fill = diabetes)) + geom_bar(position = \"dodge\")\n\n\n\n\n\nggplot(\n  diabetes_data,\n  aes(\n    x = pressure,\n    y = glucose,\n    color = diabetes\n  )\n) + geom_point(alpha = 0.5)\n\n\n\n\nIf we wanted to look at all possible scatterplot pairs we would do something like:\n\n# make a pair plot\nggpairs(data = diabetes_data, \n        mapping = aes(color = diabetes),\n        upper = list(combo = \"box\"))\n\n\n\n\nBut it’s easier to look at a correlation plot:\n\n# get a correlation matrix of the variables in the diabetes dataset:\ndiabetes_corr <- diabetes_data %>%\n  # recode outcome to be numeric (subtract 1 to return it to zero/one)\n  mutate(diabetes = as.integer(diabetes) - 1) %>%\n  cor()\n\nggcorrplot(diabetes_corr, type = \"lower\", lab = TRUE )\n\n\n\n\nLet’s create a new dataframe d_na, which has the missing values recoded as NA:\n\nd_na <- diabetes_data %>%\n  mutate(glucose = na_if(glucose, 0)) %>%\n  mutate(triceps = na_if(triceps, 0)) %>%\n  mutate(insulin = na_if(insulin, 0)) %>%\n  mutate(mass = na_if(mass, 0)) %>%\n  mutate(pressure = na_if(pressure, 0))\n\n# approximately half of the dataset is complete, whereas half is missing data\ntable(complete.cases(d_na))\n\n\nFALSE  TRUE \n  376   392 \n\nnaniar::gg_miss_var(d_na)\n\n\n\nvisdat::vis_dat(d_na)\n\n\n\n\nLet’s compare the correlation plot from before with another one now that we’ve correctly labelled the missing data:\n\ndiabetes_corr_na <-\n  d_na %>%\n  # recode outcome to be numeric (subtract 1 to return it to zero/one)\n  mutate(diabetes = as.integer(diabetes) - 1) %>%\n  # use pairwise complete observations for the two variables\n  cor(use = \"pairwise.complete.obs\")\n\nggcorrplot(diabetes_corr_na,  type = \"lower\",lab = TRUE)\n\n\n\n\nNotice that the correlation between some variables (eg. pregnant - insulin) changes quite substantially. (Negative before to Positive now)."
  },
  {
    "objectID": "200_dataset2/step1.html#lets-explore-our-data",
    "href": "200_dataset2/step1.html#lets-explore-our-data",
    "title": "Sydney Informatics Hub",
    "section": "Let’s Explore our data",
    "text": "Let’s Explore our data\n\nlibrary(tidyverse)\ntheme_set(theme_minimal())\nlibrary(ggcorrplot)\nlibrary(GGally)\n\nLoad data:\n\n# read in the csv\ndiabetes <- read_csv(\"../datasets/diabetes.csv\")\n# look at the variable names\nnames(diabetes)\n\n[1] \"Pregnancies\"              \"Glucose\"                 \n[3] \"BloodPressure\"            \"SkinThickness\"           \n[5] \"Insulin\"                  \"BMI\"                     \n[7] \"DiabetesPedigreeFunction\" \"Age\"                     \n[9] \"Outcome\"                 \n\n# look at the data\nglimpse(diabetes)\n\nRows: 768\nColumns: 9\n$ Pregnancies              <dbl> 6, 1, 8, 1, 0, 5, 3, 10, 2, 8, 4, 10, 10, 1, …\n$ Glucose                  <dbl> 148, 85, 183, 89, 137, 116, 78, 115, 197, 125…\n$ BloodPressure            <dbl> 72, 66, 64, 66, 40, 74, 50, 0, 70, 96, 92, 74…\n$ SkinThickness            <dbl> 35, 29, 0, 23, 35, 0, 32, 0, 45, 0, 0, 0, 0, …\n$ Insulin                  <dbl> 0, 0, 0, 94, 168, 0, 88, 0, 543, 0, 0, 0, 0, …\n$ BMI                      <dbl> 33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.…\n$ DiabetesPedigreeFunction <dbl> 0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.2…\n$ Age                      <dbl> 50, 31, 32, 21, 33, 30, 26, 29, 53, 54, 30, 3…\n$ Outcome                  <dbl> 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, …\n\n\nTurn the diagnosis into a labelled factor:\n\n# diabetes status is coded as 0/1\nhead(diabetes$Outcome)\n\n[1] 1 0 1 0 1 0\n\n# convert diabetes status into a labelled factor\ndiabetes <-\n  diabetes %>%\n  mutate(Outcome = recode_factor(diabetes$Outcome,\n                                 `0` = \"normal\",\n                                 `1` = \"diabetes\",\n                                 .ordered = T)\n  )\n# confirm conversion has worked\nhead(diabetes$Outcome)\n\n[1] diabetes normal   diabetes normal   diabetes normal  \nLevels: normal < diabetes\n\n\nLook for missing data:\n\nanyNA(diabetes)\n\n[1] FALSE\n\n\nIt seems like there is no missing data.\nGet a summary of the data frame:\n\nsummary(diabetes)\n\n  Pregnancies        Glucose      BloodPressure    SkinThickness  \n Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  \n 1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  \n Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  \n Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  \n 3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  \n Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  \n    Insulin           BMI        DiabetesPedigreeFunction      Age       \n Min.   :  0.0   Min.   : 0.00   Min.   :0.0780           Min.   :21.00  \n 1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437           1st Qu.:24.00  \n Median : 30.5   Median :32.00   Median :0.3725           Median :29.00  \n Mean   : 79.8   Mean   :31.99   Mean   :0.4719           Mean   :33.24  \n 3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262           3rd Qu.:41.00  \n Max.   :846.0   Max.   :67.10   Max.   :2.4200           Max.   :81.00  \n     Outcome   \n normal  :500  \n diabetes:268  \n               \n\n\n\n\n\n\n\n\nExercise:\n\n\n\nLook at the output of summary above and the table that explains what each of the variables are. Do the values make sense for all of: - (a) Pregnancies and Glucose - (b) Blood pressure and Skin thickness - (c) Insulin and DiabetesPedigreeFunction, and - (d) BMI and Age\nIf not, how do you think we should deal with them? Can you hypothesise what the consequences of this approach would be?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#Possibly missing: \n\ncolSums(diabetes == 0)\n\n             Pregnancies                  Glucose            BloodPressure \n                     111                        5                       35 \n           SkinThickness                  Insulin                      BMI \n                     227                      374                       11 \nDiabetesPedigreeFunction                      Age                  Outcome \n                       0                        0                        0 \n\n#Not missing:\n\ncolSums(diabetes != 0)\n\n             Pregnancies                  Glucose            BloodPressure \n                     657                      763                      733 \n           SkinThickness                  Insulin                      BMI \n                     541                      394                      757 \nDiabetesPedigreeFunction                      Age                  Outcome \n                     768                      768                      768 \n\n\nIt is clear that the values of several variables are zero when it is impossible for them to be so (i.e. this value could not be zero if it was measured). Hence, we are dealing with “hidden” missing data, and should recode it as NA.\nThe following variables have zero “values” that are actually likely to be missing:\n\nGlucose (a)\nBloodPressure (b)\nSkinThickness (b)\nInsulin (c)\nBMI (d)\n\n\n\n\nLet’s use visualisation to further explore the dataset:\n\nggplot(diabetes, aes(x = Pregnancies, fill = Outcome)) + geom_bar(position = \"dodge\")\n\n\n\n\n\nggplot(\n  diabetes,\n  aes(\n    x = BloodPressure,\n    y = Glucose,\n    color = Outcome\n  )\n) + geom_point(alpha = 0.5)\n\n\n\n\nIf we wanted to look at all possible scatterplot pairs we would do something like:\n\n# make a pair plot\nggpairs(data = diabetes, \n        mapping = aes(color = Outcome),\n        upper = list(combo = \"box\"))\n\n\n\n\nBut it’s easier to look at a correlation plot:\n\n# get a correlation matrix of the variables in the diabetes dataset:\ndiabetes_corr <- diabetes %>%\n  # recode outcome to be numeric again (subtract 1 to return it to zero/one)\n  mutate(Outcome = as.integer(Outcome) - 1) %>%\n  cor()\n\nggcorrplot(diabetes_corr, type = \"lower\", lab = TRUE )\n\n\n\n\nLet’s create a new dataframe d_na, which has the missing values recoded as NA:\n\nd_na <- diabetes %>%\n  mutate(Glucose = na_if(Glucose, 0)) %>%\n  mutate(SkinThickness = na_if(SkinThickness, 0)) %>%\n  mutate(Insulin = na_if(Insulin, 0)) %>%\n  mutate(BMI = na_if(BMI, 0)) %>%\n  mutate(BloodPressure = na_if(BloodPressure, 0))\n\n# approximately half of the dataset is complete, whereas half is missing data\ntable(complete.cases(d_na))\n\n\nFALSE  TRUE \n  376   392 \n\nnaniar::gg_miss_var(d_na)\n\n\n\n\nLet’s compare the correlation plot from before with another one now that we’ve correctly labelled the missing data:\n\ndiabetes_corr_na <-\n  d_na %>%\n  # recode outcome to be numeric again (subtract 1 to return it to zero/one)\n  mutate(Outcome = as.integer(Outcome) - 1) %>%\n  # use pairwise complete observations for the two variables\n  cor(use = \"pairwise.complete.obs\")\n\nggcorrplot(diabetes_corr_na,  type = \"lower\",lab = TRUE)\n\n\n\n\nNotice that the correlation between some variables (eg. Pregnancies - Insulin) changes quite substantially. (Negative before to Positive now)."
  },
  {
    "objectID": "200_dataset2/step1.html#train-test-split",
    "href": "200_dataset2/step1.html#train-test-split",
    "title": "Sydney Informatics Hub",
    "section": "Train-Test Split",
    "text": "Train-Test Split\n\nWe’re going to split our data into 70% training and 30% testing sets.\n\nset.seed(42) # so we all get the same results\n\ndiabetes_split <- initial_split(d_na , prop = 0.7, strata = \"diabetes\" )\nd_na_train <- training(diabetes_split)\nd_na_test <- testing(diabetes_split)\n\nsaveRDS(d_na_train, \"../_models/d_na_train.Rds\")\nsaveRDS(d_na_test, \"../_models/d_na_test.Rds\")\nsaveRDS(diabetes_split, \"../_models/diabetes_split.Rds\")\n\nSome standard checks on the test/train split\nLook how many examples we have in the training and testing sets.\n\ndim(d_na_train)\n\n[1] 537   9\n\ndim(d_na_test)\n\n[1] 231   9\n\n\nPlot histograms of outputs to check we stratified appropriately\n\ntogether <- bind_rows(train = d_na_train,\n                      test = d_na_test,\n                      .id = \"test_train\" ) \n\ntogether %>%\n  ggplot(aes(x = diabetes))+\n  geom_bar()+\n  facet_grid(test_train~., scales = \"free\")\n\n\n\ntogether %>%\n  {ggduo(., \n         setdiff( names(.), c(\"test_train\", \"diabetes\") ), \n         # column names not including test_train or the outcome\n         \"test_train\")} # faceted by test_train split\n\n\n\n\nAt some point we’re going to want to do some parameter tuning (explained later), and to do that we’re going to want to use cross-validation. So we can create a cross-validated version of the training set in preparation for that moment:\n\ndiabetes_folds <- vfold_cv(d_na_train, v=10, repeats = 5, strata = diabetes)\n\nsaveRDS(diabetes_folds, \"../_models/diabetes_folds.rds\")\n\nImpute missing data\n\nImputation is often used to handle missing data because many statistical methods and machine learning algorithms require complete data. When we do imputation, we aren’t adding new information to our dataset, but we are using the patterns in our dataset so that we don’t have to throw away the data that have some variables missing. We can impute the missing data using a recipe:\n\n# set seed to be 42 so everyone gets the same results\nset.seed(42)\ndiabetes_rec <-\n  d_na_train %>%\n  recipe(diabetes ~ .) %>%\n  # all our predictors are numeric so standardize them\n  step_normalize(all_numeric_predictors()) %>%\n  step_impute_median(all_predictors())\n\ndiabetes_rec  \n\nsaveRDS(diabetes_rec, \"../_models/diabetes_rec.rds\")"
  },
  {
    "objectID": "200_dataset2/step2.html#model-evaluation-classification",
    "href": "200_dataset2/step2.html#model-evaluation-classification",
    "title": "Sydney Informatics Hub",
    "section": "Model evaluation (classification)",
    "text": "Model evaluation (classification)\n\nFor now, let’s imagine we have a classifier already. How can we test it to see how good it is? A good start is a confusion matrix - a table of what test data it labels correctly and incorrectly.\n\n\nDemonstration of a confusion matrix for a cat classifier that has labelled 100 animals as cats or not-cats.\n\n\nConfusion Matrix\n\nWhen applying classification models, we often use a confusion matrix to evaluate certain performance measures. A confusion matrix is a matrix that compares “the truth” to the labels generated by your classifier. When we label a cat correctly, we refer to this as a true positive. When we fail to label a cat as a cat, this is called a false negative. However, if we label something which is not a cat as a cat, this is called a false positive; and if we correctly label something which is not a cat, as not a cat, then this is a true negative. In our case, the confusion matrix will look like this:\n\n\ntrue positive (TP) : Diabetic correctly identified as diabetic\n\ntrue negative (TN) : Healthy correctly identified as healthy\n\nfalse positive (FP) : Healthy incorrectly identified as diabetic\n\nfalse negative (FN) : Diabetic incorrectly identified as healthy\nSome common classification metrics\n\nDon’t worry if you forget some of these - there are so many different words used to describe different ways to divide up the confusion matrix, it can get very confusing. I swear each time I just look up wikipedia again to figure out which part of the confusion matrix to look at. There are even more there that we won’t even bother talking about here.\n\nAccuracy:\nHow often does the classifier label examples correctly? Objective: maximize. Example:\n\\[\\frac{TP+TN}{TP+TN+FP+FN} = \\frac{\\text{Correctly labelled examples}}{\\text{All examples}}=\\frac{31+52}{31+52+10+7}=83\\%\\]\nAccuracy is the opposite of the misclassification rate. So,\n\\[\\text{Misclassification rate} = 1 - \\text{Accuracy} = \\frac{\\text{Incorrectly labelled examples}}{\\text{All examples}}\\]\n\nPrecision:\nWhat fraction of things labelled as a cat were actually cats? Objective: maximize. Example:\n\\[\\frac{TP}{TP+FP} = \\frac{\\text{Correctly labelled cats}}{\\text{All things labelled as cats}}=\\frac{31}{31+10}=76\\%\\]\n\nSensitivity / Recall:\nHow often does the classifier label a cat as a cat? Objective: maximize. Example:\n\\[\\frac{TP}{TP+FN} = \\frac{\\text{Correctly labelled cats}}{\\text{All true cats}}=\\frac{31}{31+7}=81\\%\\]\n\nSpecificity:\nHow often does it label a not-cat as a not-cat? Objective: maximize. Example:\n\\[\\frac{TN}{TN+FP} = \\frac{\\text{Correctly labelled not-cats}}{\\text{All true not-cats}}=\\frac{52}{52+10}=84\\%\\]\n\nF1-score:\nThis is a commonly used overall measure of classifier performance (but not the only one and not always the best depending upon the problem). It is defined as the harmonic mean of precision and sensitivity;\n\\[\\frac{1}{F_1} = \\frac{1}{2}\\left(\\frac{1}{\\text{Precision}}+\\frac{1}{\\text{Sensitivity}}\\right)\\]\nSo that\n\\[F_1 = 2\\cdot\\left(\\frac{1}{\\frac{1}{81\\%}+\\frac{1}{83\\%}}\\right) = 82\\%\\]\nAUC: Area under the curve\n\nA good classifier will have high precision and high specificity, minimizing both false positives and false negatives. In practice, and with an imperfect classifier, you can tune a knob to say which of those two you care more about. There will be some kind of a trade-off between the two.\nTo capture this balance, we often use a Reciever Operator Characteristic (ROC) curve that plots the false positive rate along the x-axis and the true positive rate along the y-axis, for all possible trade-offs. A line that is diagonal from the lower left corner to the upper right corner represents a random guess at labelling each example. The higher the line is in the upper left-hand corner, the better the classifier in general. AUC computes the area under this curve. For a perfect classifier, AUC = 1, for a random guess, AUC=0.5. Objective: maximize.\n\n\nA Reciever Operator Characteristic (ROC) curve, from which the Area Under the Curve (AUC) can be calculated.\n\n\n\nFor additional discussion of classification error metrics, see Tharwat 2018, for example.\n\n\n\n\n\n\n\nChallenge 1\n\n\n\n\nIn the case of patients with a rare disease, what can be the problem of using accuracy to evaluate the performance of a machine learning model.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAccuracy is calculated as the (TP + TN)/(total) number of cases in the dataset. If you have very few positive cases, such as when working with a rare disease, the numerator of this fraction will be dominated by the true negatives you accurately predict in your dataset - so not very informative when assessing whether your classifier predicts the disease well at all!\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(workflows)\nlibrary(tune)\nlibrary(vip)\nlibrary(ParallelLogger)\nlibrary(doParallel)\nlibrary(workflowsets)\ntheme_set(theme_minimal())\n\ndiabetes_rec <- readRDS(\"../_models/diabetes_rec.rds\")\ndiabetes_folds <- readRDS(\"../_models/diabetes_folds.rds\")\nd_na_train <- readRDS(\"../_models/d_na_train.Rds\")\nd_na_test <- readRDS(\"../_models/d_na_test.Rds\")\ndiabetes_split <- readRDS(\"../_models/diabetes_split.Rds\")"
  },
  {
    "objectID": "200_dataset2/step2.html#what-is-a-classifier",
    "href": "200_dataset2/step2.html#what-is-a-classifier",
    "title": "Sydney Informatics Hub",
    "section": "What is a classifier?",
    "text": "What is a classifier?\n\nA classifier is some kind of rule / black box / widget that you can feed a new example and it will spit out whether or not it is part of a given class. E.g. below, we are classifying the animals to be either cat or not cat.\n\n\nA classifier for cats and not cats.\n\n\nYou can have classifiers for anything you can have a yes/no answer to, e.g.\n\nIs this a cat? 🐱\nDo these test results indicate cancer? 🚑\nIs this email spam or not spam? 📧\n\nYou can also have classifiers that categorise things into multiple (more than two) categories e.g.\n\nWhich animal is this, out of the 12 animals I have trained my model on? 🐱\nDo these test results indicate {none, stage 1, stage 2, stage 3, stage 4} cancer? 🚑\nIs this email important, not important but not spam, or spam? 📧\n\nIt is clear that in some of these examples we are more concerned with being wrong in one direction than the other, e.g. it’s better to let some spam email through accidentally than to block all of it but also junk important emails from people you know. Likewise, we would prefer our medical tests to err on the side of caution and not give a negative test result to someone who needs treatment. So we will need to adjust a parameter to decide how much we want to trade this off."
  },
  {
    "objectID": "200_dataset2/step2.html#tune-model-hyperparameters",
    "href": "200_dataset2/step2.html#tune-model-hyperparameters",
    "title": "Sydney Informatics Hub",
    "section": "Tune model hyperparameters",
    "text": "Tune model hyperparameters\n\nSome model parameters cannot be learned directly from a dataset during model training; these kinds of parameters are called hyperparameters. Some examples of hyperparameters include the number of randomly selected variables to be considered at each split in a tree-based model (called mtry in tidymodels).\nInstead of learning these kinds of hyperparameters during model training, we can estimate the best values for these values by training many models on a resampled data set (like the cross-validation folds we have previously created) and measuring how well all these models perform. This process is called *tuning.\nYou can identify which parameters to tune() in a model specification.\nWe can specify a random forest classifier with the following hyperparameters:\n\n\nmtry: the number of predictors that will be randomly sampled at each split when creating the tree models;\n\ntrees: the number of decision trees to fit and ultimately average;\n\nmin_n: The minimum number of data points in a node that are required for the node to be split further.\n\nTo specify a random forest model with tidymodels, we need the rand_forest() function. The hyperparameters of the model are arguments within the rand_forest() function and may be set to specific values. However, if tuning is required, then each of these parameters must be set to tune().\nWe will be using the ranger engine. This engine has an optional importance argument which can be used to track variable importance measures. In order to make a variable importance plot with vip(), we must add importance = 'impurity' inside our set_engine() function:\n\nrf_model_diabetes <- \n  # specify that the model is a random forest and which hyperparameters need to be tuned\n  rand_forest(mtry = tune(),\n              trees = tune(),\n              min_n = tune()) %>%\n  # select the engine/package that underlies the model\n  set_engine(\"ranger\", importance = \"impurity\") %>% #get variable importance scores\n  # choose either the continuous regression or binary classification mode\n  set_mode(\"classification\") \n\nrlr_model_diabetes <- \n  logistic_reg(mixture = tune(), penalty = tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\n\nNote Nothing about this model specification is specific to the diabetes dataset.\n\nFind which parameters will give the model its best accuracy\n\n\nTry different values and measure their performance;\nFind good values for these parameters;\nOnce the value(s) of the parameter(s) are determined, a model can be finalized by fitting the model to the entire training set.\n\n\nYou have a couple of options for how to choose which possible values for the tuning parameters to try. One of these options is creating a random grid of values. Random grid search is implemented with the grid_random() function in tidymodels, taking a sequence of hyperparameter names to create the grid. It also has a size parameter that specifies the number of random combinations to create.\nThe mtry() hyperparameter requires a pre-set range of values to test since it cannot exceed the number of columns in our data. When we add this to grid_random() we can pass mtry() into the range_set() function and set a range for the hyperparameter with a numeric vector.\nIn the code below, we set the range from 3 to 6. This is because we have 9 columns in diabetes_data and we would like to test mtry() values somewhere in the middle between 1 and 9, trying to avoid values close to the ends.\nWhen using grid_random(), it is suggested to use set.seed() for reproducibility.\nWe can then use the function tune_grid() to tune either a workflow or a model specification with a set of resampled data, such as the cross-validation we created. Grid search, combined with resampling, requires fitting a lot of models! These models don’t depend on one another and can be run in parallel.\n\nset.seed(314)\n\nrf_grid <- grid_random(mtry() %>% range_set(c(3, 6)),\n                       trees(),\n                       min_n(),\n                       size = 10)\n\n#View grid\nrf_grid\n\n# A tibble: 10 × 3\n    mtry trees min_n\n   <int> <int> <int>\n 1     4  1644    34\n 2     6  1440    20\n 3     6  1549    31\n 4     5  1734    39\n 5     6   332    11\n 6     5  1064     3\n 7     5   218    37\n 8     4  1304    24\n 9     4   477    32\n10     5  1621     6\n\n#Tune random forest model \nrf_tune_model <- tune_grid(\n  rf_model_diabetes,  #your model\n  diabetes_rec,       #your recipe\n  resamples = diabetes_folds, #your resampling\n  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity),\n  grid = rf_grid)\n\nrf_tune_model\n\n# Tuning results\n# 10-fold cross-validation repeated 5 times using stratification \n# A tibble: 50 × 5\n   splits           id      id2    .metrics          .notes          \n   <list>           <chr>   <chr>  <list>            <list>          \n 1 <split [483/54]> Repeat1 Fold01 <tibble [40 × 7]> <tibble [0 × 3]>\n 2 <split [483/54]> Repeat1 Fold02 <tibble [40 × 7]> <tibble [0 × 3]>\n 3 <split [483/54]> Repeat1 Fold03 <tibble [40 × 7]> <tibble [0 × 3]>\n 4 <split [483/54]> Repeat1 Fold04 <tibble [40 × 7]> <tibble [0 × 3]>\n 5 <split [483/54]> Repeat1 Fold05 <tibble [40 × 7]> <tibble [0 × 3]>\n 6 <split [483/54]> Repeat1 Fold06 <tibble [40 × 7]> <tibble [0 × 3]>\n 7 <split [483/54]> Repeat1 Fold07 <tibble [40 × 7]> <tibble [0 × 3]>\n 8 <split [484/53]> Repeat1 Fold08 <tibble [40 × 7]> <tibble [0 × 3]>\n 9 <split [484/53]> Repeat1 Fold09 <tibble [40 × 7]> <tibble [0 × 3]>\n10 <split [484/53]> Repeat1 Fold10 <tibble [40 × 7]> <tibble [0 × 3]>\n# … with 40 more rows\n\n\nUse collect_metrics to extract the metrics calculated from the cross-validation performance across the different values of the parameters:\n\n#collect metrics\nrf_tune_model %>%\n  collect_metrics()\n\n# A tibble: 40 × 9\n    mtry trees min_n .metric     .estimator  mean     n std_err .config         \n   <int> <int> <int> <chr>       <chr>      <dbl> <int>   <dbl> <chr>           \n 1     4  1644    34 accuracy    binary     0.764    50 0.00643 Preprocessor1_M…\n 2     4  1644    34 roc_auc     binary     0.847    50 0.00645 Preprocessor1_M…\n 3     4  1644    34 sensitivity binary     0.855    50 0.00772 Preprocessor1_M…\n 4     4  1644    34 specificity binary     0.592    50 0.0153  Preprocessor1_M…\n 5     6  1440    20 accuracy    binary     0.764    50 0.00634 Preprocessor1_M…\n 6     6  1440    20 roc_auc     binary     0.842    50 0.00654 Preprocessor1_M…\n 7     6  1440    20 sensitivity binary     0.852    50 0.00733 Preprocessor1_M…\n 8     6  1440    20 specificity binary     0.597    50 0.0144  Preprocessor1_M…\n 9     6  1549    31 accuracy    binary     0.759    50 0.00626 Preprocessor1_M…\n10     6  1549    31 roc_auc     binary     0.843    50 0.00635 Preprocessor1_M…\n# … with 30 more rows\n\n#see which model performed the best, in terms of some given metric\nrf_tune_model %>%\n  show_best(\"roc_auc\")\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     4  1644    34 roc_auc binary     0.847    50 0.00645 Preprocessor1_Model01\n2     4  1304    24 roc_auc binary     0.846    50 0.00643 Preprocessor1_Model08\n3     4   477    32 roc_auc binary     0.845    50 0.00633 Preprocessor1_Model09\n4     5  1734    39 roc_auc binary     0.845    50 0.00647 Preprocessor1_Model04\n5     5   218    37 roc_auc binary     0.844    50 0.00650 Preprocessor1_Model07\n\n\n\n\n\n\n\n\nChallenge X\n\n\n\nUse tune_grid and collect_metrics to tune a workflow. Hints:\nUse workflow() to define the workflow:\n\n#set the workflow\n\n#add the recipe\n\n#add the model\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#set the workflow\nrf_workflow <- workflow() %>%\n#add the recipe\nadd_recipe(diabetes_rec) %>%\n#add the model\n  add_model(rf_model_diabetes)\n\n#tune the workflow\nset.seed(22)\n\nrf_tune_wf <- rf_workflow %>%\n  tune_grid(resamples = diabetes_folds,\n            metrics = metric_set(accuracy, roc_auc, sensitivity, specificity),\n            grid = rf_grid)\n\nrf_tune_wf %>%\n  collect_metrics()\n\n# A tibble: 40 × 9\n    mtry trees min_n .metric     .estimator  mean     n std_err .config         \n   <int> <int> <int> <chr>       <chr>      <dbl> <int>   <dbl> <chr>           \n 1     4  1644    34 accuracy    binary     0.762    50 0.00639 Preprocessor1_M…\n 2     4  1644    34 roc_auc     binary     0.847    50 0.00640 Preprocessor1_M…\n 3     4  1644    34 sensitivity binary     0.857    50 0.00783 Preprocessor1_M…\n 4     4  1644    34 specificity binary     0.584    50 0.0142  Preprocessor1_M…\n 5     6  1440    20 accuracy    binary     0.762    50 0.00640 Preprocessor1_M…\n 6     6  1440    20 roc_auc     binary     0.842    50 0.00659 Preprocessor1_M…\n 7     6  1440    20 sensitivity binary     0.851    50 0.00736 Preprocessor1_M…\n 8     6  1440    20 specificity binary     0.595    50 0.0146  Preprocessor1_M…\n 9     6  1549    31 accuracy    binary     0.761    50 0.00648 Preprocessor1_M…\n10     6  1549    31 roc_auc     binary     0.843    50 0.00661 Preprocessor1_M…\n# … with 30 more rows\n\nrf_tune_wf %>%\n  show_best(\"roc_auc\")\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     4  1644    34 roc_auc binary     0.847    50 0.00640 Preprocessor1_Model01\n2     4   477    32 roc_auc binary     0.846    50 0.00639 Preprocessor1_Model09\n3     4  1304    24 roc_auc binary     0.846    50 0.00641 Preprocessor1_Model08\n4     5  1734    39 roc_auc binary     0.845    50 0.00643 Preprocessor1_Model04\n5     5   218    37 roc_auc binary     0.845    50 0.00628 Preprocessor1_Model07\n\n\n\n\n\nLet’s visualise our results:\n\nautoplot(rf_tune_model)\n\n\n\nautoplot(rf_tune_wf)\n\n\n\n\nWe can also specify the values of the parameters to tune with an tuning grid, entered as a data frame. It contains all the combinations of parameters to be tested. For regularized logistic regression, we test eleven values of mixture:\n\n#set the grid\nrlr_grid <- data.frame(mixture = seq(0, 1, 0.1),\n                       penalty = seq(0, 1, 0.1))\nrlr_grid\n\n   mixture penalty\n1      0.0     0.0\n2      0.1     0.1\n3      0.2     0.2\n4      0.3     0.3\n5      0.4     0.4\n6      0.5     0.5\n7      0.6     0.6\n8      0.7     0.7\n9      0.8     0.8\n10     0.9     0.9\n11     1.0     1.0\n\nset.seed(435)\n\n##use tune_grid() for hyperparameters tuning, doing cross validation for each row of the tuning grid\nrlr_tune_model <- tune_grid(\n  rlr_model_diabetes,  #your model\n  diabetes_rec,       #your recipe\n  resamples = diabetes_folds, #your resampling\n  grid = rlr_grid)\n\nrlr_tune_model %>%\n  collect_metrics()\n\n# A tibble: 22 × 8\n   penalty mixture .metric  .estimator  mean     n  std_err .config             \n     <dbl>   <dbl> <chr>    <chr>      <dbl> <int>    <dbl> <chr>               \n 1     0       0   accuracy binary     0.747    50 0.00649  Preprocessor1_Model…\n 2     0       0   roc_auc  binary     0.838    50 0.00623  Preprocessor1_Model…\n 3     0.1     0.1 accuracy binary     0.756    50 0.00596  Preprocessor1_Model…\n 4     0.1     0.1 roc_auc  binary     0.839    50 0.00620  Preprocessor1_Model…\n 5     0.2     0.2 accuracy binary     0.751    50 0.00602  Preprocessor1_Model…\n 6     0.2     0.2 roc_auc  binary     0.837    50 0.00603  Preprocessor1_Model…\n 7     0.3     0.3 accuracy binary     0.681    50 0.00402  Preprocessor1_Model…\n 8     0.3     0.3 roc_auc  binary     0.805    50 0.00690  Preprocessor1_Model…\n 9     0.4     0.4 accuracy binary     0.652    50 0.000801 Preprocessor1_Model…\n10     0.4     0.4 roc_auc  binary     0.783    50 0.00742  Preprocessor1_Model…\n# … with 12 more rows\n\nrlr_tune_model %>%\n  show_best(\"roc_auc\")\n\n# A tibble: 5 × 8\n  penalty mixture .metric .estimator  mean     n std_err .config              \n    <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     0.1     0.1 roc_auc binary     0.839    50 0.00620 Preprocessor1_Model02\n2     0       0   roc_auc binary     0.838    50 0.00623 Preprocessor1_Model01\n3     0.2     0.2 roc_auc binary     0.837    50 0.00603 Preprocessor1_Model03\n4     0.3     0.3 roc_auc binary     0.805    50 0.00690 Preprocessor1_Model04\n5     0.4     0.4 roc_auc binary     0.783    50 0.00742 Preprocessor1_Model05\n\n\nThe workflowsets package\n\nTidymodels allows us to perform all of the above steps in a much faster way with the workflowsets package:\n\ndiabetes_wf_set <- workflow_set(list(diabetes_rec),  #list of recipes\n             list(rf_model_diabetes, rlr_model_diabetes), #list of models\n             cross = TRUE) #all combinations of the preprocessors and models are used to create the workflows\n  \ndiabetes_wf_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id            info             option    result    \n  <chr>               <list>           <list>    <list>    \n1 recipe_rand_forest  <tibble [1 × 4]> <opts[0]> <list [0]>\n2 recipe_logistic_reg <tibble [1 × 4]> <opts[0]> <list [0]>\n\n# setting the parameters on each workflow seperately\nrf_params <- diabetes_wf_set %>%\n  extract_workflow(\"recipe_rand_forest\") %>%\n  parameters() %>%\n  update(mtry = mtry(c(3,6)),\n         trees = trees(c(1, 10)),\n         min_n = min_n(c(1, 10)))\n\nrlr_params <- diabetes_wf_set %>%\n  extract_workflow(\"recipe_logistic_reg\") %>%\n  parameters() %>%\n  update(mixture = mixture(c(0, 1)),\n         penalty = penalty(c(1,2)))\n  \ndiabetes_wf_set <- diabetes_wf_set %>%\n  workflow_map(\"tune_grid\", # the first argument is a function name from the tune package (tune_grid(), fit_resamples()..)\n               resamples = diabetes_folds,\n               verbose = TRUE) \n\n\ndiabetes_wf_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id            info             option    result   \n  <chr>               <list>           <list>    <list>   \n1 recipe_rand_forest  <tibble [1 × 4]> <opts[1]> <tune[+]>\n2 recipe_logistic_reg <tibble [1 × 4]> <opts[1]> <tune[+]>\n\n\nThe results column contains the results of each call to tune_grid() for the workflows. From these results, we can get quick assessments of how well these models classified the data:\n\n#To get the rankings of the models (and their tuning parameter sub-models) as a data frame:\nrank_results(diabetes_wf_set, rank_metric = \"roc_auc\")\n\n# A tibble: 40 × 9\n   wflow_id           .config    .metric  mean std_err     n prepr…¹ model  rank\n   <chr>              <chr>      <chr>   <dbl>   <dbl> <int> <chr>   <chr> <int>\n 1 recipe_rand_forest Preproces… accura… 0.766 0.00669    50 recipe  rand…     1\n 2 recipe_rand_forest Preproces… roc_auc 0.849 0.00610    50 recipe  rand…     1\n 3 recipe_rand_forest Preproces… accura… 0.771 0.00625    50 recipe  rand…     2\n 4 recipe_rand_forest Preproces… roc_auc 0.848 0.00621    50 recipe  rand…     2\n 5 recipe_rand_forest Preproces… accura… 0.764 0.00646    50 recipe  rand…     3\n 6 recipe_rand_forest Preproces… roc_auc 0.847 0.00635    50 recipe  rand…     3\n 7 recipe_rand_forest Preproces… accura… 0.764 0.00656    50 recipe  rand…     4\n 8 recipe_rand_forest Preproces… roc_auc 0.845 0.00646    50 recipe  rand…     4\n 9 recipe_rand_forest Preproces… accura… 0.762 0.00665    50 recipe  rand…     5\n10 recipe_rand_forest Preproces… roc_auc 0.843 0.00654    50 recipe  rand…     5\n# … with 30 more rows, and abbreviated variable name ¹​preprocessor\n\n#plot the results\nautoplot(diabetes_wf_set, metric = \"roc_auc\")\n\n\n\n\nThis shows the results for all tuning parameter combinations for each model. It looks like the random forest model did well. We can use the extract_workflow_set_result() function to extract the tuning results:\n\nbest_results <- diabetes_wf_set %>%\n  extract_workflow_set_result(\"recipe_rand_forest\") %>%\n  select_best(metric=\"roc_auc\")\n\nbest_results\n\n# A tibble: 1 × 4\n   mtry trees min_n .config              \n  <int> <int> <int> <chr>                \n1     2   983    30 Preprocessor1_Model10\n\n\nUpdate and fit the workflow\n\nThe last step in hyperparameter tuning is to use finalize_workflow() to add our optimal model to our workflow object, and apply the last_fit() function to our workflow and our train/test split object. This will automatically train the model specified by the workflow using the training data, and produce evaluations based on the test set:\n\nfinal_diabetes_fit <- diabetes_wf_set %>%\n  extract_workflow(\"recipe_rand_forest\") %>%\n  finalize_workflow(best_results) %>%\n  last_fit(diabetes_split)\n\nfinal_diabetes_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [537/231]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nSince we supplied the train/test object when we fit the workflow, the metrics are evaluated on the test set. Now when we use the collect_metrics() function (the same we used when tuning our parameters) to extract the performance of the final model (since rf_fit_final now consists of a single final model) applied to the test set:\n\ntest_performance <- final_diabetes_fit %>% collect_metrics()\ntest_performance\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.753 Preprocessor1_Model1\n2 roc_auc  binary         0.819 Preprocessor1_Model1\n\n\nWe can plot the ROC curve to visualize test set performance of our random forest model, and generate a confusion matrix:\nNote In R, factor levels are ordered alphabetically by default, which means that “no” comes first before “yes” and is considered the level of interest or positive case. Use the argument event_level = \"second\" to alter this as needed.\n\n#ROC curve\n  collect_predictions(final_diabetes_fit) %>%\n  roc_curve(truth  = diabetes, event_level=\"second\", estimate = .pred_pos) %>%  #specify which level of truth to                                                                                       consider as the \"event\"\n                autoplot()\n\n\n\n#confusion matrix\nconf_matrix_rf <- final_diabetes_fit %>%\n  collect_predictions() %>%\n  conf_mat(truth = diabetes, estimate = .pred_class) \n\nconf_matrix_rf\n\n          Truth\nPrediction neg pos\n       neg 128  35\n       pos  22  46\n\nconf_matrix_rf %>%\n  autoplot()\n\n\n\n\nVariable importance\n\nIn order to visualize the variable importance scores of our random forest model, we will need to manually train our workflow object with the fit() function on the training data, then extract the trained model with the pull_workflow_fit() function, and next passing the trained model to the vip() function:\n\n#extract the final workflow\nfinal_workflow <- diabetes_wf_set %>%\n  extract_workflow(\"recipe_rand_forest\") %>%\n  finalize_workflow(best_results)\n\n#fit on the training data\nwf_fit <- final_workflow %>%\n  fit(data = d_na_train)\n#extract the trained model\nwf_fit <- wf_fit %>% \n          pull_workflow_fit()\n#plot variable importance\nvip(wf_fit)\n\n\n\n\nThis returns a ggplot object with the variable importance scores from our model.\nWe see from the results below, that the glucose concentration, body mass index and age are the most important predictors of diabetes."
  },
  {
    "objectID": "200_dataset2/step2.html#some-classification-models",
    "href": "200_dataset2/step2.html#some-classification-models",
    "title": "Sydney Informatics Hub",
    "section": "Some classification models",
    "text": "Some classification models\nTree-based models\n\nA tree-based model is a type of algorithm that creates a tree-like structure to make predictions about a certain outcome, such as whether a customer will buy a product or not. The tree structure consists of nodes that represent different features, and the algorithm uses these features to split the data into smaller and smaller subsets. Each subset is then assigned a label based on the majority of its observations, and this process continues until the algorithm reaches a stopping criterion or has created a fully-grown tree. Once the tree is created, it can be used to make predictions by following the path through the tree that corresponds to a given set of input features. Tree-based models are simple and intuitive to understand, and can be used for both classification and regression tasks.\n\nDecision trees are a simple type of tree-based model that use a hierarchical structure of nodes to make predictions about a certain outcome. The process continues until a stopping criterion is met, such as a maximum tree depth or a minimum number of observations per leaf node, and it can predict the outcome. A single decision tree may not be accurate enough for many real-world problems;\nRandom forest overcomes this limitation by building many decision trees, each using a randomly selected subset of the data and features, and then combining their predictions to make a final prediction.\nLogistic regression\n\nLogistic regression is a type of algorithm that is used to predict a binary outcome, such as whether a patient is likely to develop diabetes or no. It works by creating a mathematical function that predicts the probability of an observation belonging to a certain class (e.g., diabetes or not diabetes). The function takes into account one or more input variables, such as the patients’s age, gender, or body mass index. The output of the function is a value between 0 and 1, which represents the probability of the observation belonging to the positive class (e.g., developing diabetes). To make a prediction, the algorithm compares the predicted probability to a threshold value (e.g., 0.5), and assigns the observation to the positive class if the probability is greater than the threshold, and to the negative class otherwise.\nRegularization is a technique that can be used to prevent overfitting of the model. A regularized logistic regression model, is a logistic classifier that has been modified to include a regularization term. This is done by adding a penalty to the model that discourages it from giving too much importance to any variable.\nThere are several regularized regression models, defined with the mixture parameter:\n\n\nRidge regularization encourages the model to have small coefficient values (mixture = 0);\n\nLasso regularization encourages the model to set some of the coefficients to zero, which performs feature selection. This can help improve the model’s interpretability and reduce the impact of irrelevant features on the model’s performance (mixture = 1);\n\nElastic Net regularization combines Ridge and Lasso regularization by adding a penalty term that is a weighted average of both penalties. This approach can provide the benefits of both Ridge and Lasso regularization, such as feature selection and coefficient shrinkage (mixture between 0 and 1)."
  },
  {
    "objectID": "200_classification/step2.html",
    "href": "200_classification/step2.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\nBuild a ML model for predicting whether a person has diabetes or not;"
  },
  {
    "objectID": "200_classification/step2.html#what-is-a-classifier",
    "href": "200_classification/step2.html#what-is-a-classifier",
    "title": "Sydney Informatics Hub",
    "section": "What is a classifier?",
    "text": "What is a classifier?\n\nA classifier is some kind of rule / black box / widget that you can feed a new example and it will spit out whether or not it is part of a given class. E.g. below, we are classifying the animals to be either cat or not cat.\n\n\nA classifier for cats and not cats.\n\n\nYou can have classifiers for anything you can have a yes/no answer to, e.g.\n\nIs this a cat? 🐱\nDo these test results indicate cancer? 🚑\nIs this email spam or not spam? 📧\n\nYou can also have classifiers that categorise things into multiple (more than two) categories e.g.\n\nWhich animal is this, out of the 12 animals I have trained my model on? 🐱\nDo these test results indicate {none, stage 1, stage 2, stage 3, stage 4} cancer? 🚑\nIs this email important, not important but not spam, or spam? 📧\n\nIt is clear that in some of these examples we are more concerned with being wrong in one direction than the other, e.g. it’s better to let some spam email through accidentally than to block all of it but also junk important emails from people you know. Likewise, we would prefer our medical tests to err on the side of caution and not give a negative test result to someone who needs treatment. So we will need to adjust a parameter to decide how much we want to trade this off."
  },
  {
    "objectID": "200_classification/step2.html#model-evaluation-classification",
    "href": "200_classification/step2.html#model-evaluation-classification",
    "title": "Sydney Informatics Hub",
    "section": "Model evaluation (classification)",
    "text": "Model evaluation (classification)\n\nFor now, let’s imagine we have a classifier already. How can we test it to see how good it is? A good start is a confusion matrix - a table of what test data it labels correctly and incorrectly.\n\n\nDemonstration of a confusion matrix for a cat classifier that has labelled 100 animals as cats or not-cats.\n\n\nConfusion Matrix\n\nWhen applying classification models, we often use a confusion matrix to evaluate certain performance measures. A confusion matrix is a matrix that compares “the truth” to the labels generated by your classifier. When we label a cat correctly, we refer to this as a true positive. When we fail to label a cat as a cat, this is called a false negative. However, if we label something which is not a cat as a cat, this is called a false positive; and if we correctly label something which is not a cat, as not a cat, then this is a true negative. In our case, the confusion matrix will look like this:\n\n\ntrue positive (TP) : Diabetic correctly identified as diabetic\n\ntrue negative (TN) : Healthy correctly identified as healthy\n\nfalse positive (FP) : Healthy incorrectly identified as diabetic\n\nfalse negative (FN) : Diabetic incorrectly identified as healthy\nSome common classification metrics\n\nDon’t worry if you forget some of these - there are so many different words used to describe different ways to divide up the confusion matrix, it can get very confusing. I swear each time I just look up wikipedia again to figure out which part of the confusion matrix to look at. There are even more there that we won’t even bother talking about here.\n\nAccuracy:\nHow often does the classifier label examples correctly?\n\\[\\frac{TP+TN}{TP+TN+FP+FN} = \\frac{\\text{Correctly labelled examples}}{\\text{All examples}}\\]\n\nPrecision:\nWhat fraction of things labelled as a cat were actually cats?\n\\[\\frac{TP}{TP+FP} = \\frac{\\text{Correctly labelled cats}}{\\text{All things labelled as cats}}\\]\n\nSensitivity / Recall:\nHow often does the classifier label a cat as a cat?\n\\[\\frac{TP}{TP+FN} = \\frac{\\text{Correctly labelled cats}}{\\text{All true cats}}\\]\n\nSpecificity:\nHow often does it label a not-cat as a not-cat?\n\\[\\frac{TN}{TN+FP} = \\frac{\\text{Correctly labelled not-cats}}{\\text{All true not-cats}}\\]\n\nF1-score:\nThis is a commonly used overall measure of classifier performance (but not the only one and not always the best depending upon the problem). It is defined as the harmonic mean of precision and sensitivity;\n\\[\\frac{1}{F_1} = \\frac{1}{2}\\left(\\frac{1}{\\text{Precision}}+\\frac{1}{\\text{Sensitivity}}\\right)\\]\nAUC: Area under the curve\n\nA good classifier will have high precision and high specificity, minimizing both false positives and false negatives. In practice, and with an imperfect classifier, you can tune a knob to say which of those two you care more about. There will be some kind of a trade-off between the two.\nTo capture this balance, we often use a Reciever Operator Characteristic (ROC) curve that plots the false positive rate along the x-axis and the true positive rate along the y-axis, for all possible trade-offs. A line that is diagonal from the lower left corner to the upper right corner represents a random guess at labelling each example. The higher the line is in the upper left-hand corner, the better the classifier in general. AUC computes the area under this curve. For a perfect classifier, AUC = 1, for a random guess, AUC=0.5. Objective: maximize.\n\n\nA Reciever Operator Characteristic (ROC) curve, from which the Area Under the Curve (AUC) can be calculated.\n\n\n\nFor additional discussion of classification error metrics, see Tharwat 2018, for example.\n\n\n\n\n\n\n\nChallenge 1\n\n\n\n\nIn the case of patients with a rare disease, what can be the problem of using accuracy to evaluate the performance of a machine learning model.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAccuracy is calculated as the (TP + TN)/(total) number of cases in the dataset. If you have very few positive cases, such as when working with a rare disease, the numerator of this fraction will be dominated by the true negatives you accurately predict in your dataset - so not very informative when assessing whether your classifier predicts the disease well at all!\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(workflows)\nlibrary(tune)\nlibrary(vip)\nlibrary(ParallelLogger)\nlibrary(doParallel)\nlibrary(workflowsets)\nlibrary(qs)\ntheme_set(theme_minimal())\n\ndiabetes_rec <- qread(\"../_models/diabetes_rec.qs\")\ndiabetes_folds <- qread(\"../_models/diabetes_folds.qs\")\nd_na_train <- qread(\"../_models/d_na_train.qs\")\nd_na_test <- qread(\"../_models/d_na_test.qs\")\ndiabetes_split <- qread(\"../_models/diabetes_split.qs\")"
  },
  {
    "objectID": "200_classification/step2.html#some-classification-models",
    "href": "200_classification/step2.html#some-classification-models",
    "title": "Sydney Informatics Hub",
    "section": "Some classification models",
    "text": "Some classification models\nTree-based models\n\nA tree-based model is a type of algorithm that creates a tree-like structure to make predictions about a certain outcome, such as whether a customer will buy a product or not. The tree structure consists of nodes that represent different features, and the algorithm uses these features to split the data into smaller and smaller subsets. Each subset is then assigned a label based on the majority of its observations, and this process continues until the algorithm reaches a stopping criterion or has created a fully-grown tree. Once the tree is created, it can be used to make predictions by following the path through the tree that corresponds to a given set of input features. Tree-based models are simple and intuitive to understand, and can be used for both classification and regression tasks.\n\nDecision trees are a simple type of tree-based model that use a hierarchical structure of nodes to make predictions about a certain outcome. The process continues until a stopping criterion is met, such as a maximum tree depth or a minimum number of observations per leaf node, and it can predict the outcome. A single decision tree may not be accurate enough for many real-world problems; \nRandom forest overcomes this limitation by building many decision trees, each using a randomly selected subset of the data and features, and then combining their predictions to make a final prediction.\nLogistic regression\n\nLogistic regression is a type of regression where the range of mapping is confined to [0,1], unlike simple linear regression models where the domain and range could take any real value. Logistic regression is a type of algorithm that is used to predict a binary outcome, such as whether a patient is likely to develop diabetes or no. It works by creating a mathematical function that predicts the probability of an observation belonging to a certain class (e.g., diabetes or not diabetes). The function takes into account one or more input variables, such as the patients’s age, gender, or body mass index. The output of the function is a value between 0 and 1, which represents the probability of the observation belonging to the positive class (e.g., developing diabetes). To make a prediction, the algorithm compares the predicted probability to a threshold value (e.g., 0.5), and assigns the observation to the positive class if the probability is greater than the threshold, and to the negative class otherwise. The scatter plot of this data looks something like this:  We see that the data points are in the two extreme clusters. For our prediction modeling, a naive regression line in this scenario will give a nonsense fit (red line on the right plot) and what we actually require to fit is a line (blue on the right plot) to explain (or to correctly separate) a maximum number of data points. Logistic regression is a scheme to search this most optimum blue line.\nRegularization is a technique that can be used to prevent overfitting of the model. A regularized logistic regression model, is a logistic classifier that has been modified to include a regularization term. This is done by adding a penalty to the model that discourages it from giving too much importance to any variable.\nThere are several regularized regression models, defined with the mixture parameter:\n\n\nRidge regularization encourages the model to have small coefficient values (mixture = 0);\n\nLasso regularization encourages the model to set some of the coefficients to zero, which performs feature selection. This can help improve the model’s interpretability and reduce the impact of irrelevant features on the model’s performance (mixture = 1);\n\nElastic Net regularization combines Ridge and Lasso regularization by adding a penalty term that is a weighted average of both penalties. This approach can provide the benefits of both Ridge and Lasso regularization, such as feature selection and coefficient shrinkage (mixture between 0 and 1)."
  },
  {
    "objectID": "200_classification/step2.html#tune-model-hyperparameters",
    "href": "200_classification/step2.html#tune-model-hyperparameters",
    "title": "Sydney Informatics Hub",
    "section": "Tune model hyperparameters",
    "text": "Tune model hyperparameters\n\nSome model parameters cannot be learned directly from a dataset during model training; these kinds of parameters are called hyperparameters. Some examples of hyperparameters include the number of randomly selected variables to be considered at each split in a tree-based model (called mtry in tidymodels).\nInstead of learning these kinds of hyperparameters during model training, we can estimate the best values for these values by training many models on a resampled data set (like the cross-validation folds we have previously created) and measuring how well all these models perform. This process is called *tuning.\nYou can identify which parameters to tune() in a model specification.\nWe can specify a random forest classifier with the following hyperparameters:\n\n\nmtry: the number of predictors that will be randomly sampled at each split when creating the tree models;\n\ntrees: the number of decision trees to fit and ultimately average;\n\nmin_n: The minimum number of data points in a node that are required for the node to be split further.\n\nTo specify a random forest model with tidymodels, we need the rand_forest() function. The hyperparameters of the model are arguments within the rand_forest() function and may be set to specific values. However, if tuning is required, then each of these parameters must be set to tune().\nWe will be using the ranger engine. This engine has an optional importance argument which can be used to track variable importance measures. In order to make a variable importance plot with vip(), we must add importance = 'impurity' inside our set_engine() function:\n\nrf_model_diabetes <- \n  # specify that the model is a random forest and which hyperparameters need to be tuned\n  rand_forest(mtry = tune(),\n              trees = tune(),\n              min_n = tune()) %>%\n  # select the engine/package that underlies the model\n  set_engine(\"ranger\", importance = \"impurity\") %>% #get variable importance scores\n  # choose either the continuous regression or binary classification mode\n  set_mode(\"classification\") \n\nrlr_model_diabetes <- \n  logistic_reg(mixture = tune(), penalty = tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\n\nNote Nothing about this model specification is specific to the diabetes dataset.\n\nFind which parameters will give the model its best accuracy\n\n\nTry different values and measure their performance;\nFind good values for these parameters;\nOnce the value(s) of the parameter(s) are determined, a model can be finalized by fitting the model to the entire training set.\n\n\nYou have a couple of options for how to choose which possible values for the tuning parameters to try. One of these options is creating a random grid of values. Random grid search is implemented with the grid_random() function in tidymodels, taking a sequence of hyperparameter names to create the grid. It also has a size parameter that specifies the number of random combinations to create.\nThe mtry() hyperparameter requires a pre-set range of values to test since it cannot exceed the number of columns in our data. When we add this to grid_random() we can pass mtry() into the range_set() function and set a range for the hyperparameter with a numeric vector.\nIn the code below, we set the range from 3 to 6. This is because we have 9 columns in diabetes_data and we would like to test mtry() values somewhere in the middle between 1 and 9, trying to avoid values close to the ends.\nWhen using grid_random(), it is suggested to use set.seed() for reproducibility.\nWe can then use the function tune_grid() to tune either a workflow or a model specification with a set of resampled data, such as the cross-validation we created. Grid search, combined with resampling, requires fitting a lot of models! These models don’t depend on one another and can be run in parallel.\n\nset.seed(314)\n\nrf_grid <- grid_random(mtry() %>% range_set(c(3, 6)),\n                       trees(),\n                       min_n(),\n                       size = 10)\n\n#View grid\nrf_grid\n\n# A tibble: 10 × 3\n    mtry trees min_n\n   <int> <int> <int>\n 1     4  1644    34\n 2     6  1440    20\n 3     6  1549    31\n 4     5  1734    39\n 5     6   332    11\n 6     5  1064     3\n 7     5   218    37\n 8     4  1304    24\n 9     4   477    32\n10     5  1621     6\n\n#Tune random forest model \nrf_tune_model <- tune_grid(\n  rf_model_diabetes,  #your model\n  diabetes_rec,       #your recipe\n  resamples = diabetes_folds, #your resampling\n  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity),\n  grid = rf_grid)\n\nrf_tune_model\n\n# Tuning results\n# 10-fold cross-validation repeated 5 times using stratification \n# A tibble: 50 × 5\n   splits           id      id2    .metrics          .notes          \n   <list>           <chr>   <chr>  <list>            <list>          \n 1 <split [483/54]> Repeat1 Fold01 <tibble [40 × 7]> <tibble [0 × 3]>\n 2 <split [483/54]> Repeat1 Fold02 <tibble [40 × 7]> <tibble [0 × 3]>\n 3 <split [483/54]> Repeat1 Fold03 <tibble [40 × 7]> <tibble [0 × 3]>\n 4 <split [483/54]> Repeat1 Fold04 <tibble [40 × 7]> <tibble [0 × 3]>\n 5 <split [483/54]> Repeat1 Fold05 <tibble [40 × 7]> <tibble [0 × 3]>\n 6 <split [483/54]> Repeat1 Fold06 <tibble [40 × 7]> <tibble [0 × 3]>\n 7 <split [483/54]> Repeat1 Fold07 <tibble [40 × 7]> <tibble [0 × 3]>\n 8 <split [484/53]> Repeat1 Fold08 <tibble [40 × 7]> <tibble [0 × 3]>\n 9 <split [484/53]> Repeat1 Fold09 <tibble [40 × 7]> <tibble [0 × 3]>\n10 <split [484/53]> Repeat1 Fold10 <tibble [40 × 7]> <tibble [0 × 3]>\n# … with 40 more rows\n\n\nUse collect_metrics to extract the metrics calculated from the cross-validation performance across the different values of the parameters:\n\n#collect metrics\nrf_tune_model %>%\n  collect_metrics()\n\n# A tibble: 40 × 9\n    mtry trees min_n .metric     .estimator  mean     n std_err .config         \n   <int> <int> <int> <chr>       <chr>      <dbl> <int>   <dbl> <chr>           \n 1     4  1644    34 accuracy    binary     0.764    50 0.00643 Preprocessor1_M…\n 2     4  1644    34 roc_auc     binary     0.847    50 0.00645 Preprocessor1_M…\n 3     4  1644    34 sensitivity binary     0.855    50 0.00772 Preprocessor1_M…\n 4     4  1644    34 specificity binary     0.592    50 0.0153  Preprocessor1_M…\n 5     6  1440    20 accuracy    binary     0.764    50 0.00634 Preprocessor1_M…\n 6     6  1440    20 roc_auc     binary     0.842    50 0.00654 Preprocessor1_M…\n 7     6  1440    20 sensitivity binary     0.852    50 0.00733 Preprocessor1_M…\n 8     6  1440    20 specificity binary     0.597    50 0.0144  Preprocessor1_M…\n 9     6  1549    31 accuracy    binary     0.759    50 0.00626 Preprocessor1_M…\n10     6  1549    31 roc_auc     binary     0.843    50 0.00635 Preprocessor1_M…\n# … with 30 more rows\n\n#see which model performed the best, in terms of some given metric\nrf_tune_model %>%\n  show_best(\"roc_auc\")\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     4  1644    34 roc_auc binary     0.847    50 0.00645 Preprocessor1_Model01\n2     4  1304    24 roc_auc binary     0.846    50 0.00643 Preprocessor1_Model08\n3     4   477    32 roc_auc binary     0.845    50 0.00633 Preprocessor1_Model09\n4     5  1734    39 roc_auc binary     0.845    50 0.00647 Preprocessor1_Model04\n5     5   218    37 roc_auc binary     0.844    50 0.00650 Preprocessor1_Model07\n\n\n\n\n\n\n\n\nChallenge X\n\n\n\nUse tune_grid and collect_metrics to tune a workflow. Hints:\nUse workflow() to define the workflow:\n\n#set the workflow\n\n#add the recipe\n\n#add the model\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#set the workflow\nrf_workflow <- workflow() %>%\n#add the recipe\nadd_recipe(diabetes_rec) %>%\n#add the model\n  add_model(rf_model_diabetes)\n\n#tune the workflow\nset.seed(22)\n\nrf_tune_wf <- rf_workflow %>%\n  tune_grid(resamples = diabetes_folds,\n            metrics = metric_set(accuracy, roc_auc, sensitivity, specificity),\n            grid = rf_grid)\n\nrf_tune_wf %>%\n  collect_metrics()\n\n# A tibble: 40 × 9\n    mtry trees min_n .metric     .estimator  mean     n std_err .config         \n   <int> <int> <int> <chr>       <chr>      <dbl> <int>   <dbl> <chr>           \n 1     4  1644    34 accuracy    binary     0.762    50 0.00639 Preprocessor1_M…\n 2     4  1644    34 roc_auc     binary     0.847    50 0.00640 Preprocessor1_M…\n 3     4  1644    34 sensitivity binary     0.857    50 0.00783 Preprocessor1_M…\n 4     4  1644    34 specificity binary     0.584    50 0.0142  Preprocessor1_M…\n 5     6  1440    20 accuracy    binary     0.762    50 0.00640 Preprocessor1_M…\n 6     6  1440    20 roc_auc     binary     0.842    50 0.00659 Preprocessor1_M…\n 7     6  1440    20 sensitivity binary     0.851    50 0.00736 Preprocessor1_M…\n 8     6  1440    20 specificity binary     0.595    50 0.0146  Preprocessor1_M…\n 9     6  1549    31 accuracy    binary     0.761    50 0.00648 Preprocessor1_M…\n10     6  1549    31 roc_auc     binary     0.843    50 0.00661 Preprocessor1_M…\n# … with 30 more rows\n\nrf_tune_wf %>%\n  show_best(\"roc_auc\")\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     4  1644    34 roc_auc binary     0.847    50 0.00640 Preprocessor1_Model01\n2     4   477    32 roc_auc binary     0.846    50 0.00639 Preprocessor1_Model09\n3     4  1304    24 roc_auc binary     0.846    50 0.00641 Preprocessor1_Model08\n4     5  1734    39 roc_auc binary     0.845    50 0.00643 Preprocessor1_Model04\n5     5   218    37 roc_auc binary     0.845    50 0.00628 Preprocessor1_Model07\n\n\n\n\n\nLet’s visualise our results:\n\nautoplot(rf_tune_model)\n\n\n\nautoplot(rf_tune_wf)\n\n\n\n\nWe can also specify the values of the parameters to tune with an tuning grid, entered as a data frame. It contains all the combinations of parameters to be tested. For regularized logistic regression, we test eleven values of mixture:\n\n#set the grid\nrlr_grid <- data.frame(mixture = seq(0, 1, 0.1),\n                       penalty = seq(0, 1, 0.1))\nrlr_grid\n\n   mixture penalty\n1      0.0     0.0\n2      0.1     0.1\n3      0.2     0.2\n4      0.3     0.3\n5      0.4     0.4\n6      0.5     0.5\n7      0.6     0.6\n8      0.7     0.7\n9      0.8     0.8\n10     0.9     0.9\n11     1.0     1.0\n\nset.seed(435)\n\n##use tune_grid() for hyperparameters tuning, doing cross validation for each row of the tuning grid\nrlr_tune_model <- tune_grid(\n  rlr_model_diabetes,  #your model\n  diabetes_rec,       #your recipe\n  resamples = diabetes_folds, #your resampling\n  grid = rlr_grid)\n\nrlr_tune_model %>%\n  collect_metrics()\n\n# A tibble: 22 × 8\n   penalty mixture .metric  .estimator  mean     n  std_err .config             \n     <dbl>   <dbl> <chr>    <chr>      <dbl> <int>    <dbl> <chr>               \n 1     0       0   accuracy binary     0.747    50 0.00649  Preprocessor1_Model…\n 2     0       0   roc_auc  binary     0.838    50 0.00623  Preprocessor1_Model…\n 3     0.1     0.1 accuracy binary     0.756    50 0.00596  Preprocessor1_Model…\n 4     0.1     0.1 roc_auc  binary     0.839    50 0.00620  Preprocessor1_Model…\n 5     0.2     0.2 accuracy binary     0.751    50 0.00602  Preprocessor1_Model…\n 6     0.2     0.2 roc_auc  binary     0.837    50 0.00603  Preprocessor1_Model…\n 7     0.3     0.3 accuracy binary     0.681    50 0.00402  Preprocessor1_Model…\n 8     0.3     0.3 roc_auc  binary     0.805    50 0.00690  Preprocessor1_Model…\n 9     0.4     0.4 accuracy binary     0.652    50 0.000801 Preprocessor1_Model…\n10     0.4     0.4 roc_auc  binary     0.783    50 0.00742  Preprocessor1_Model…\n# … with 12 more rows\n\nrlr_tune_model %>%\n  show_best(\"roc_auc\")\n\n# A tibble: 5 × 8\n  penalty mixture .metric .estimator  mean     n std_err .config              \n    <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     0.1     0.1 roc_auc binary     0.839    50 0.00620 Preprocessor1_Model02\n2     0       0   roc_auc binary     0.838    50 0.00623 Preprocessor1_Model01\n3     0.2     0.2 roc_auc binary     0.837    50 0.00603 Preprocessor1_Model03\n4     0.3     0.3 roc_auc binary     0.805    50 0.00690 Preprocessor1_Model04\n5     0.4     0.4 roc_auc binary     0.783    50 0.00742 Preprocessor1_Model05\n\n\nThe workflowsets package\n\nTidymodels allows us to perform all of the above steps in a much faster way with the workflowsets package:\n\ndiabetes_wf_set <- workflow_set(list(diabetes_rec),  #list of recipes\n             list(rf_model_diabetes, rlr_model_diabetes), #list of models\n             cross = TRUE) #all combinations of the preprocessors and models are used to create the workflows\n  \ndiabetes_wf_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id            info             option    result    \n  <chr>               <list>           <list>    <list>    \n1 recipe_rand_forest  <tibble [1 × 4]> <opts[0]> <list [0]>\n2 recipe_logistic_reg <tibble [1 × 4]> <opts[0]> <list [0]>\n\n# setting the parameters on each workflow seperately\nrf_params <- diabetes_wf_set %>%\n  extract_workflow(\"recipe_rand_forest\") %>%\n  parameters() %>%\n  update(mtry = mtry(c(3,6)),\n         trees = trees(c(1, 10)),\n         min_n = min_n(c(1, 10)))\n\nrlr_params <- diabetes_wf_set %>%\n  extract_workflow(\"recipe_logistic_reg\") %>%\n  parameters() %>%\n  update(mixture = mixture(c(0, 1)),\n         penalty = penalty(c(1,2)))\n  \ndiabetes_wf_set <- diabetes_wf_set %>%\n  workflow_map(\"tune_grid\", # the first argument is a function name from the tune package (tune_grid(), fit_resamples()..)\n               resamples = diabetes_folds,\n               verbose = TRUE) \n\n\ndiabetes_wf_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id            info             option    result   \n  <chr>               <list>           <list>    <list>   \n1 recipe_rand_forest  <tibble [1 × 4]> <opts[1]> <tune[+]>\n2 recipe_logistic_reg <tibble [1 × 4]> <opts[1]> <tune[+]>\n\n\nThe results column contains the results of each call to tune_grid() for the workflows. From these results, we can get quick assessments of how well these models classified the data:\n\n#To get the rankings of the models (and their tuning parameter sub-models) as a data frame:\nrank_results(diabetes_wf_set, rank_metric = \"roc_auc\")\n\n# A tibble: 40 × 9\n   wflow_id           .config    .metric  mean std_err     n prepr…¹ model  rank\n   <chr>              <chr>      <chr>   <dbl>   <dbl> <int> <chr>   <chr> <int>\n 1 recipe_rand_forest Preproces… accura… 0.766 0.00669    50 recipe  rand…     1\n 2 recipe_rand_forest Preproces… roc_auc 0.849 0.00610    50 recipe  rand…     1\n 3 recipe_rand_forest Preproces… accura… 0.771 0.00625    50 recipe  rand…     2\n 4 recipe_rand_forest Preproces… roc_auc 0.848 0.00621    50 recipe  rand…     2\n 5 recipe_rand_forest Preproces… accura… 0.764 0.00646    50 recipe  rand…     3\n 6 recipe_rand_forest Preproces… roc_auc 0.847 0.00635    50 recipe  rand…     3\n 7 recipe_rand_forest Preproces… accura… 0.764 0.00656    50 recipe  rand…     4\n 8 recipe_rand_forest Preproces… roc_auc 0.845 0.00646    50 recipe  rand…     4\n 9 recipe_rand_forest Preproces… accura… 0.762 0.00665    50 recipe  rand…     5\n10 recipe_rand_forest Preproces… roc_auc 0.843 0.00654    50 recipe  rand…     5\n# … with 30 more rows, and abbreviated variable name ¹​preprocessor\n\n#plot the results\nautoplot(diabetes_wf_set, metric = \"roc_auc\")\n\n\n\n\nThis shows the results for all tuning parameter combinations for each model. It looks like the random forest model did well. We can use the extract_workflow_set_result() function to extract the tuning results:\n\nbest_results <- diabetes_wf_set %>%\n  extract_workflow_set_result(\"recipe_rand_forest\") %>%\n  select_best(metric=\"roc_auc\")\n\nbest_results\n\n# A tibble: 1 × 4\n   mtry trees min_n .config              \n  <int> <int> <int> <chr>                \n1     2   983    30 Preprocessor1_Model10\n\n\nUpdate and fit the workflow\n\nThe last step in hyperparameter tuning is to use finalize_workflow() to add our optimal model to our workflow object, and apply the last_fit() function to our workflow and our train/test split object. This will automatically train the model specified by the workflow using the training data, and produce evaluations based on the test set:\n\nfinal_diabetes_fit <- diabetes_wf_set %>%\n  extract_workflow(\"recipe_rand_forest\") %>%\n  finalize_workflow(best_results) %>%\n  last_fit(diabetes_split)\n\nfinal_diabetes_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [537/231]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nSince we supplied the train/test object when we fit the workflow, the metrics are evaluated on the test set. Now when we use the collect_metrics() function (the same we used when tuning our parameters) to extract the performance of the final model (since rf_fit_final now consists of a single final model) applied to the test set:\n\ntest_performance <- final_diabetes_fit %>% collect_metrics()\ntest_performance\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.753 Preprocessor1_Model1\n2 roc_auc  binary         0.819 Preprocessor1_Model1\n\n\nWe can plot the ROC curve to visualize test set performance of our random forest model, and generate a confusion matrix:\nNote In R, factor levels are ordered alphabetically by default, which means that “no” comes first before “yes” and is considered the level of interest or positive case. Use the argument event_level = \"second\" to alter this as needed.\n\n#ROC curve\n  collect_predictions(final_diabetes_fit) %>%\n  roc_curve(truth  = diabetes, event_level=\"second\", estimate = .pred_pos) %>%  #specify which level of truth to                                                                                       consider as the \"event\"\n                autoplot()\n\n\n\n#confusion matrix\nconf_matrix_rf <- final_diabetes_fit %>%\n  collect_predictions() %>%\n  conf_mat(truth = diabetes, estimate = .pred_class) \n\nconf_matrix_rf\n\n          Truth\nPrediction neg pos\n       neg 128  35\n       pos  22  46\n\nconf_matrix_rf %>%\n  autoplot()\n\n\n\n\nVariable importance\n\nIn order to visualize the variable importance scores of our random forest model, we will need to manually train our workflow object with the fit() function on the training data, then extract the trained model with the pull_workflow_fit() function, and next passing the trained model to the vip() function:\n\n#extract the final workflow\nfinal_workflow <- diabetes_wf_set %>%\n  extract_workflow(\"recipe_rand_forest\") %>%\n  finalize_workflow(best_results)\n\n#fit on the training data\nwf_fit <- final_workflow %>%\n  fit(data = d_na_train)\n#extract the trained model\nwf_fit <- wf_fit %>% \n          pull_workflow_fit()\n#plot variable importance\nvip(wf_fit)\n\n\n\n\nThis returns a ggplot object with the variable importance scores from our model.\nWe see from the results below, that the glucose concentration, body mass index and age are the most important predictors of diabetes.\n\n\n\n\n\n\nKey Points\n\n\n\n\nA workflow is a combination of a model and preprocessors (e.g, a formula, recipe, etc.);\nIn order to try different combinations of these, the workflow_set() function creates an object that contains many workflows;\nThe workflow_map() executes the function from the tune package (e.g, tune_grid(), fit_resamples()) across all the workflows in the set.\n\n\n\n\nAdapted from “Decision Trees and Random Forests”, available here.\nAdapted from “Machine Learning with tidymodels” workshop, licensed CC Y-SA 4.0. Available here."
  },
  {
    "objectID": "200_classification/step1.html",
    "href": "200_classification/step1.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\nUse tidyverse functions for exploratory data analysis;\nIntroduce and explore the Pima Indians Diabetes dataset;\nImpute missing data.\n\n\n\n\n\nToday, we are going to be working with Pima Indian Women’s diabetes dataset which contains information on 768 Pima Indian women’s diabetes status, as well as many predictive features:\n\npregnant - Number of times pregnant\nglucose - Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\npressure - Diastolic blood pressure (mm Hg)\ntriceps - Triceps skin fold thickness (mm) - a measure correlated with body fat\n\ninsulin - 2-Hour serum insulin (mu U/ml)\nmass - Body mass index (weight in kg/(height in m)^2)\nage - Age (years)\ndiabetes - diabetes status (pos - diabetic; neg - non-diabetic)\npedigree - diabetes pedigree function\n\nThe diabetes pedigree function was developed by Smith 1988 to provide a synthesis ofthe diabetes mellitus history in relatives and the genetic relationship of those relatives to the subject. It uses information from parents, grandparents, siblings, aunts and uncles, and first cousin to provide a measure of the expected genetic influence of affected and unaffected relatives on the subject’s eventual diabetes risk.\nThe Pima Indians are a group of Native Americans living in an area consisting of what is now central and southern Arizona. The short name, “Pima” is believed to have come from a phrase meaning “I don’t know,” which they used repeatedly in their initial meetings with Spanish colonists. Thanks Wikipedia!\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggcorrplot)\nlibrary(GGally)\nlibrary(qs)\nlibrary(mlbench)\ntheme_set(theme_minimal())\n\nLoad data:\n\n# load the Pima Indians dataset from the mlbench dataset\ndata(PimaIndiansDiabetes)\n# rename dataset to have shorter name because lazy\ndiabetes_data <- PimaIndiansDiabetes\n# look at the variable names\nnames(diabetes_data)\n\n[1] \"pregnant\" \"glucose\"  \"pressure\" \"triceps\"  \"insulin\"  \"mass\"     \"pedigree\"\n[8] \"age\"      \"diabetes\"\n\n# look at the data\nglimpse(diabetes_data)\n\nRows: 768\nColumns: 9\n$ pregnant <dbl> 6, 1, 8, 1, 0, 5, 3, 10, 2, 8, 4, 10, 10, 1, 5, 7, 0, 7, 1, 1…\n$ glucose  <dbl> 148, 85, 183, 89, 137, 116, 78, 115, 197, 125, 110, 168, 139,…\n$ pressure <dbl> 72, 66, 64, 66, 40, 74, 50, 0, 70, 96, 92, 74, 80, 60, 72, 0,…\n$ triceps  <dbl> 35, 29, 0, 23, 35, 0, 32, 0, 45, 0, 0, 0, 0, 23, 19, 0, 47, 0…\n$ insulin  <dbl> 0, 0, 0, 94, 168, 0, 88, 0, 543, 0, 0, 0, 0, 846, 175, 0, 230…\n$ mass     <dbl> 33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.5, 0.0, 37…\n$ pedigree <dbl> 0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.134, 0.158…\n$ age      <dbl> 50, 31, 32, 21, 33, 30, 26, 29, 53, 54, 30, 34, 57, 59, 51, 3…\n$ diabetes <fct> pos, neg, pos, neg, pos, neg, pos, neg, pos, pos, neg, pos, n…\n\n\nLook for missing data:\n\nanyNA(diabetes_data)\n\n[1] FALSE\n\n\nIt seems like there is no missing data.\nGet a summary of the data frame:\n\nsummary(diabetes_data)\n\n    pregnant         glucose         pressure         triceps     \n Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  \n 1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  \n Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  \n Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  \n 3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  \n Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  \n    insulin           mass          pedigree           age        diabetes \n Min.   :  0.0   Min.   : 0.00   Min.   :0.0780   Min.   :21.00   neg:500  \n 1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437   1st Qu.:24.00   pos:268  \n Median : 30.5   Median :32.00   Median :0.3725   Median :29.00            \n Mean   : 79.8   Mean   :31.99   Mean   :0.4719   Mean   :33.24            \n 3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262   3rd Qu.:41.00            \n Max.   :846.0   Max.   :67.10   Max.   :2.4200   Max.   :81.00            \n\n\n\n\n\n\n\n\nExercise:\n\n\n\nLook at the output of summary above and the table that explains what each of the variables are. Do the values make sense for all of: - (a) Pregnancies and Glucose - (b) Blood pressure and Skin thickness - (c) Insulin and DiabetesPedigreeFunction, and - (d) BMI and Age\nIf not, how do you think we should deal with them? Can you hypothesise what the consequences of this approach would be?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#Possibly missing: \n\ncolSums(diabetes_data == 0)\n\npregnant  glucose pressure  triceps  insulin     mass pedigree      age \n     111        5       35      227      374       11        0        0 \ndiabetes \n       0 \n\n#Not missing:\n\ncolSums(diabetes_data != 0)\n\npregnant  glucose pressure  triceps  insulin     mass pedigree      age \n     657      763      733      541      394      757      768      768 \ndiabetes \n     768 \n\n\nIt is clear that the values of several variables are zero when it is impossible for them to be so (i.e. this value could not be zero if it was measured). Hence, we are dealing with “hidden” missing data, and should recode it as NA.\nThe following variables have zero “values” that are actually likely to be missing:\n\nGlucose (a)\nBloodPressure (b)\nSkinThickness (b)\nInsulin (c)\nBMI (d)\n\n\n\n\n\n\n\nggplot(diabetes_data, aes(x = pregnant, fill = diabetes)) + geom_bar(position = \"dodge\")\n\n\n\n\n\nggplot(\n  diabetes_data,\n  aes(\n    x = pressure,\n    y = glucose,\n    color = diabetes\n  )\n) + geom_point(alpha = 0.5)\n\n\n\n\nIf we wanted to look at all possible scatterplot pairs we would do something like:\n\n# make a pair plot\nggpairs(data = diabetes_data, \n        mapping = aes(color = diabetes),\n        upper = list(combo = \"box\"))\n\n\n\n\nBut it’s easier to look at a correlation plot:\n\n# get a correlation matrix of the variables in the diabetes dataset:\ndiabetes_corr <- diabetes_data %>%\n  # recode outcome to be numeric (subtract 1 to return it to zero/one)\n  mutate(diabetes = as.integer(diabetes) - 1) %>%\n  cor()\n\nggcorrplot(diabetes_corr, type = \"lower\", lab = TRUE )\n\n\n\n\nLet’s create a new dataframe d_na, which has the missing values recoded as NA:\n\nd_na <- diabetes_data %>%\n  mutate(glucose = na_if(glucose, 0)) %>%\n  mutate(triceps = na_if(triceps, 0)) %>%\n  mutate(insulin = na_if(insulin, 0)) %>%\n  mutate(mass = na_if(mass, 0)) %>%\n  mutate(pressure = na_if(pressure, 0))\n\n# approximately half of the dataset is complete, whereas half is missing data\ntable(complete.cases(d_na))\n\n\nFALSE  TRUE \n  376   392 \n\nnaniar::gg_miss_var(d_na)\n\n\n\nvisdat::vis_dat(d_na)\n\n\n\n\nLet’s compare the correlation plot from before with another one now that we’ve correctly labelled the missing data:\n\ndiabetes_corr_na <-\n  d_na %>%\n  # recode outcome to be numeric (subtract 1 to return it to zero/one)\n  mutate(diabetes = as.integer(diabetes) - 1) %>%\n  # use pairwise complete observations for the two variables\n  cor(use = \"pairwise.complete.obs\")\n\nggcorrplot(diabetes_corr_na,  type = \"lower\",lab = TRUE)\n\n\n\n\nNotice that the correlation between some variables (eg. pregnant - insulin) changes quite substantially. (Negative before to Positive now).\n\n\nWe’re going to split our data into 70% training and 30% testing sets.\n\nset.seed(42) # so we all get the same results\n\ndiabetes_split <- initial_split(d_na , prop = 0.7, strata = \"diabetes\" )\nd_na_train <- training(diabetes_split)\nd_na_test <- testing(diabetes_split)\n\nqsave(d_na_train, \"../_models/d_na_train.qs\")\nqsave(d_na_test, \"../_models/d_na_test.qs\")\nqsave(diabetes_split, \"../_models/diabetes_split.qs\")\n\n\nLook how many examples we have in the training and testing sets.\n\ndim(d_na_train)\n\n[1] 537   9\n\ndim(d_na_test)\n\n[1] 231   9\n\n\nPlot histograms of outputs to check we stratified appropriately\n\ntogether <- bind_rows(train = d_na_train,\n                      test = d_na_test,\n                      .id = \"test_train\" ) \n\ntogether %>%\n  ggplot(aes(x = diabetes))+\n  geom_bar()+\n  facet_grid(test_train~., scales = \"free\")\n\n\n\ntogether %>%\n  {ggduo(., \n         setdiff( names(.), c(\"test_train\", \"diabetes\") ), \n         # column names not including test_train or the outcome\n         \"test_train\")} # faceted by test_train split\n\n\n\n\nAt some point we’re going to want to do some parameter tuning (explained later), and to do that we’re going to want to use cross-validation. So we can create a cross-validated version of the training set in preparation for that moment:\n\ndiabetes_folds <- vfold_cv(d_na_train, v=10, repeats = 5, strata = diabetes)\n\nqsave(diabetes_folds, \"../_models/diabetes_folds.qs\")\n\n\n\nImputation is often used to handle missing data because many statistical methods and machine learning algorithms require complete data. When we do imputation, we aren’t adding new information to our dataset, but we are using the patterns in our dataset so that we don’t have to throw away the data that have some variables missing. We can impute the missing data using a recipe:\n\n# set seed to be 42 so everyone gets the same results\nset.seed(42)\ndiabetes_rec <-\n  d_na_train %>%\n  recipe(diabetes ~ .) %>%\n  # all our predictors are numeric so standardize them\n  step_normalize(all_numeric_predictors()) %>%\n  step_impute_median(all_predictors())\n\ndiabetes_rec  \n\nqsave(diabetes_rec, \"../_models/diabetes_rec.qs\")\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nClassification attempts to predict the class to which a particular observation belongs;\nThere are many different metrics for assessing performance for a classification problem;\nWhich metric you choose and optimise for should be considered carefully, and will be different depending on the problem;\nExporatory data analysis is a time consuming but critical process that needs to be carried out prior to any modeling."
  },
  {
    "objectID": "200_classification/step1.html#pima-indians-diabetes",
    "href": "200_classification/step1.html#pima-indians-diabetes",
    "title": "Sydney Informatics Hub",
    "section": "Pima Indians Diabetes",
    "text": "Pima Indians Diabetes\n\nToday, we are going to be working with Pima Indian Women’s diabetes dataset which contains information on 768 Pima Indian women’s diabetes status, as well as many predictive features:\n\npregnant - Number of times pregnant\nglucose - Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\npressure - Diastolic blood pressure (mm Hg)\ntriceps - Triceps skin fold thickness (mm) - a measure correlated with body fat\n\ninsulin - 2-Hour serum insulin (mu U/ml)\nmass - Body mass index (weight in kg/(height in m)^2)\nage - Age (years)\ndiabetes - diabetes status (pos - diabetic; neg - non-diabetic)\npedigree - diabetes pedigree function\n\nThe diabetes pedigree function was developed by Smith 1988 to provide a synthesis ofthe diabetes mellitus history in relatives and the genetic relationship of those relatives to the subject. It uses information from parents, grandparents, siblings, aunts and uncles, and first cousin to provide a measure of the expected genetic influence of affected and unaffected relatives on the subject’s eventual diabetes risk.\nThe Pima Indians are a group of Native Americans living in an area consisting of what is now central and southern Arizona. The short name, “Pima” is believed to have come from a phrase meaning “I don’t know,” which they used repeatedly in their initial meetings with Spanish colonists. Thanks Wikipedia!\nLet’s Explore our data\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggcorrplot)\nlibrary(GGally)\nlibrary(qs)\nlibrary(mlbench)\ntheme_set(theme_minimal())\n\nLoad data:\n\n# load the Pima Indians dataset from the mlbench dataset\ndata(PimaIndiansDiabetes)\n# rename dataset to have shorter name because lazy\ndiabetes_data <- PimaIndiansDiabetes\n# look at the variable names\nnames(diabetes_data)\n\n[1] \"pregnant\" \"glucose\"  \"pressure\" \"triceps\"  \"insulin\"  \"mass\"     \"pedigree\"\n[8] \"age\"      \"diabetes\"\n\n# look at the data\nglimpse(diabetes_data)\n\nRows: 768\nColumns: 9\n$ pregnant <dbl> 6, 1, 8, 1, 0, 5, 3, 10, 2, 8, 4, 10, 10, 1, 5, 7, 0, 7, 1, 1…\n$ glucose  <dbl> 148, 85, 183, 89, 137, 116, 78, 115, 197, 125, 110, 168, 139,…\n$ pressure <dbl> 72, 66, 64, 66, 40, 74, 50, 0, 70, 96, 92, 74, 80, 60, 72, 0,…\n$ triceps  <dbl> 35, 29, 0, 23, 35, 0, 32, 0, 45, 0, 0, 0, 0, 23, 19, 0, 47, 0…\n$ insulin  <dbl> 0, 0, 0, 94, 168, 0, 88, 0, 543, 0, 0, 0, 0, 846, 175, 0, 230…\n$ mass     <dbl> 33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.5, 0.0, 37…\n$ pedigree <dbl> 0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.134, 0.158…\n$ age      <dbl> 50, 31, 32, 21, 33, 30, 26, 29, 53, 54, 30, 34, 57, 59, 51, 3…\n$ diabetes <fct> pos, neg, pos, neg, pos, neg, pos, neg, pos, pos, neg, pos, n…\n\n\nLook for missing data:\n\nanyNA(diabetes_data)\n\n[1] FALSE\n\n\nIt seems like there is no missing data.\nGet a summary of the data frame:\n\nsummary(diabetes_data)\n\n    pregnant         glucose         pressure         triceps     \n Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  \n 1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  \n Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  \n Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  \n 3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  \n Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  \n    insulin           mass          pedigree           age        diabetes \n Min.   :  0.0   Min.   : 0.00   Min.   :0.0780   Min.   :21.00   neg:500  \n 1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437   1st Qu.:24.00   pos:268  \n Median : 30.5   Median :32.00   Median :0.3725   Median :29.00            \n Mean   : 79.8   Mean   :31.99   Mean   :0.4719   Mean   :33.24            \n 3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262   3rd Qu.:41.00            \n Max.   :846.0   Max.   :67.10   Max.   :2.4200   Max.   :81.00            \n\n\n\n\n\n\n\n\nExercise:\n\n\n\nLook at the output of summary above and the table that explains what each of the variables are. Do the values make sense for all of: - (a) Pregnancies and Glucose - (b) Blood pressure and Skin thickness - (c) Insulin and DiabetesPedigreeFunction, and - (d) BMI and Age\nIf not, how do you think we should deal with them? Can you hypothesise what the consequences of this approach would be?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#Possibly missing: \n\ncolSums(diabetes_data == 0)\n\npregnant  glucose pressure  triceps  insulin     mass pedigree      age \n     111        5       35      227      374       11        0        0 \ndiabetes \n       0 \n\n#Not missing:\n\ncolSums(diabetes_data != 0)\n\npregnant  glucose pressure  triceps  insulin     mass pedigree      age \n     657      763      733      541      394      757      768      768 \ndiabetes \n     768 \n\n\nIt is clear that the values of several variables are zero when it is impossible for them to be so (i.e. this value could not be zero if it was measured). Hence, we are dealing with “hidden” missing data, and should recode it as NA.\nThe following variables have zero “values” that are actually likely to be missing:\n\nGlucose (a)\nBloodPressure (b)\nSkinThickness (b)\nInsulin (c)\nBMI (d)\n\n\n\n\nLet’s use visualisation to further explore the dataset\n\n\nggplot(diabetes_data, aes(x = pregnant, fill = diabetes)) + geom_bar(position = \"dodge\")\n\n\n\n\n\nggplot(\n  diabetes_data,\n  aes(\n    x = pressure,\n    y = glucose,\n    color = diabetes\n  )\n) + geom_point(alpha = 0.5)\n\n\n\n\nIf we wanted to look at all possible scatterplot pairs we would do something like:\n\n# make a pair plot\nggpairs(data = diabetes_data, \n        mapping = aes(color = diabetes),\n        upper = list(combo = \"box\"))\n\n\n\n\nBut it’s easier to look at a correlation plot:\n\n# get a correlation matrix of the variables in the diabetes dataset:\ndiabetes_corr <- diabetes_data %>%\n  # recode outcome to be numeric (subtract 1 to return it to zero/one)\n  mutate(diabetes = as.integer(diabetes) - 1) %>%\n  cor()\n\nggcorrplot(diabetes_corr, type = \"lower\", lab = TRUE )\n\n\n\n\nLet’s create a new dataframe d_na, which has the missing values recoded as NA:\n\nd_na <- diabetes_data %>%\n  mutate(glucose = na_if(glucose, 0)) %>%\n  mutate(triceps = na_if(triceps, 0)) %>%\n  mutate(insulin = na_if(insulin, 0)) %>%\n  mutate(mass = na_if(mass, 0)) %>%\n  mutate(pressure = na_if(pressure, 0))\n\n# approximately half of the dataset is complete, whereas half is missing data\ntable(complete.cases(d_na))\n\n\nFALSE  TRUE \n  376   392 \n\nnaniar::gg_miss_var(d_na)\n\n\n\nvisdat::vis_dat(d_na)\n\n\n\n\nLet’s compare the correlation plot from before with another one now that we’ve correctly labelled the missing data:\n\ndiabetes_corr_na <-\n  d_na %>%\n  # recode outcome to be numeric (subtract 1 to return it to zero/one)\n  mutate(diabetes = as.integer(diabetes) - 1) %>%\n  # use pairwise complete observations for the two variables\n  cor(use = \"pairwise.complete.obs\")\n\nggcorrplot(diabetes_corr_na,  type = \"lower\",lab = TRUE)\n\n\n\n\nNotice that the correlation between some variables (eg. pregnant - insulin) changes quite substantially. (Negative before to Positive now)."
  },
  {
    "objectID": "200_classification/step1.html#train-test-split",
    "href": "200_classification/step1.html#train-test-split",
    "title": "Sydney Informatics Hub",
    "section": "Train-Test Split",
    "text": "Train-Test Split\n\nWe’re going to split our data into 70% training and 30% testing sets.\n\nset.seed(42) # so we all get the same results\n\ndiabetes_split <- initial_split(d_na , prop = 0.7, strata = \"diabetes\" )\nd_na_train <- training(diabetes_split)\nd_na_test <- testing(diabetes_split)\n\nqsave(d_na_train, \"../_models/d_na_train.qs\")\nqsave(d_na_test, \"../_models/d_na_test.qs\")\nqsave(diabetes_split, \"../_models/diabetes_split.qs\")\n\nSome standard checks on the test/train split\nLook how many examples we have in the training and testing sets.\n\ndim(d_na_train)\n\n[1] 537   9\n\ndim(d_na_test)\n\n[1] 231   9\n\n\nPlot histograms of outputs to check we stratified appropriately\n\ntogether <- bind_rows(train = d_na_train,\n                      test = d_na_test,\n                      .id = \"test_train\" ) \n\ntogether %>%\n  ggplot(aes(x = diabetes))+\n  geom_bar()+\n  facet_grid(test_train~., scales = \"free\")\n\n\n\ntogether %>%\n  {ggduo(., \n         setdiff( names(.), c(\"test_train\", \"diabetes\") ), \n         # column names not including test_train or the outcome\n         \"test_train\")} # faceted by test_train split\n\n\n\n\nAt some point we’re going to want to do some parameter tuning (explained later), and to do that we’re going to want to use cross-validation. So we can create a cross-validated version of the training set in preparation for that moment:\n\ndiabetes_folds <- vfold_cv(d_na_train, v=10, repeats = 5, strata = diabetes)\n\nqsave(diabetes_folds, \"../_models/diabetes_folds.qs\")\n\nImpute missing data\n\nImputation is often used to handle missing data because many statistical methods and machine learning algorithms require complete data. When we do imputation, we aren’t adding new information to our dataset, but we are using the patterns in our dataset so that we don’t have to throw away the data that have some variables missing. We can impute the missing data using a recipe:\n\n# set seed to be 42 so everyone gets the same results\nset.seed(42)\ndiabetes_rec <-\n  d_na_train %>%\n  recipe(diabetes ~ .) %>%\n  # all our predictors are numeric so standardize them\n  step_normalize(all_numeric_predictors()) %>%\n  step_impute_median(all_predictors())\n\ndiabetes_rec  \n\nqsave(diabetes_rec, \"../_models/diabetes_rec.qs\")\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nClassification attempts to predict the class to which a particular observation belongs;\nThere are many different metrics for assessing performance for a classification problem;\nWhich metric you choose and optimise for should be considered carefully, and will be different depending on the problem;\nExporatory data analysis is a time consuming but critical process that needs to be carried out prior to any modeling."
  },
  {
    "objectID": "100_regression/step1.html",
    "href": "100_regression/step1.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\nUse Tidyverse functions for exploratory data analysis (EDA);\nExplore the Ames Housing dataset.\n\n\n\n\n\nFirst, let’s load the required packages. We will use the tidyverse for general data processing and visualisation.\n\nlibrary(tidyverse)\nlibrary(naniar) # for visualising missing data\nlibrary(GGally) # for EDA\nlibrary(ggcorrplot)\nlibrary(AmesHousing)\nlibrary(plotly) # dynamic visualisations\nlibrary(bestNormalize)\nlibrary(qs)\ntheme_set(theme_minimal())\n\nWe will use the Ames housing data to explore different ML approaches to regression. This dataset was “designed” by Dean De Cock as an alternative to the “classic” Boston housing dataset, and has been extensively used in ML teaching. It is also available from kaggle as part of its advanced regression practice competition.\nThe Ames Housing Data Documentation file describes the independent variables presented in the data. This includes:\n\n20 continuous variables relate to various area dimensions for each observation;\n14 discrete variables, which typically quantify the number of items occurring within the house;\n23 ordinal, 23 nominal categorical variables, with 2 (STREET: gravel or paved) - 28 (NEIGHBORHOOD) classes;\n\nWe will explore both the “uncleaned” data available from kaggle/UCI, and the processed data available in the AmesHousing package in R, for which documentation is available here. It can be useful for understanding what each of the independent variables mean.\n\nameshousing <- AmesHousing::make_ames()\n\n# Read in the uncleaned data. \nameshousing_uncleaned <- AmesHousing::ames_raw\n\n\n\nExploratory data analysis involves looking at:\n\nThe distribution of variables in your dataset;\nWhether any data is missing;\nData skewness;\nCorrelated variables.\n\n\n\n\n\n\n\nChallenge 1\n\n\n\n\nExplore the Ames Housing dataset.\n\nWhat can you figure out about the different variables?\nWhich do you think are more or less important?\n\n\nCompare the ameshousing variable, which is from the AmesHousing package in R and has been cleaned, with the ameshousing_uncleaned dataset, which is the raw data from the UCI machine learning repository.\n\nWhat was missing in the raw data?\nWhat are some of the approaches that have been taken to deal with missingness?\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can see that the “uncleaned” dataset has a lot of missing data, whereas it has been cleaned up for us in the “cleaned” one. In the interests of time, we will not focus here on how every variable in that dataset has been explored and cleaned up - however, it presents a good example of “messy” real-world data, so we would encourage you to try and look at a handful of variables at home, to see how they’ve been processed.\n\ndim(ameshousing)\n\n[1] 2930   81\n\nglimpse(ameshousing)\n\nRows: 2,930\nColumns: 81\n$ MS_SubClass        <fct> One_Story_1946_and_Newer_All_Styles, One_Story_1946…\n$ MS_Zoning          <fct> Residential_Low_Density, Residential_High_Density, …\n$ Lot_Frontage       <dbl> 141, 80, 81, 93, 74, 78, 41, 43, 39, 60, 75, 0, 63,…\n$ Lot_Area           <int> 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005…\n$ Street             <fct> Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pav…\n$ Alley              <fct> No_Alley_Access, No_Alley_Access, No_Alley_Access, …\n$ Lot_Shape          <fct> Slightly_Irregular, Regular, Slightly_Irregular, Re…\n$ Land_Contour       <fct> Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, HLS, Lvl, Lvl, L…\n$ Utilities          <fct> AllPub, AllPub, AllPub, AllPub, AllPub, AllPub, All…\n$ Lot_Config         <fct> Corner, Inside, Corner, Corner, Inside, Inside, Ins…\n$ Land_Slope         <fct> Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, G…\n$ Neighborhood       <fct> North_Ames, North_Ames, North_Ames, North_Ames, Gil…\n$ Condition_1        <fct> Norm, Feedr, Norm, Norm, Norm, Norm, Norm, Norm, No…\n$ Condition_2        <fct> Norm, Norm, Norm, Norm, Norm, Norm, Norm, Norm, Nor…\n$ Bldg_Type          <fct> OneFam, OneFam, OneFam, OneFam, OneFam, OneFam, Twn…\n$ House_Style        <fct> One_Story, One_Story, One_Story, One_Story, Two_Sto…\n$ Overall_Qual       <fct> Above_Average, Average, Above_Average, Good, Averag…\n$ Overall_Cond       <fct> Average, Above_Average, Above_Average, Average, Ave…\n$ Year_Built         <int> 1960, 1961, 1958, 1968, 1997, 1998, 2001, 1992, 199…\n$ Year_Remod_Add     <int> 1960, 1961, 1958, 1968, 1998, 1998, 2001, 1992, 199…\n$ Roof_Style         <fct> Hip, Gable, Hip, Hip, Gable, Gable, Gable, Gable, G…\n$ Roof_Matl          <fct> CompShg, CompShg, CompShg, CompShg, CompShg, CompSh…\n$ Exterior_1st       <fct> BrkFace, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Exterior_2nd       <fct> Plywood, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Mas_Vnr_Type       <fct> Stone, None, BrkFace, None, None, BrkFace, None, No…\n$ Mas_Vnr_Area       <dbl> 112, 0, 108, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6…\n$ Exter_Qual         <fct> Typical, Typical, Typical, Good, Typical, Typical, …\n$ Exter_Cond         <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Foundation         <fct> CBlock, CBlock, CBlock, CBlock, PConc, PConc, PConc…\n$ Bsmt_Qual          <fct> Typical, Typical, Typical, Typical, Good, Typical, …\n$ Bsmt_Cond          <fct> Good, Typical, Typical, Typical, Typical, Typical, …\n$ Bsmt_Exposure      <fct> Gd, No, No, No, No, No, Mn, No, No, No, No, No, No,…\n$ BsmtFin_Type_1     <fct> BLQ, Rec, ALQ, ALQ, GLQ, GLQ, GLQ, ALQ, GLQ, Unf, U…\n$ BsmtFin_SF_1       <dbl> 2, 6, 1, 1, 3, 3, 3, 1, 3, 7, 7, 1, 7, 3, 3, 1, 3, …\n$ BsmtFin_Type_2     <fct> Unf, LwQ, Unf, Unf, Unf, Unf, Unf, Unf, Unf, Unf, U…\n$ BsmtFin_SF_2       <dbl> 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1120, 0…\n$ Bsmt_Unf_SF        <dbl> 441, 270, 406, 1045, 137, 324, 722, 1017, 415, 994,…\n$ Total_Bsmt_SF      <dbl> 1080, 882, 1329, 2110, 928, 926, 1338, 1280, 1595, …\n$ Heating            <fct> GasA, GasA, GasA, GasA, GasA, GasA, GasA, GasA, Gas…\n$ Heating_QC         <fct> Fair, Typical, Typical, Excellent, Good, Excellent,…\n$ Central_Air        <fct> Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, …\n$ Electrical         <fct> SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SB…\n$ First_Flr_SF       <int> 1656, 896, 1329, 2110, 928, 926, 1338, 1280, 1616, …\n$ Second_Flr_SF      <int> 0, 0, 0, 0, 701, 678, 0, 0, 0, 776, 892, 0, 676, 0,…\n$ Low_Qual_Fin_SF    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Gr_Liv_Area        <int> 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616…\n$ Bsmt_Full_Bath     <dbl> 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, …\n$ Bsmt_Half_Bath     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Full_Bath          <int> 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, …\n$ Half_Bath          <int> 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ Bedroom_AbvGr      <int> 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 1, 4, 4, …\n$ Kitchen_AbvGr      <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Kitchen_Qual       <fct> Typical, Typical, Good, Excellent, Typical, Good, G…\n$ TotRms_AbvGrd      <int> 7, 5, 6, 8, 6, 7, 6, 5, 5, 7, 7, 6, 7, 5, 4, 12, 8,…\n$ Functional         <fct> Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, T…\n$ Fireplaces         <int> 2, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, …\n$ Fireplace_Qu       <fct> Good, No_Fireplace, No_Fireplace, Typical, Typical,…\n$ Garage_Type        <fct> Attchd, Attchd, Attchd, Attchd, Attchd, Attchd, Att…\n$ Garage_Finish      <fct> Fin, Unf, Unf, Fin, Fin, Fin, Fin, RFn, RFn, Fin, F…\n$ Garage_Cars        <dbl> 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, …\n$ Garage_Area        <dbl> 528, 730, 312, 522, 482, 470, 582, 506, 608, 442, 4…\n$ Garage_Qual        <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Garage_Cond        <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Paved_Drive        <fct> Partial_Pavement, Paved, Paved, Paved, Paved, Paved…\n$ Wood_Deck_SF       <int> 210, 140, 393, 0, 212, 360, 0, 0, 237, 140, 157, 48…\n$ Open_Porch_SF      <int> 62, 0, 36, 0, 34, 36, 0, 82, 152, 60, 84, 21, 75, 0…\n$ Enclosed_Porch     <int> 0, 0, 0, 0, 0, 0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Three_season_porch <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Screen_Porch       <int> 0, 120, 0, 0, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 140, …\n$ Pool_Area          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Pool_QC            <fct> No_Pool, No_Pool, No_Pool, No_Pool, No_Pool, No_Poo…\n$ Fence              <fct> No_Fence, Minimum_Privacy, No_Fence, No_Fence, Mini…\n$ Misc_Feature       <fct> None, None, Gar2, None, None, None, None, None, Non…\n$ Misc_Val           <int> 0, 0, 12500, 0, 0, 0, 0, 0, 0, 0, 0, 500, 0, 0, 0, …\n$ Mo_Sold            <int> 5, 6, 6, 4, 3, 6, 4, 1, 3, 6, 4, 3, 5, 2, 6, 6, 6, …\n$ Year_Sold          <int> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 201…\n$ Sale_Type          <fct> WD , WD , WD , WD , WD , WD , WD , WD , WD , WD , W…\n$ Sale_Condition     <fct> Normal, Normal, Normal, Normal, Normal, Normal, Nor…\n$ Sale_Price         <int> 215000, 105000, 172000, 244000, 189900, 195500, 213…\n$ Longitude          <dbl> -93.61975, -93.61976, -93.61939, -93.61732, -93.638…\n$ Latitude           <dbl> 42.05403, 42.05301, 42.05266, 42.05125, 42.06090, 4…\n\ncolSums(is.na(ameshousing_uncleaned))\n\n          Order             PID     MS SubClass       MS Zoning    Lot Frontage \n              0               0               0               0             490 \n       Lot Area          Street           Alley       Lot Shape    Land Contour \n              0               0            2732               0               0 \n      Utilities      Lot Config      Land Slope    Neighborhood     Condition 1 \n              0               0               0               0               0 \n    Condition 2       Bldg Type     House Style    Overall Qual    Overall Cond \n              0               0               0               0               0 \n     Year Built  Year Remod/Add      Roof Style       Roof Matl    Exterior 1st \n              0               0               0               0               0 \n   Exterior 2nd    Mas Vnr Type    Mas Vnr Area      Exter Qual      Exter Cond \n              0              23              23               0               0 \n     Foundation       Bsmt Qual       Bsmt Cond   Bsmt Exposure  BsmtFin Type 1 \n              0              80              80              83              80 \n   BsmtFin SF 1  BsmtFin Type 2    BsmtFin SF 2     Bsmt Unf SF   Total Bsmt SF \n              1              81               1               1               1 \n        Heating      Heating QC     Central Air      Electrical      1st Flr SF \n              0               0               0               1               0 \n     2nd Flr SF Low Qual Fin SF     Gr Liv Area  Bsmt Full Bath  Bsmt Half Bath \n              0               0               0               2               2 \n      Full Bath       Half Bath   Bedroom AbvGr   Kitchen AbvGr    Kitchen Qual \n              0               0               0               0               0 \n  TotRms AbvGrd      Functional      Fireplaces    Fireplace Qu     Garage Type \n              0               0               0            1422             157 \n  Garage Yr Blt   Garage Finish     Garage Cars     Garage Area     Garage Qual \n            159             159               1               1             159 \n    Garage Cond     Paved Drive    Wood Deck SF   Open Porch SF  Enclosed Porch \n            159               0               0               0               0 \n     3Ssn Porch    Screen Porch       Pool Area         Pool QC           Fence \n              0               0               0            2917            2358 \n   Misc Feature        Misc Val         Mo Sold         Yr Sold       Sale Type \n           2824               0               0               0               0 \n Sale Condition       SalePrice \n              0               0 \n\ncolSums(is.na(ameshousing))\n\n       MS_SubClass          MS_Zoning       Lot_Frontage           Lot_Area \n                 0                  0                  0                  0 \n            Street              Alley          Lot_Shape       Land_Contour \n                 0                  0                  0                  0 \n         Utilities         Lot_Config         Land_Slope       Neighborhood \n                 0                  0                  0                  0 \n       Condition_1        Condition_2          Bldg_Type        House_Style \n                 0                  0                  0                  0 \n      Overall_Qual       Overall_Cond         Year_Built     Year_Remod_Add \n                 0                  0                  0                  0 \n        Roof_Style          Roof_Matl       Exterior_1st       Exterior_2nd \n                 0                  0                  0                  0 \n      Mas_Vnr_Type       Mas_Vnr_Area         Exter_Qual         Exter_Cond \n                 0                  0                  0                  0 \n        Foundation          Bsmt_Qual          Bsmt_Cond      Bsmt_Exposure \n                 0                  0                  0                  0 \n    BsmtFin_Type_1       BsmtFin_SF_1     BsmtFin_Type_2       BsmtFin_SF_2 \n                 0                  0                  0                  0 \n       Bsmt_Unf_SF      Total_Bsmt_SF            Heating         Heating_QC \n                 0                  0                  0                  0 \n       Central_Air         Electrical       First_Flr_SF      Second_Flr_SF \n                 0                  0                  0                  0 \n   Low_Qual_Fin_SF        Gr_Liv_Area     Bsmt_Full_Bath     Bsmt_Half_Bath \n                 0                  0                  0                  0 \n         Full_Bath          Half_Bath      Bedroom_AbvGr      Kitchen_AbvGr \n                 0                  0                  0                  0 \n      Kitchen_Qual      TotRms_AbvGrd         Functional         Fireplaces \n                 0                  0                  0                  0 \n      Fireplace_Qu        Garage_Type      Garage_Finish        Garage_Cars \n                 0                  0                  0                  0 \n       Garage_Area        Garage_Qual        Garage_Cond        Paved_Drive \n                 0                  0                  0                  0 \n      Wood_Deck_SF      Open_Porch_SF     Enclosed_Porch Three_season_porch \n                 0                  0                  0                  0 \n      Screen_Porch          Pool_Area            Pool_QC              Fence \n                 0                  0                  0                  0 \n      Misc_Feature           Misc_Val            Mo_Sold          Year_Sold \n                 0                  0                  0                  0 \n         Sale_Type     Sale_Condition         Sale_Price          Longitude \n                 0                  0                  0                  0 \n          Latitude \n                 0 \n\n\n\n\n\n\n\nWhen working with missing data, it can be helpful to look for “co-missingness”, i.e. multiple variables missing together. For example, when working with patient data, number of pregnancies, age at onset of menstruation and menopause may all be missing - which, when observed together, may indicate that these samples come from male patients for whom this data is irrelevant. “Gender” may or may not be a variable coded in the dataset.\nA way of visualising missing data in the tidy context has been proposed @tierney2018expanding. See this web page for more options for your own data.\nLet’s look at the missing variables in our housing data:\n\ngg_miss_var(ameshousing_uncleaned)\n\n\n\n\nWe can see that the most missingness is observed in the Pool_QC, Misc_Feature, Alley, Fence and Fireplace_QC variables. This is most likely due to many houses not having pools, alleys, fences, and fireplaces, and not having any features that the real estate agent considers to be notable enough to be added to the “miscellaneous” category.\nAn upset plot will give us more idea about the co-missingness of these variables:\n\ngg_miss_upset(ameshousing_uncleaned, nsets = 10)\n\n\n\n\n\n\n\n\n\n\nChallenge 2\n\n\n\n\nWhich variables are most frequently missing together?\nDoes this “co-missingness” make sense?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nFence, Alley, Misc feature and Pool QC are most often missing together. This probably means that a house doesn’t have an alley, a fence, a pool or any other miscellaneous features.\nSimilarly, the second most frequent “co-missingess” involves these plus missing “fireplace quality”, most likely due to the house not having fireplace.\nWe can also see that Garage_Yr_Blt, Garage_Finish, Garage_Qual and Garage Cond “co-miss” the same number of times - probably because these represent houses without garages.\n\n\n\n\nNext, let’s create two “helper” vectors with the names of the numeric and categorical variables from the ameshousing dataset, which we can then use to batch subset our dataset prior to EDA/visualisation:\n\n# pull out all of the numerical variables\nnumVars <- ameshousing %>% \n  select_if(is.numeric) %>%\n  names()\n\n# use Negate(is.numeric) to pull out all of the categorical variables\ncatVars <- ameshousing %>% \n  select_if(Negate(is.numeric)) %>%\n  names()\n\nLet’s then use the ggpairs() function to generate a plot of the first 10 numeric variables (and sale price, which is 33) against each other. We can repeat this for variables 11-20 and 21-33.\n\nggpairs(data = ameshousing, \n        columns = numVars[c(1:10, 33)], \n        title = \"Numeric variables 1 - 10\")\n\n\n\n# ggpairs(ameshousing, numVars[c(11:20, 33)], title = \"Numeric variables 11 - 20\")\n# ggpairs(ameshousing, numVars[c(21:33)], title = \"Numeric variables 21 - 33\")\nggpairs(data = ameshousing, \n        columns = c(catVars[2:5], \"Sale_Price\"), \n        title = \"Some categorical variables\")\n\n\n\n\nNext, we can generate a correlation plot between all of our numeric variables. By default, the cor() method will calculate the Pearson correlation between the Sale_Price and the other variables, and we can specify how we’d like to handle missing data when calculating this correlation.\nIn this case, we use pairwise.complete.obs, which calculates the correlation between each pair of variables using all complete pairs of observations on those variables.\nWe then plot the correlation using the corrplot library, which has several options for how to visualise a correlation plot. See here for some examples of the visualisations it can produce.\n\n# pairs.panels(ameshousing[ , names(ameshousing)[c(3, 16, 23, 27,37)]], scale=TRUE)\nameshousingCor <- cor(ameshousing[,numVars],\n                      use = \"pairwise.complete.obs\")\n\nameshousingCor_pvalues <- cor_pmat(ameshousingCor)\nggcorrplot(ameshousingCor, type = \"lower\")\n\n\n\n\nWe can also make a dynamic visualisation using plotly.\n\n#Bonus: interactive corrplot with zoom and mouseover\nggcorrplot(ameshousingCor, type = \"lower\") %>% ggplotly()\n\n\n\n\n\n\n\n\n\n\n\nChallenge 3\n\n\n\n\nWhat variables are the most correlated with SalePrice?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nas_tibble(ameshousingCor, rownames = \"rowname\") %>%\n  gather(pair, value, -rowname) %>%\n  filter(rowname != pair) %>% #remove self correlation\n  filter(rowname == \"Sale_Price\") %>%\n  arrange(desc(abs(value))) %>%\n  head()\n\n# A tibble: 6 × 3\n  rowname    pair          value\n  <chr>      <chr>         <dbl>\n1 Sale_Price Gr_Liv_Area   0.707\n2 Sale_Price Garage_Cars   0.648\n3 Sale_Price Garage_Area   0.640\n4 Sale_Price Total_Bsmt_SF 0.633\n5 Sale_Price First_Flr_SF  0.622\n6 Sale_Price Year_Built    0.558\n\n\nWe can also plot this, using a slightly different representation:\n\nCircles instead of only colour to represent correlation levels\nFilter out correlations less than 0.5\n\n\nall_numVar <- ameshousing[, numVars]\ncor_numVar <- cor(all_numVar, use=\"pairwise.complete.obs\") \nCorHigh <- as_tibble(\n  data.frame(correlation = cor_numVar[,'Sale_Price']), rownames = \"rownames\")  %>% \n  filter(abs(correlation) >= 0.5) %>% \n  .$rownames\nggcorrplot(cor_numVar[CorHigh, CorHigh], type = \"lower\", \"circle\")\n\n\n\n\n\n\n\nLet’s plot one of these relationships:\n\ngra <- ameshousing %>%\n  ggplot(aes(x = Gr_Liv_Area, y = Sale_Price/1000)) + \n  geom_point(alpha = 0.1) + \n  labs(y = \"Sale Price/$1000\",\n       x = \"Living Area (sq.ft)\",\n       title = \"Ames Housing Data\") +\n  geom_smooth(method= \"lm\")  +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ngra %>% \n  ggplotly()\n\n\n\n\n\nWe can see that there are five houses with an area > 4000 square feet that seem to be outliers in the data. We should filter them out. Next, let’s generate a violin and boxplot by Quality:\n\nameshousing_filt <-\n  ameshousing %>%\n  filter(Gr_Liv_Area <= 4000)\n\np <- ameshousing_filt %>%\n  ggplot(aes(x = Overall_Qual, y = Sale_Price)) +\n  geom_violin() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nggplotly(p)\n\n\n\n\np <-ameshousing_filt %>%\n  mutate(Quality = as.factor(Overall_Qual)) %>%\n  ggplot(aes(x = Quality,\n             y = Sale_Price / 1000,\n             fill = Quality)) +\n  labs(y = \"Sale Price in $k's\",\n       x = \"Overall Quality of House\",\n       title = \"Ames Housing Data\") +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \nggplotly(p)\n\n\n\n\n\n\n\nYou also need to do EDA on the outcome variable to:\n\nidentify outliers\nexplore whether there is any skew in its distribution\nidentify a transformation to use when modelling the data (if appropriate)\n\nThis is because many models, including ordinary linear regression, assume that prediction errors (and hence the response) are normally distributed.\n\nameshousing_filt %>% \n  ggplot(aes(x = Sale_Price/1000)) + \n  geom_histogram(bins = 50) + \n  labs(x = \"Sale Price in $k's\",\n       y = \"Number of Houses sold\")\n\n\n\n\nLet’s explore different ways of transforming the Sale Price.\n\n#No transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = Sale_Price)) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#Sqrt transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = sqrt(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#natural log transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = log(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#log10 transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = log10(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nChallenge 4\n\n\n\n\nIf you were working with this dataset, which of the above would you prefer?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe log10 transformation seems best, as it both helps the distribution look more normal and helps keep our error metrics and final predictions easily interpretable. It also means that the errors of predicting the values of inexpensive and expensive houses will affect the prediction equally.\n\nbestNormalize::bestNormalize(\n  ameshousing_filt$Sale_Price,\n  allow_orderNorm = FALSE)\n\nBest Normalizing transformation with 2925 Observations\n Estimated Normality Statistics (Pearson P / df, lower => more normal):\n - arcsinh(x): 1.5968\n - Box-Cox: 1.6314\n - Center+scale: 5.2811\n - Log_b(x+a): 1.5968\n - sqrt(x + a): 2.7969\n - Yeo-Johnson: 1.6314\nEstimation method: Out-of-sample via CV with 10 folds and 5 repeats\nBased off these, bestNormalize chose:\nStandardized asinh(x) Transformation with 2925 nonmissing obs.:\n Relevant statistics:\n - mean (before standardization) = 12.71303 \n - sd (before standardization) = 0.4060161 \n\n\nThe bestNormalize library can be used to identify the best normalising transformation. Note that in this case, the arcsinh(x) and logarithmic transformations both achieve best normalisation results. To make interpretation a bit easier, we choose the logarithmic transformation.\n\n\n\n\nameshousing_filt <- ameshousing_filt %>% mutate(Sale_Price = log10(Sale_Price))\n\n\n\nThe year in which the house was built and the year when it was remodelled are not really the most relevant parameters we look at when buying a house: instead, buyers usually care a lot more about the age of the house and the time since the last remodel. Let’s transform these features:\n\nameshousing_filt_tr <-\n  ameshousing_filt %>%\n  mutate(Time_Since_Remodel = Year_Sold - Year_Remod_Add, \n         House_Age = Year_Sold - Year_Built) %>%\n  select(-Year_Remod_Add, -Year_Built)\n\nqsave(ameshousing_filt_tr, \"../_models/ames_dataset_filt.qs\")\n\n\nNote Make sure to create a “models” folder in your project working directory! Before you can save your data as .Rds objects, you will actually need to create a folder for these files to go into. Do this by clicking on the “new folder” button in the files window in R studio. Rename your new folder to “models”.\n\n\n\n\n\n\n\nKey points\n\n\n\nExploratory Data Analysis (EDA) is an essential first step in ML.\n\n\nTierney, Nicholas J, and Dianne H Cook. 2018. “Expanding Tidy Data Principles to Facilitate Missing Data Exploration, Visualization and Assessment of Imputations.” arXiv Preprint arXiv:1809.02264."
  },
  {
    "objectID": "100_regression/step1.html#exploratory-data-analysis",
    "href": "100_regression/step1.html#exploratory-data-analysis",
    "title": "Sydney Informatics Hub",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nExploratory data analysis involves looking at:\n\nThe distribution of variables in your dataset;\nWhether any data is missing;\nData skewness;\nCorrelated variables.\n\n\n\n\n\n\n\nChallenge 1\n\n\n\n\nExplore the Ames Housing dataset.\n\nWhat can you figure out about the different variables?\nWhich do you think are more or less important?\n\n\nCompare the ameshousing variable, which is from the AmesHousing package in R and has been cleaned, with the ameshousing_uncleaned dataset, which is the raw data from the UCI machine learning repository.\n\nWhat was missing in the raw data?\nWhat are some of the approaches that have been taken to deal with missingness?\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can see that the “uncleaned” dataset has a lot of missing data, whereas it has been cleaned up for us in the “cleaned” one. In the interests of time, we will not focus here on how every variable in that dataset has been explored and cleaned up - however, it presents a good example of “messy” real-world data, so we would encourage you to try and look at a handful of variables at home, to see how they’ve been processed.\n\ndim(ameshousing)\n\n[1] 2930   81\n\nglimpse(ameshousing)\n\nRows: 2,930\nColumns: 81\n$ MS_SubClass        <fct> One_Story_1946_and_Newer_All_Styles, One_Story_1946…\n$ MS_Zoning          <fct> Residential_Low_Density, Residential_High_Density, …\n$ Lot_Frontage       <dbl> 141, 80, 81, 93, 74, 78, 41, 43, 39, 60, 75, 0, 63,…\n$ Lot_Area           <int> 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005…\n$ Street             <fct> Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pave, Pav…\n$ Alley              <fct> No_Alley_Access, No_Alley_Access, No_Alley_Access, …\n$ Lot_Shape          <fct> Slightly_Irregular, Regular, Slightly_Irregular, Re…\n$ Land_Contour       <fct> Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, Lvl, HLS, Lvl, Lvl, L…\n$ Utilities          <fct> AllPub, AllPub, AllPub, AllPub, AllPub, AllPub, All…\n$ Lot_Config         <fct> Corner, Inside, Corner, Corner, Inside, Inside, Ins…\n$ Land_Slope         <fct> Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, Gtl, G…\n$ Neighborhood       <fct> North_Ames, North_Ames, North_Ames, North_Ames, Gil…\n$ Condition_1        <fct> Norm, Feedr, Norm, Norm, Norm, Norm, Norm, Norm, No…\n$ Condition_2        <fct> Norm, Norm, Norm, Norm, Norm, Norm, Norm, Norm, Nor…\n$ Bldg_Type          <fct> OneFam, OneFam, OneFam, OneFam, OneFam, OneFam, Twn…\n$ House_Style        <fct> One_Story, One_Story, One_Story, One_Story, Two_Sto…\n$ Overall_Qual       <fct> Above_Average, Average, Above_Average, Good, Averag…\n$ Overall_Cond       <fct> Average, Above_Average, Above_Average, Average, Ave…\n$ Year_Built         <int> 1960, 1961, 1958, 1968, 1997, 1998, 2001, 1992, 199…\n$ Year_Remod_Add     <int> 1960, 1961, 1958, 1968, 1998, 1998, 2001, 1992, 199…\n$ Roof_Style         <fct> Hip, Gable, Hip, Hip, Gable, Gable, Gable, Gable, G…\n$ Roof_Matl          <fct> CompShg, CompShg, CompShg, CompShg, CompShg, CompSh…\n$ Exterior_1st       <fct> BrkFace, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Exterior_2nd       <fct> Plywood, VinylSd, Wd Sdng, BrkFace, VinylSd, VinylS…\n$ Mas_Vnr_Type       <fct> Stone, None, BrkFace, None, None, BrkFace, None, No…\n$ Mas_Vnr_Area       <dbl> 112, 0, 108, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6…\n$ Exter_Qual         <fct> Typical, Typical, Typical, Good, Typical, Typical, …\n$ Exter_Cond         <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Foundation         <fct> CBlock, CBlock, CBlock, CBlock, PConc, PConc, PConc…\n$ Bsmt_Qual          <fct> Typical, Typical, Typical, Typical, Good, Typical, …\n$ Bsmt_Cond          <fct> Good, Typical, Typical, Typical, Typical, Typical, …\n$ Bsmt_Exposure      <fct> Gd, No, No, No, No, No, Mn, No, No, No, No, No, No,…\n$ BsmtFin_Type_1     <fct> BLQ, Rec, ALQ, ALQ, GLQ, GLQ, GLQ, ALQ, GLQ, Unf, U…\n$ BsmtFin_SF_1       <dbl> 2, 6, 1, 1, 3, 3, 3, 1, 3, 7, 7, 1, 7, 3, 3, 1, 3, …\n$ BsmtFin_Type_2     <fct> Unf, LwQ, Unf, Unf, Unf, Unf, Unf, Unf, Unf, Unf, U…\n$ BsmtFin_SF_2       <dbl> 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1120, 0…\n$ Bsmt_Unf_SF        <dbl> 441, 270, 406, 1045, 137, 324, 722, 1017, 415, 994,…\n$ Total_Bsmt_SF      <dbl> 1080, 882, 1329, 2110, 928, 926, 1338, 1280, 1595, …\n$ Heating            <fct> GasA, GasA, GasA, GasA, GasA, GasA, GasA, GasA, Gas…\n$ Heating_QC         <fct> Fair, Typical, Typical, Excellent, Good, Excellent,…\n$ Central_Air        <fct> Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, …\n$ Electrical         <fct> SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SBrkr, SB…\n$ First_Flr_SF       <int> 1656, 896, 1329, 2110, 928, 926, 1338, 1280, 1616, …\n$ Second_Flr_SF      <int> 0, 0, 0, 0, 701, 678, 0, 0, 0, 776, 892, 0, 676, 0,…\n$ Low_Qual_Fin_SF    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Gr_Liv_Area        <int> 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616…\n$ Bsmt_Full_Bath     <dbl> 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, …\n$ Bsmt_Half_Bath     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Full_Bath          <int> 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, …\n$ Half_Bath          <int> 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ Bedroom_AbvGr      <int> 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 1, 4, 4, …\n$ Kitchen_AbvGr      <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Kitchen_Qual       <fct> Typical, Typical, Good, Excellent, Typical, Good, G…\n$ TotRms_AbvGrd      <int> 7, 5, 6, 8, 6, 7, 6, 5, 5, 7, 7, 6, 7, 5, 4, 12, 8,…\n$ Functional         <fct> Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, Typ, T…\n$ Fireplaces         <int> 2, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, …\n$ Fireplace_Qu       <fct> Good, No_Fireplace, No_Fireplace, Typical, Typical,…\n$ Garage_Type        <fct> Attchd, Attchd, Attchd, Attchd, Attchd, Attchd, Att…\n$ Garage_Finish      <fct> Fin, Unf, Unf, Fin, Fin, Fin, Fin, RFn, RFn, Fin, F…\n$ Garage_Cars        <dbl> 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, …\n$ Garage_Area        <dbl> 528, 730, 312, 522, 482, 470, 582, 506, 608, 442, 4…\n$ Garage_Qual        <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Garage_Cond        <fct> Typical, Typical, Typical, Typical, Typical, Typica…\n$ Paved_Drive        <fct> Partial_Pavement, Paved, Paved, Paved, Paved, Paved…\n$ Wood_Deck_SF       <int> 210, 140, 393, 0, 212, 360, 0, 0, 237, 140, 157, 48…\n$ Open_Porch_SF      <int> 62, 0, 36, 0, 34, 36, 0, 82, 152, 60, 84, 21, 75, 0…\n$ Enclosed_Porch     <int> 0, 0, 0, 0, 0, 0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Three_season_porch <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Screen_Porch       <int> 0, 120, 0, 0, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 140, …\n$ Pool_Area          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Pool_QC            <fct> No_Pool, No_Pool, No_Pool, No_Pool, No_Pool, No_Poo…\n$ Fence              <fct> No_Fence, Minimum_Privacy, No_Fence, No_Fence, Mini…\n$ Misc_Feature       <fct> None, None, Gar2, None, None, None, None, None, Non…\n$ Misc_Val           <int> 0, 0, 12500, 0, 0, 0, 0, 0, 0, 0, 0, 500, 0, 0, 0, …\n$ Mo_Sold            <int> 5, 6, 6, 4, 3, 6, 4, 1, 3, 6, 4, 3, 5, 2, 6, 6, 6, …\n$ Year_Sold          <int> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 201…\n$ Sale_Type          <fct> WD , WD , WD , WD , WD , WD , WD , WD , WD , WD , W…\n$ Sale_Condition     <fct> Normal, Normal, Normal, Normal, Normal, Normal, Nor…\n$ Sale_Price         <int> 215000, 105000, 172000, 244000, 189900, 195500, 213…\n$ Longitude          <dbl> -93.61975, -93.61976, -93.61939, -93.61732, -93.638…\n$ Latitude           <dbl> 42.05403, 42.05301, 42.05266, 42.05125, 42.06090, 4…\n\ncolSums(is.na(ameshousing_uncleaned))\n\n          Order             PID     MS SubClass       MS Zoning    Lot Frontage \n              0               0               0               0             490 \n       Lot Area          Street           Alley       Lot Shape    Land Contour \n              0               0            2732               0               0 \n      Utilities      Lot Config      Land Slope    Neighborhood     Condition 1 \n              0               0               0               0               0 \n    Condition 2       Bldg Type     House Style    Overall Qual    Overall Cond \n              0               0               0               0               0 \n     Year Built  Year Remod/Add      Roof Style       Roof Matl    Exterior 1st \n              0               0               0               0               0 \n   Exterior 2nd    Mas Vnr Type    Mas Vnr Area      Exter Qual      Exter Cond \n              0              23              23               0               0 \n     Foundation       Bsmt Qual       Bsmt Cond   Bsmt Exposure  BsmtFin Type 1 \n              0              80              80              83              80 \n   BsmtFin SF 1  BsmtFin Type 2    BsmtFin SF 2     Bsmt Unf SF   Total Bsmt SF \n              1              81               1               1               1 \n        Heating      Heating QC     Central Air      Electrical      1st Flr SF \n              0               0               0               1               0 \n     2nd Flr SF Low Qual Fin SF     Gr Liv Area  Bsmt Full Bath  Bsmt Half Bath \n              0               0               0               2               2 \n      Full Bath       Half Bath   Bedroom AbvGr   Kitchen AbvGr    Kitchen Qual \n              0               0               0               0               0 \n  TotRms AbvGrd      Functional      Fireplaces    Fireplace Qu     Garage Type \n              0               0               0            1422             157 \n  Garage Yr Blt   Garage Finish     Garage Cars     Garage Area     Garage Qual \n            159             159               1               1             159 \n    Garage Cond     Paved Drive    Wood Deck SF   Open Porch SF  Enclosed Porch \n            159               0               0               0               0 \n     3Ssn Porch    Screen Porch       Pool Area         Pool QC           Fence \n              0               0               0            2917            2358 \n   Misc Feature        Misc Val         Mo Sold         Yr Sold       Sale Type \n           2824               0               0               0               0 \n Sale Condition       SalePrice \n              0               0 \n\ncolSums(is.na(ameshousing))\n\n       MS_SubClass          MS_Zoning       Lot_Frontage           Lot_Area \n                 0                  0                  0                  0 \n            Street              Alley          Lot_Shape       Land_Contour \n                 0                  0                  0                  0 \n         Utilities         Lot_Config         Land_Slope       Neighborhood \n                 0                  0                  0                  0 \n       Condition_1        Condition_2          Bldg_Type        House_Style \n                 0                  0                  0                  0 \n      Overall_Qual       Overall_Cond         Year_Built     Year_Remod_Add \n                 0                  0                  0                  0 \n        Roof_Style          Roof_Matl       Exterior_1st       Exterior_2nd \n                 0                  0                  0                  0 \n      Mas_Vnr_Type       Mas_Vnr_Area         Exter_Qual         Exter_Cond \n                 0                  0                  0                  0 \n        Foundation          Bsmt_Qual          Bsmt_Cond      Bsmt_Exposure \n                 0                  0                  0                  0 \n    BsmtFin_Type_1       BsmtFin_SF_1     BsmtFin_Type_2       BsmtFin_SF_2 \n                 0                  0                  0                  0 \n       Bsmt_Unf_SF      Total_Bsmt_SF            Heating         Heating_QC \n                 0                  0                  0                  0 \n       Central_Air         Electrical       First_Flr_SF      Second_Flr_SF \n                 0                  0                  0                  0 \n   Low_Qual_Fin_SF        Gr_Liv_Area     Bsmt_Full_Bath     Bsmt_Half_Bath \n                 0                  0                  0                  0 \n         Full_Bath          Half_Bath      Bedroom_AbvGr      Kitchen_AbvGr \n                 0                  0                  0                  0 \n      Kitchen_Qual      TotRms_AbvGrd         Functional         Fireplaces \n                 0                  0                  0                  0 \n      Fireplace_Qu        Garage_Type      Garage_Finish        Garage_Cars \n                 0                  0                  0                  0 \n       Garage_Area        Garage_Qual        Garage_Cond        Paved_Drive \n                 0                  0                  0                  0 \n      Wood_Deck_SF      Open_Porch_SF     Enclosed_Porch Three_season_porch \n                 0                  0                  0                  0 \n      Screen_Porch          Pool_Area            Pool_QC              Fence \n                 0                  0                  0                  0 \n      Misc_Feature           Misc_Val            Mo_Sold          Year_Sold \n                 0                  0                  0                  0 \n         Sale_Type     Sale_Condition         Sale_Price          Longitude \n                 0                  0                  0                  0 \n          Latitude \n                 0 \n\n\n\n\n\nVisualise missingness\n\nWhen working with missing data, it can be helpful to look for “co-missingness”, i.e. multiple variables missing together. For example, when working with patient data, number of pregnancies, age at onset of menstruation and menopause may all be missing - which, when observed together, may indicate that these samples come from male patients for whom this data is irrelevant. “Gender” may or may not be a variable coded in the dataset.\nA way of visualising missing data in the tidy context has been proposed @tierney2018expanding. See this web page for more options for your own data.\nLet’s look at the missing variables in our housing data:\n\ngg_miss_var(ameshousing_uncleaned)\n\n\n\n\nWe can see that the most missingness is observed in the Pool_QC, Misc_Feature, Alley, Fence and Fireplace_QC variables. This is most likely due to many houses not having pools, alleys, fences, and fireplaces, and not having any features that the real estate agent considers to be notable enough to be added to the “miscellaneous” category.\nAn upset plot will give us more idea about the co-missingness of these variables:\n\ngg_miss_upset(ameshousing_uncleaned, nsets = 10)\n\n\n\n\n\n\n\n\n\n\nChallenge 2\n\n\n\n\nWhich variables are most frequently missing together?\nDoes this “co-missingness” make sense?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nFence, Alley, Misc feature and Pool QC are most often missing together. This probably means that a house doesn’t have an alley, a fence, a pool or any other miscellaneous features.\nSimilarly, the second most frequent “co-missingess” involves these plus missing “fireplace quality”, most likely due to the house not having fireplace.\nWe can also see that Garage_Yr_Blt, Garage_Finish, Garage_Qual and Garage Cond “co-miss” the same number of times - probably because these represent houses without garages.\n\n\n\n\nNext, let’s create two “helper” vectors with the names of the numeric and categorical variables from the ameshousing dataset, which we can then use to batch subset our dataset prior to EDA/visualisation:\n\n# pull out all of the numerical variables\nnumVars <- ameshousing %>% \n  select_if(is.numeric) %>%\n  names()\n\n# use Negate(is.numeric) to pull out all of the categorical variables\ncatVars <- ameshousing %>% \n  select_if(Negate(is.numeric)) %>%\n  names()\n\nLet’s then use the ggpairs() function to generate a plot of the first 10 numeric variables (and sale price, which is 33) against each other. We can repeat this for variables 11-20 and 21-33.\n\nggpairs(data = ameshousing, \n        columns = numVars[c(1:10, 33)], \n        title = \"Numeric variables 1 - 10\")\n\n\n\n# ggpairs(ameshousing, numVars[c(11:20, 33)], title = \"Numeric variables 11 - 20\")\n# ggpairs(ameshousing, numVars[c(21:33)], title = \"Numeric variables 21 - 33\")\nggpairs(data = ameshousing, \n        columns = c(catVars[2:5], \"Sale_Price\"), \n        title = \"Some categorical variables\")\n\n\n\n\nNext, we can generate a correlation plot between all of our numeric variables. By default, the cor() method will calculate the Pearson correlation between the Sale_Price and the other variables, and we can specify how we’d like to handle missing data when calculating this correlation.\nIn this case, we use pairwise.complete.obs, which calculates the correlation between each pair of variables using all complete pairs of observations on those variables.\nWe then plot the correlation using the corrplot library, which has several options for how to visualise a correlation plot. See here for some examples of the visualisations it can produce.\n\n# pairs.panels(ameshousing[ , names(ameshousing)[c(3, 16, 23, 27,37)]], scale=TRUE)\nameshousingCor <- cor(ameshousing[,numVars],\n                      use = \"pairwise.complete.obs\")\n\nameshousingCor_pvalues <- cor_pmat(ameshousingCor)\nggcorrplot(ameshousingCor, type = \"lower\")\n\n\n\n\nWe can also make a dynamic visualisation using plotly.\n\n#Bonus: interactive corrplot with zoom and mouseover\nggcorrplot(ameshousingCor, type = \"lower\") %>% ggplotly()\n\n\n\n\n\n\n\n\n\n\n\nChallenge 3\n\n\n\n\nWhat variables are the most correlated with SalePrice?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nas_tibble(ameshousingCor, rownames = \"rowname\") %>%\n  gather(pair, value, -rowname) %>%\n  filter(rowname != pair) %>% #remove self correlation\n  filter(rowname == \"Sale_Price\") %>%\n  arrange(desc(abs(value))) %>%\n  head()\n\n# A tibble: 6 × 3\n  rowname    pair          value\n  <chr>      <chr>         <dbl>\n1 Sale_Price Gr_Liv_Area   0.707\n2 Sale_Price Garage_Cars   0.648\n3 Sale_Price Garage_Area   0.640\n4 Sale_Price Total_Bsmt_SF 0.633\n5 Sale_Price First_Flr_SF  0.622\n6 Sale_Price Year_Built    0.558\n\n\nWe can also plot this, using a slightly different representation:\n\nCircles instead of only colour to represent correlation levels\nFilter out correlations less than 0.5\n\n\nall_numVar <- ameshousing[, numVars]\ncor_numVar <- cor(all_numVar, use=\"pairwise.complete.obs\") \nCorHigh <- as_tibble(\n  data.frame(correlation = cor_numVar[,'Sale_Price']), rownames = \"rownames\")  %>% \n  filter(abs(correlation) >= 0.5) %>% \n  .$rownames\nggcorrplot(cor_numVar[CorHigh, CorHigh], type = \"lower\", \"circle\")\n\n\n\n\n\n\n\nLet’s plot one of these relationships:\n\ngra <- ameshousing %>%\n  ggplot(aes(x = Gr_Liv_Area, y = Sale_Price/1000)) + \n  geom_point(alpha = 0.1) + \n  labs(y = \"Sale Price/$1000\",\n       x = \"Living Area (sq.ft)\",\n       title = \"Ames Housing Data\") +\n  geom_smooth(method= \"lm\")  +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ngra %>% \n  ggplotly()\n\n\n\n\n\nWe can see that there are five houses with an area > 4000 square feet that seem to be outliers in the data. We should filter them out. Next, let’s generate a violin and boxplot by Quality:\n\nameshousing_filt <-\n  ameshousing %>%\n  filter(Gr_Liv_Area <= 4000)\n\np <- ameshousing_filt %>%\n  ggplot(aes(x = Overall_Qual, y = Sale_Price)) +\n  geom_violin() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nggplotly(p)\n\n\n\n\np <-ameshousing_filt %>%\n  mutate(Quality = as.factor(Overall_Qual)) %>%\n  ggplot(aes(x = Quality,\n             y = Sale_Price / 1000,\n             fill = Quality)) +\n  labs(y = \"Sale Price in $k's\",\n       x = \"Overall Quality of House\",\n       title = \"Ames Housing Data\") +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \nggplotly(p)"
  },
  {
    "objectID": "100_regression/step1.html#eda-of-outcome-variable",
    "href": "100_regression/step1.html#eda-of-outcome-variable",
    "title": "Sydney Informatics Hub",
    "section": "EDA of outcome variable",
    "text": "EDA of outcome variable\n\nYou also need to do EDA on the outcome variable to:\n\nidentify outliers\nexplore whether there is any skew in its distribution\nidentify a transformation to use when modelling the data (if appropriate)\n\nThis is because many models, including ordinary linear regression, assume that prediction errors (and hence the response) are normally distributed.\n\nameshousing_filt %>% \n  ggplot(aes(x = Sale_Price/1000)) + \n  geom_histogram(bins = 50) + \n  labs(x = \"Sale Price in $k's\",\n       y = \"Number of Houses sold\")\n\n\n\n\nLet’s explore different ways of transforming the Sale Price.\n\n#No transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = Sale_Price)) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#Sqrt transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = sqrt(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#natural log transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = log(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n#log10 transform\n\nameshousing_filt %>%\n  ggplot(aes( sample = log10(Sale_Price))) +\n  stat_qq() + stat_qq_line(col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nChallenge 4\n\n\n\n\nIf you were working with this dataset, which of the above would you prefer?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe log10 transformation seems best, as it both helps the distribution look more normal and helps keep our error metrics and final predictions easily interpretable. It also means that the errors of predicting the values of inexpensive and expensive houses will affect the prediction equally.\n\nbestNormalize::bestNormalize(\n  ameshousing_filt$Sale_Price,\n  allow_orderNorm = FALSE)\n\nBest Normalizing transformation with 2925 Observations\n Estimated Normality Statistics (Pearson P / df, lower => more normal):\n - arcsinh(x): 1.5968\n - Box-Cox: 1.6314\n - Center+scale: 5.2811\n - Log_b(x+a): 1.5968\n - sqrt(x + a): 2.7969\n - Yeo-Johnson: 1.6314\nEstimation method: Out-of-sample via CV with 10 folds and 5 repeats\nBased off these, bestNormalize chose:\nStandardized asinh(x) Transformation with 2925 nonmissing obs.:\n Relevant statistics:\n - mean (before standardization) = 12.71303 \n - sd (before standardization) = 0.4060161 \n\n\nThe bestNormalize library can be used to identify the best normalising transformation. Note that in this case, the arcsinh(x) and logarithmic transformations both achieve best normalisation results. To make interpretation a bit easier, we choose the logarithmic transformation.\n\n\n\n\nameshousing_filt <- ameshousing_filt %>% mutate(Sale_Price = log10(Sale_Price))"
  },
  {
    "objectID": "100_regression/step1.html#feature-transformation",
    "href": "100_regression/step1.html#feature-transformation",
    "title": "Sydney Informatics Hub",
    "section": "Feature transformation",
    "text": "Feature transformation\n\nThe year in which the house was built and the year when it was remodelled are not really the most relevant parameters we look at when buying a house: instead, buyers usually care a lot more about the age of the house and the time since the last remodel. Let’s transform these features:\n\nameshousing_filt_tr <-\n  ameshousing_filt %>%\n  mutate(Time_Since_Remodel = Year_Sold - Year_Remod_Add, \n         House_Age = Year_Sold - Year_Built) %>%\n  select(-Year_Remod_Add, -Year_Built)\n\nqsave(ameshousing_filt_tr, \"../_models/ames_dataset_filt.qs\")\n\n\nNote Make sure to create a “models” folder in your project working directory! Before you can save your data as .Rds objects, you will actually need to create a folder for these files to go into. Do this by clicking on the “new folder” button in the files window in R studio. Rename your new folder to “models”.\n\n\n\n\n\n\n\nKey points\n\n\n\nExploratory Data Analysis (EDA) is an essential first step in ML.\n\n\nTierney, Nicholas J, and Dianne H Cook. 2018. “Expanding Tidy Data Principles to Facilitate Missing Data Exploration, Visualization and Assessment of Imputations.” arXiv Preprint arXiv:1809.02264."
  },
  {
    "objectID": "100_regression/step2.html",
    "href": "100_regression/step2.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "Learning objective:\n\n\n\n\nFrom base R to tidymodels;\nSplit our data into training and test sets;\nPreprocess the training data;\nSpecify a linear regression model;\nTrain our model on the training data;\nTransform the test data and obtain predictions using our trained model.\n\n\n\n\n\n\n\n\n\nExercise:\n\n\n\nIn this case study, you will predict houses selling price from characteristics of these houses, like size and layout of the living space in the house. What kind of model will you build?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTo predict a continuous, numeric quantity like selling price, use regression models.\n\n\n\nLoad in the packages we’ll be using for modelling:\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(rsample)\nlibrary(vip) \nlibrary(qs)\ntheme_set(theme_minimal())\n\n\n\n\n\nIn a linear model, we assume that there is a linear relationship between the input variable(s) and the output variable. This means that as the input variable(s) increase or decrease, the output variable changes in a straight line.\nImagine you have a scatter plot with your data points all over it. A linear model is like drawing a straight line through the scatter plot that best fits all the points. The slope and intercept of this line are chosen in such a way that the distance between the line and all the points is minimized. This line is then used to predict the output for new input values.\n\n\nExample of a linear model\n\n\nThe straight red dotted line represents the linear model equation \\(y=mx+c\\), where \\(c\\) is the y-intercept of the regression line, \\(m\\) is the slope of the regression line, and \\(y\\) is the expected value for y for the given \\(x\\) value.\n\n#fit a linear model\names_lm <- lm(Sale_Price ~ Gr_Liv_Area, data = ames_data)\n\n#Print the summary of the model\nsummary(ames_lm)\n\n\nCall:\nlm(formula = Sale_Price ~ Gr_Liv_Area, data = ames_data)\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.94258 -0.06622  0.01359  0.07298  0.39246 \nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 4.835e+00  7.406e-03  652.80   <2e-16 ***\nGr_Liv_Area 2.579e-04  4.714e-06   54.72   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nResidual standard error: 0.124 on 2923 degrees of freedom\nMultiple R-squared:  0.506, Adjusted R-squared:  0.5058 \nF-statistic:  2994 on 1 and 2923 DF,  p-value: < 2.2e-16\n\n\nR-squared value explains the variability of y with respect to x:\n\nvaries between 0 to 1 (0-100%);\nR-squared values closer to 0 mean the regression relationship is very low;\nR-squared values closer to 1 mean the regression relationship is very strong.\n\nLet’s plot our linear regression model:\n\nplot(ames_data$Gr_Liv_Area, ames_data$Sale_Price,\n     xlab=\"Gr_Liv_Area\",\n     ylab=\"Sale_Price\", \n     col = \"blue\")\nabline(ames_lm, col = \"red\")\n\n\n\n\n\n\nWhen you type library(tidymodels), you load a collection of packages for modeling and machine learning using tidyverse principles. All the packages are designed to be consistent, modular, and to support good modeling practices. The first thing we are going to practice is splitting your data into a training set and a testing set. The tidymodels package rsample has functions that help you specify training and testing sets:\n\nset.seed(42) #so we all get the same results\names_split <- ames_data %>%\n    initial_split(prop = 0.8,\n                  strata = Sale_Price) #stratification\n\names_train <- training(ames_split)\names_test <- testing(ames_split)\n\nqsave(ames_train, \"../_models/ames_train.qs\")\nqsave(ames_test, \"../_models/ames_test.qs\")\n\nStratified sampling would split within each quartile. Splitting with stratification involves dividing the data into subsets based on the target/outcome variable’s distribution, such that the proportion of each class in the target variable is maintained in each subset. This ensures that the training and testing sets have a similar distribution of the target variable, which can lead to more reliable model performance estimates. \nThe code here takes an input data set and puts 80% of it into a training dataset and 20% of it into a testing dataset; it chooses the individual cases so that both sets are balanced in selling price.\nLet’s check if the distribution of the selling price is the same in the testing and training datasets:\n\names_train %>% \n  ggplot(aes(x = log(Sale_Price),  col = \"red\", fill = NULL)) + \n  geom_density() + theme_minimal() +\n  geom_line(data = ames_test,\n            stat = \"density\",\n            col = \"blue\") + theme(legend.position=\"none\")\n\n\n\n\n\n\nWe might want to modify our predictors columns for a few reasons:\n\nThe model requires them in a different format;\nThe model needs certain data qualities;\nThe outcome is better predicted when one or more columns are transformed in some way (a.k.a “feature engineering”).\n\nIn tidymodels, you can use the recipes package, an extensible framework for pipeable sequences of feature engineering steps that provide preprocessing tools to be applied to data.\nSome of these steps can include:\n\nScaling and centering numeric predictors;\nRemoving skewness from numeric variables;\nOne-hot and dummy variable encoding for categorical variables;\nRemoving correlated predictors and zero variance variables;\nImputing missing data.\n\nStatistical parameters for the steps can be estimated from an initial data set and then applied to other data sets.\nThe resulting processed output can be used as inputs for statistical or machine learning models.\n\names_rec <-\n  recipe(Sale_Price ~ ., data = ames_train) %>% #assigns columns to roles of “outcome” or “predictor” using the formula\n  step_other(all_nominal(), threshold = 0.01) %>% #useful when you have some factor levels with very few observations, all_nominal selects both characters and factors, pools infrequently occurring values (frequency less than 0.01) into an \"other\" category\n  step_nzv(all_predictors()) %>% #remove predictors that are highly sparse and unbalanced\n  step_center(all_numeric_predictors()) %>% #subtracts the column mean from predictors\n  step_scale(all_numeric_predictors()) %>% #divides by the standard deviation\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% #for any nominal predictor, make binary indicators\n  step_lincomb(all_numeric_predictors()) #remove linear dependencies in the predictors, if present\names_rec\n\nqsave(ames_rec, \"../_models/ames_rec.qs\")\n\nNote that each successive step() function adds a preprocessing step to our recipe object in the order that they are provided. The preprocessing recipe ames_rec has been defined but no values have been estimated.\n\n\n\n\n\n\nChallenge X\n\n\n\nDoes it make sense to apply these preprocessing steps to the test set?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNo, it doesn’t. You want the set test to look like new data that your model will see in the future.\n\n\n\n\n\n\n\nThe prep() function takes a recipe and computes everything so that the preprocessing steps can be executed. Note that this is done with the training data.\n\n\n\names_prep <- prep(ames_rec)\n\names_prep\n\nThe bake() and juice() functions both return data, not a preprocessing recipe object.\n\n\nThe bake() function takes a prepped recipe (one that has had all quantities estimated from training data) and applies it to new_data. That new_data could be the training data again or it could be the testing data (with the TRAINING parameters).\n\n\n\names_test_baked <- bake(ames_prep, new_data = ames_test)\n\n\n\nThe juice() function is a nice little shortcut. When we juice() the recipe, we squeeze that training data back out, transformed in the ways we specified.\n\n\nLet’s compare the bake() and juice() outputs:\n\nbake(ames_prep, new_data = ames_train)\n\n# A tibble: 2,339 × 187\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       0.374   -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2       0.374    0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3      -0.137   -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4      -1.01    -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5      -0.0770  -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6      -0.227   -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7       0.374   -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8       0.314   -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9      -1.73    -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10      -1.73    -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\njuice(ames_prep) \n\n# A tibble: 2,339 × 187\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       0.374   -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2       0.374    0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3      -0.137   -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4      -1.01    -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5      -0.0770  -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6      -0.227   -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7       0.374   -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8       0.314   -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9      -1.73    -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10      -1.73    -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\n\nNote that the juice() output is the same as bake(ames_rep, new_data = ames_train) and is just a shortcut that we are going to use later.\n\n\nIn tidymodels, you specify models using three concepts:\n\n\ntype differentiates models such as logistic regression, linear regression, and so forth;\n\nmode includes common options like regression and classification, some model types support either of these while some only have one mode;\n\nengine is the computational tool which will be used to fit the model.\n\nWe will specify the model using the parsnip package. Many functions have different interfaces and arguments names and parsnip standardizes the interface for fitting models as well as the return values.\n\n#a linear regression model specification\names_model <- linear_reg() %>% #pick a model\n  set_engine(\"lm\")           #set the engine\n                             #set_mode(\"regression\") we don't need this as the model linear_reg() only does regression\n\n#view model properties\names_model\n\nLinear Regression Model Specification (regression)\nComputational engine: lm \n\n\n\n\nNow we are ready to train our model object on the training data. We can do this using the fit() function from the parsnip package. The fit() function takes the following arguments:\n\na parnsip model object specification;\na model formula\na data frame with the training data\n\nThe code below trains our linear regression model on the prepped training data. In our formula, we have specified that Sale_Price is the response variable and included all the rest as our predictor variables.\n\names_fit <- ames_model %>%\n  fit(Sale_Price ~ .,\n      data=juice(ames_prep))\n\n# View lm_fit properties\names_fit\n\nparsnip model object\nCall:\nstats::lm(formula = Sale_Price ~ ., data = data)\nCoefficients:\n                                          (Intercept)  \n                                            4.225e+00  \n                                         Lot_Frontage  \n                                            1.510e-03  \n                                             Lot_Area  \n                                            5.634e-03  \n                                         Mas_Vnr_Area  \n                                            3.178e-03  \n                                         BsmtFin_SF_1  \n                                            2.910e-02  \n                                         BsmtFin_SF_2  \n                                           -2.438e-03  \n                                          Bsmt_Unf_SF  \n                                           -9.865e-03  \n                                        Total_Bsmt_SF  \n                                            3.052e-02  \n                                         First_Flr_SF  \n                                            4.657e-03  \n                                        Second_Flr_SF  \n                                            9.635e-03  \n                                          Gr_Liv_Area  \n                                            4.895e-02  \n                                       Bsmt_Full_Bath  \n                                            4.946e-03  \n                                       Bsmt_Half_Bath  \n                                            1.160e-03  \n                                            Full_Bath  \n                                            7.528e-03  \n                                            Half_Bath  \n                                            6.568e-03  \n                                        Bedroom_AbvGr  \n                                           -3.780e-03  \n                                        TotRms_AbvGrd  \n                                           -4.477e-05  \n                                           Fireplaces  \n                                            5.691e-03  \n                                          Garage_Cars  \n                                            8.626e-03  \n                                          Garage_Area  \n                                            6.286e-03  \n                                         Wood_Deck_SF  \n                                            1.943e-03  \n                                        Open_Porch_SF  \n                                            1.901e-03  \n                                              Mo_Sold  \n                                           -3.097e-04  \n                                            Year_Sold  \n                                           -2.016e-03  \n                                            Longitude  \n                                           -8.325e-03  \n                                             Latitude  \n                                           -4.980e-03  \n                                   Time_Since_Remodel  \n                                           -5.556e-03  \n                                            House_Age  \n                                           -1.929e-02  \n      MS_SubClass_One_Story_1946_and_Newer_All_Styles  \n                                            6.196e-03  \n                 MS_SubClass_One_Story_1945_and_Older  \n                                           -2.177e-02  \n     MS_SubClass_One_and_Half_Story_Finished_All_Ages  \n                                            2.813e-02  \n                 MS_SubClass_Two_Story_1946_and_Newer  \n                                           -1.093e-02  \n                 MS_SubClass_Two_Story_1945_and_Older  \n                                            1.847e-02  \n                      MS_SubClass_Split_or_Multilevel  \n                                           -2.027e-02  \n                              MS_SubClass_Split_Foyer  \n                                            3.816e-03  \n               MS_SubClass_Duplex_All_Styles_and_Ages  \n                                           -2.177e-03  \n             MS_SubClass_One_Story_PUD_1946_and_Newer  \n                                            2.046e-02  \n             MS_SubClass_Two_Story_PUD_1946_and_Newer  \n                                           -2.533e-02  \nMS_SubClass_Two_Family_conversion_All_Styles_and_Ages  \n                                            2.991e-03  \n                                    MS_SubClass_other  \n                                                   NA  \n               MS_Zoning_Floating_Village_Residential  \n                                            3.984e-02  \n                    MS_Zoning_Residential_Low_Density  \n                                            3.224e-02  \n                 MS_Zoning_Residential_Medium_Density  \n                                            2.443e-02  \n                                    Lot_Shape_Regular  \n                                            4.462e-03  \n                         Lot_Shape_Slightly_Irregular  \n                                            4.294e-03  \n                       Lot_Shape_Moderately_Irregular  \n                                            1.805e-02  \n                                    Lot_Config_Corner  \n                                            5.998e-03  \n                                   Lot_Config_CulDSac  \n                                            1.298e-02  \n                                       Lot_Config_FR2  \n                                           -5.176e-03  \n                                    Lot_Config_Inside  \n                                            3.934e-03  \n                              Neighborhood_North_Ames  \n                                           -1.547e-02  \n                           Neighborhood_College_Creek  \n                                           -3.736e-02  \n                                Neighborhood_Old_Town  \n                                           -3.894e-02  \n                                 Neighborhood_Edwards  \n                                           -4.494e-02  \n                                Neighborhood_Somerset  \n                                            1.495e-02  \n                      Neighborhood_Northridge_Heights  \n                                            1.344e-02  \n                                 Neighborhood_Gilbert  \n                                           -8.690e-03  \n                                  Neighborhood_Sawyer  \n                                           -2.252e-02  \n                          Neighborhood_Northwest_Ames  \n                                           -1.568e-02  \n                             Neighborhood_Sawyer_West  \n                                           -3.405e-02  \n                                Neighborhood_Mitchell  \n                                           -2.449e-02  \n                               Neighborhood_Brookside  \n                                           -1.037e-02  \n                                Neighborhood_Crawford  \n                                            1.911e-02  \n                  Neighborhood_Iowa_DOT_and_Rail_Road  \n                                           -4.515e-02  \n                              Neighborhood_Timberland  \n                                           -2.225e-02  \n                              Neighborhood_Northridge  \n                                            1.195e-02  \n                             Neighborhood_Stone_Brook  \n                                            3.834e-02  \n Neighborhood_South_and_West_of_Iowa_State_University  \n                                           -3.175e-02  \n                             Neighborhood_Clear_Creek  \n                                           -1.395e-02  \n                          Neighborhood_Meadow_Village  \n                                           -6.325e-02  \n                                   Condition_1_Artery  \n                                           -1.792e-02  \n                                    Condition_1_Feedr  \n                                           -1.227e-02  \n                                     Condition_1_Norm  \n                                            6.575e-03  \n                                     Condition_1_PosN  \n                                            1.180e-02  \n                                     Condition_1_RRAn  \n                                           -1.178e-02  \n                                     Bldg_Type_OneFam  \n                                            3.635e-02  \n                                   Bldg_Type_TwoFmCon  \n                                            2.470e-02  \n                                      Bldg_Type_Twnhs  \n                                           -1.657e-02  \n                         House_Style_One_and_Half_Fin  \n                                           -3.279e-02  \n                                House_Style_One_Story  \n                                           -9.496e-03  \n                                   House_Style_SFoyer  \n                                            5.423e-04  \n                                     House_Style_SLvl  \n                                            1.420e-02  \n                                House_Style_Two_Story  \n                                           -8.472e-03  \n                                    Overall_Qual_Fair  \n                                           -9.709e-03  \n                           Overall_Qual_Below_Average  \n                                           -7.711e-03  \n                                 Overall_Qual_Average  \n                                            1.465e-02  \n                           Overall_Qual_Above_Average  \n                                            2.453e-02  \n                                    Overall_Qual_Good  \n                                            3.288e-02  \n                               Overall_Qual_Very_Good  \n                                            5.065e-02  \n                               Overall_Qual_Excellent  \n                                            5.328e-02  \n                                    Overall_Cond_Fair  \n                                            8.424e-02  \n                           Overall_Cond_Below_Average  \n                                            1.386e-01  \n                                 Overall_Cond_Average  \n                                            1.647e-01  \n                           Overall_Cond_Above_Average  \n                                            1.786e-01  \n                                    Overall_Cond_Good  \n                                            1.976e-01  \n                               Overall_Cond_Very_Good  \n                                            2.004e-01  \n                               Overall_Cond_Excellent  \n                                            2.172e-01  \n                                     Roof_Style_Gable  \n                                            3.064e-03  \n                                       Roof_Style_Hip  \n                                            1.400e-03  \n                                 Exterior_1st_AsbShng  \n                                           -2.269e-02  \n                                 Exterior_1st_BrkFace  \n                                            1.762e-02  \n                                 Exterior_1st_CemntBd  \n                                           -6.648e-02  \n                                 Exterior_1st_HdBoard  \n                                           -2.029e-02  \n                                 Exterior_1st_MetalSd  \n                                           -9.188e-03  \n                                 Exterior_1st_Plywood  \n                                           -1.778e-02  \n                                  Exterior_1st_Stucco  \n                                           -2.030e-02  \n                                 Exterior_1st_VinylSd  \n                                           -3.227e-02  \n                                 Exterior_1st_Wd.Sdng  \n                                           -1.530e-02  \n                                 Exterior_1st_WdShing  \n                                           -2.727e-02  \n                                 Exterior_2nd_AsbShng  \n                                           -2.730e-02  \n                                 Exterior_2nd_BrkFace  \n                                           -2.295e-02  \n                                 Exterior_2nd_CmentBd  \n                                            4.882e-02  \n                                 Exterior_2nd_HdBoard  \n                                           -5.905e-03  \n                                 Exterior_2nd_MetalSd  \n                                           -5.823e-03  \n                                 Exterior_2nd_Plywood  \n                                           -7.550e-03  \n                                  Exterior_2nd_Stucco  \n                                            7.010e-03  \n                                 Exterior_2nd_VinylSd  \n                                            9.093e-03  \n                                 Exterior_2nd_Wd.Sdng  \n                                           -3.418e-03  \n                                 Exterior_2nd_Wd.Shng  \n                                            3.114e-03  \n                                 Mas_Vnr_Type_BrkFace  \n                                            1.391e-02  \n                                    Mas_Vnr_Type_None  \n                                            1.470e-02  \n                                   Mas_Vnr_Type_Stone  \n                                            2.233e-02  \n                                 Exter_Qual_Excellent  \n                                            4.355e-02  \n                                      Exter_Qual_Fair  \n                                           -1.018e-02  \n                                      Exter_Qual_Good  \n                                            7.081e-03  \n                                      Exter_Cond_Fair  \n                                           -5.441e-02  \n                                      Exter_Cond_Good  \n                                           -2.790e-02  \n                                   Exter_Cond_Typical  \n                                           -2.038e-02  \n                                    Foundation_BrkTil  \n                                           -2.178e-02  \n                                    Foundation_CBlock  \n                                           -1.965e-02  \n                                     Foundation_PConc  \n                                           -1.085e-02  \n                                      Foundation_Slab  \n                                            6.116e-05  \n                                  Bsmt_Qual_Excellent  \n                                            3.459e-02  \n                                       Bsmt_Qual_Fair  \n                                            6.404e-03  \n                                       Bsmt_Qual_Good  \n                                            2.045e-02  \n                                Bsmt_Qual_No_Basement  \n                                            2.428e-02  \n                                    Bsmt_Qual_Typical  \n                                            1.874e-02  \n                                     Bsmt_Exposure_Av  \n                                            3.624e-03  \n                                     Bsmt_Exposure_Gd  \n                                            2.669e-02  \n                                     Bsmt_Exposure_Mn  \n                                            5.688e-05  \n                                     Bsmt_Exposure_No  \n                                           -4.150e-03  \n                                   BsmtFin_Type_1_ALQ  \n                                            8.386e-02  \n                                   BsmtFin_Type_1_BLQ  \n                                            6.682e-02  \n                                   BsmtFin_Type_1_GLQ  \n                                            5.941e-02  \n                                   BsmtFin_Type_1_LwQ  \n                                            3.318e-02  \n                                   BsmtFin_Type_1_Rec  \n                                            7.956e-03  \n                                 Heating_QC_Excellent  \n                                            7.722e-01  \n                                      Heating_QC_Fair  \n                                            7.472e-01  \n                                      Heating_QC_Good  \n                                            7.654e-01  \n                                   Heating_QC_Typical  \n                                            7.598e-01  \n                                        Central_Air_N  \n                                           -2.408e-02  \n                                     Electrical_FuseA  \n                                           -1.545e-02  \n                                     Electrical_FuseF  \n                                           -1.968e-02  \n                                     Electrical_SBrkr  \n                                           -1.951e-02  \n                               Kitchen_Qual_Excellent  \n                                            3.178e-02  \n                                    Kitchen_Qual_Fair  \n                                           -3.273e-03  \n                                    Kitchen_Qual_Good  \n                                            5.608e-03  \n                               Fireplace_Qu_Excellent  \n                                           -1.090e-02  \n                                    Fireplace_Qu_Fair  \n                                           -5.742e-03  \n                                    Fireplace_Qu_Good  \n                                            3.799e-03  \n                            Fireplace_Qu_No_Fireplace  \n                                           -2.870e-03  \n                                    Fireplace_Qu_Poor  \n                                           -8.559e-03  \n                                   Garage_Type_Attchd  \n                                            2.717e-02  \n                                  Garage_Type_Basment  \n                                            1.841e-02  \n                                  Garage_Type_BuiltIn  \n                                            2.514e-02  \n                                   Garage_Type_Detchd  \n                                            2.309e-02  \n                                Garage_Type_No_Garage  \n                                            4.121e-04  \n                                    Garage_Finish_Fin  \n                                            9.351e-04  \n                              Garage_Finish_No_Garage  \n                                           -5.710e-03  \n                                    Garage_Finish_RFn  \n                                           -2.171e-03  \n                                     Garage_Qual_Fair  \n                                           -2.731e-02  \n                                  Garage_Qual_Typical  \n                                           -1.877e-02  \n                                     Garage_Cond_Fair  \n                                           -2.552e-02  \n                                  Garage_Cond_Typical  \n                                           -1.678e-03  \n                              Paved_Drive_Dirt_Gravel  \n                                           -4.599e-03  \n                         Paved_Drive_Partial_Pavement  \n                                           -7.736e-03  \n                                   Fence_Good_Privacy  \n                                           -4.646e-03  \n                                      Fence_Good_Wood  \n                                           -1.104e-02  \n                                Fence_Minimum_Privacy  \n                                           -1.837e-03  \n                                       Fence_No_Fence  \n                                           -3.494e-03  \n                                        Sale_Type_COD  \n                                           -1.792e-02  \n                                        Sale_Type_New  \n                                            1.829e-02  \n                                        Sale_Type_WD.  \n                                           -1.673e-02  \n                               Sale_Condition_Abnorml  \n                                           -4.424e-02  \n                                Sale_Condition_Family  \n                                           -2.159e-02  \n                                Sale_Condition_Normal  \n                                           -1.563e-03  \n                               Sale_Condition_Partial  \n                                           -2.112e-02  \n\n\nTo obtain the detailed results from our trained linear regression model in a data frame, we can use the tidy() and glance() functions directly on our trained parsnip model, ames_fit.\n\nThe tidy() function takes a linear regression object and returns a data frame of the estimated model coefficients and their associated F-statistics and p-values;\nThe glance() function returns performance metrics obtained on the training data;\nWe can also use the vip() function to plot the variable importance for each predictor in our model. The importance value is determined based on the F-statistics and estimate coefficents in our trained model object.\n\n\n# Data frame of estimated coefficients\ntidy(ames_fit)\n\n# A tibble: 187 × 5\n   term          estimate std.error statistic   p.value\n   <chr>            <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)    4.22      0.0965     43.8   8.49e-300\n 2 Lot_Frontage   0.00151   0.00121     1.24  2.14e-  1\n 3 Lot_Area       0.00563   0.00129     4.35  1.42e-  5\n 4 Mas_Vnr_Area   0.00318   0.00168     1.89  5.90e-  2\n 5 BsmtFin_SF_1   0.0291    0.0248      1.17  2.41e-  1\n 6 BsmtFin_SF_2  -0.00244   0.00119    -2.05  4.03e-  2\n 7 Bsmt_Unf_SF   -0.00986   0.00209    -4.71  2.61e-  6\n 8 Total_Bsmt_SF  0.0305    0.00326     9.36  2.01e- 20\n 9 First_Flr_SF   0.00466   0.00910     0.512 6.09e-  1\n10 Second_Flr_SF  0.00963   0.0100      0.960 3.37e-  1\n# … with 177 more rows\n\n# Performance metrics on training data\nglance(ames_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.sq…¹  sigma stati…² p.value    df logLik    AIC    BIC devia…³\n      <dbl>      <dbl>  <dbl>   <dbl>   <dbl> <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n1     0.934      0.928 0.0479    164.       0   185  3884. -7395. -6318.    4.94\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\n# Plot variable importance\nvip(ames_fit)\n\n\n\n\n\n\nTo assess the accuracy of our trained linear regression model, we must use it to make predictions on new data. This is done with the predict() function from parnsip. This function takes two important arguments:\n\na trained parnsip model object;\nnew_data for which to generate predictions.\n\nLet’s check how the model performs on our test dataset. The code below uses the predict() function to generate a data frame with a single column, .pred, which contains the predicted Sale Price values on the ames_test data.\n\npredict(ames_fit, new_data = ames_test_baked)\n\n# A tibble: 586 × 1\n   .pred\n   <dbl>\n 1  5.03\n 2  5.19\n 3  5.39\n 4  5.13\n 5  5.23\n 6  4.99\n 7  4.99\n 8  4.98\n 9  5.14\n10  5.77\n# … with 576 more rows\n\n\nGenerally it’s best to combine the new data set and the predictions into a single data frame. We create a data frame with the predictions on the training data and then use bind_cols() to add the baked test data to the results.\n\names_test_results <- predict(ames_fit, new_data = ames_test_baked) %>% \n  bind_cols(ames_test_baked)\n\n# View results\names_test_results\n\n# A tibble: 586 × 188\n   .pred Lot_F…¹ Lot_A…² Mas_V…³ BsmtF…⁴ BsmtF…⁵ Bsmt_…⁶ Total…⁷ First…⁸ Secon…⁹\n   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  5.03   0.675   0.172 -0.569    0.819   0.552 -0.657  -0.388   -0.689  -0.786\n 2  5.19   0.705   0.488  0.0527  -1.42   -0.298 -0.347   0.670    0.456  -0.786\n 3  5.39   0.916   0.145  1.45    -0.523  -0.298 -0.336   1.92     1.85   -0.786\n 4  5.13   0.224  -0.207 -0.569   -0.970  -0.298 -0.632   0.0242  -0.266  -0.786\n 5  5.23  -0.949  -0.516 -0.569   -0.523  -0.298 -0.466   0.850    0.477  -0.786\n 6  4.99  -1.10   -1.01   2.33     0.819  -0.298 -0.527  -1.33    -1.78    0.392\n 7  4.99  -1.10   -1.01   2.26     0.819  -0.298 -0.759  -1.23    -1.67    0.539\n 8  4.98  -1.10   -1.01   1.62     1.27   -0.298 -0.0770 -1.23    -1.67    0.539\n 9  5.14  -1.01   -0.943 -0.569   -1.42   -0.298 -0.495  -0.452   -0.797   0.618\n10  5.77   1.58    0.492  5.74    -0.523  -0.298  2.08    4.26     4.07   -0.786\n# … with 576 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\n\nNow we have the model results and the test data in a single data frame.\n\n\n\n\n\nRoot Mean Square Error (RMSE): difference between the predicted and observed values (loss of function);\n\nR-squared (rsq): squared correlation between the predicted and observed values.\n\n\nTo obtain the rmse and rsq values on our results, we can use the rmse() and rsq() functions. Both functions take the following arguments:\n\na data frame with columns that have the true values and predictions;\nthe column with the true response values;\nthe column with predicted values.\n\nIn the examples below we pass our ames_test_results to these functions to obtain these values for our test set. Results are always returned as a data frame with the following columns: .metric, .estimator, and .estimate.\n\n#RMSE on test set\ntest_rmse <- rmse(ames_test_results, \n     truth = Sale_Price,\n     estimate = .pred)\n\ntest_rmse\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      0.0656\n\n#rsq on test set\ntest_rsq<- rsq(ames_test_results,\n    truth = Sale_Price,\n    estimate = .pred)\n\ntest_rsq\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.858\n\n\nLet’s visualise the situation with an R2 plot:\n\names_test_results %>%\n  ggplot(aes(Sale_Price, .pred)) +\n  geom_abline(intercept = 0, slope = 1, color = \"black\", linewidth = 0.5, linetype=\"dotted\") +\n  geom_point(alpha = 0.15, color = \"blue\") +\n  labs(\n    x = \"Actual Selling Price\",\n    y = \"Predicted Selling Price\",\n    color = \"Test/Training data\"\n  )\n\n\n\n\nThis is a plot that can be used for any regression model. It plots the actual values (Sale Prices) versus the model predictions (.pred) as a scatter plot. It also plot the line y = x through the origin. This line is a visually representation of the perfect model where all predicted values are equal to the true values in the test set. The farther the points are from this line, the worse the model fit. The reason this plot is called an R2 plot, is because the R2 is the squared correlation between the true and predicted values, which are plotted as paired in the plot.\n\n\nYou just trained your model one time on the whole training set and then evaluated them on the testing set. Statisticians have come up with a slew of approaches to evaluate models in better ways than this; many important ones fall under the category of resampling.\nWe can resample the training set to produce an estimate of how the model will perform.The idea of resampling is to create simulated data sets that can be used to estimate the performance of your model, say, because you want to compare models. You can create these resampled data sets instead of using either your training set (which can give overly optimistic results, especially for powerful ML algorithms) or your testing set (which is extremely valuable and can only be used once or at most twice). One of these resampling methods is cross-validation.\nCross-validation means taking your training set and randomly dividing it up evenly into subsets, sometimes called “folds”. A fold here means a group or subset or partition.\nYou use one of the folds for validation and the rest for training, then you repeat these steps with all the subsets and combine the results, usually by taking the mean. Cross-validation allows you to get a more accurate estimate of how your model will perform on new data.\n\n\n\n\n\n\nChallenge X\n\n\n\nWhen you implement 10-fold cross-validation repeated 5 times, you:\n\nrandomly divide your training data into 50 subsets and train on 49 at a time (assessing on the other subset), iterating through all 50 subsets for assessment.\nrandomly divide your training data into 10 subsets and train on 9 at a time (assessing on the other subset), iterating through all 10 subsets for assessment. Then you repeat that process 5 times.\nrandomly divide your training data into 5 subsets and train on 4 at a time (assessing on the other subset), iterating through all 5 subsets. Then you repeat that process 10 times.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimulations and practical experience show that 10-fold cross-validation repeated 5 times is a great resampling approach for many situations. This approach involves randomly dividing your training data into 10 folds, or subsets or groups, and training on only 9 while using the other fold for assessment. You iterate through all 10 folds being used for assessment; this is one round of cross-validation. You can then repeat the whole process multiple, perhaps 5, times.\n\n\n\n\nset.seed(9)\n\names_folds <- vfold_cv(ames_train, v=10, repeats = 5, strata = Sale_Price)\n\nglimpse(ames_folds)\n\nRows: 50\nColumns: 3\n$ splits <list> [<vfold_split[2103 x 236 x 2339 x 81]>], [<vfold_split[2103 x …\n$ id     <chr> \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1…\n$ id2    <chr> \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06\", \"Fo…\n\n\n\n\nIn the previous section, we trained a linear regression model to the housing data step-by-step. In this section, we will go over how to combine all of the modeling steps into a single workflow.\nThe workflow package was designed to capture the entire modeling process and combine models and recipes into a single object. To create a workflow, we start with workflow() to create an empty workflow and then add out model and recipe with add_model() and add_recipe().\n\names_wf <- workflow() %>%\n  add_model(ames_model) %>% \n  add_recipe(ames_rec)\n\names_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n• step_other()\n• step_nzv()\n• step_center()\n• step_scale()\n• step_dummy()\n• step_lincomb()\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\nComputational engine: lm \n\n\nOnce we have created a set of resamples, we can use the function fit_resamples() to fit a model to each resample and compute performance metrics for each.\n\nset.seed(234)\names_res <- ames_wf %>%\n  fit_resamples(\n    ames_folds,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nglimpse(ames_res)\n\nRows: 50\nColumns: 6\n$ splits       <list> [<vfold_split[2103 x 236 x 2339 x 81]>], [<vfold_split[2…\n$ id           <chr> \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"R…\n$ id2          <chr> \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06…\n$ .metrics     <list> [<tbl_df[2 x 4]>], [<tbl_df[2 x 4]>], [<tbl_df[2 x 4]>],…\n$ .notes       <list> [<tbl_df[1 x 3]>], [<tbl_df[1 x 3]>], [<tbl_df[1 x 3]>],…\n$ .predictions <list> [<tbl_df[236 x 4]>], [<tbl_df[236 x 4]>], [<tbl_df[236 x…\n\nqsave(ames_res, \"../_models/ames_res.qs\")\n\n\nLinear regression detects some redundancies in the predictor set. We can ignore the warnings since lm() can deal with it.\n\nThe column .metric contains the performance statistics created from the 10 assessment sets. These can be manually unnested but the tune package contains a number of simple functions that can extract these data:\n\n# Obtain performance metrics on resampled training data\names_res %>% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.0540    50 0.00129 Preprocessor1_Model1\n2 rsq     standard   0.909     50 0.00368 Preprocessor1_Model1\n\n\nWe can see that the regression relationship is very strong: 90.8% of the variability in the selling price can be explained by the predictors and, on average, each element in the predicted selling price differs from the actual selling price by 0.05.\nWe can reliably measure performance using only the training data.\nIf we wanted to try different model types for this data set, we could more confidently compare performance metrics computed using resampling to choose between models. Also, remember that at the end of our project, we return to our test set to estimate final model performance.\n\names_res %>%\n  collect_predictions() %>%\n  ggplot(aes(.pred, Sale_Price, color = id)) + \n  geom_abline(intercept = 0, slope = 1, color = 'black', linewidth=0.5, linetype=\"dotted\") +\n  geom_point(alpha = 0.15) +\n   labs(title = 'Linear Regression Results - Ames Test Set',\n       x = 'Predicted Selling Price',\n       y = 'Actual Selling Price')\n\n\n\n\n\n\nLet’s use the last_fit() function to evaluate once on the testing set:\n\n#Final fit on test dataset\names_final <- ames_wf %>%\n  last_fit(ames_split)\n\n# Obtain performance metrics on test data\ncollect_metrics(ames_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard      0.0656 Preprocessor1_Model1\n2 rsq     standard      0.858  Preprocessor1_Model1\n\n\nThe R2 and RMSE metrics are similar for both the training and testing datasets in our linear regression model. This is a good sign that the model is not over-fitting and can be used for making predictions on new data.\nWe can save the test set predictions by using the collect_predictions() function. This function returns a data frame which will have the response variables values from the test set and a column named .pred with the model predictions.\n\n# Obtain test set predictions data frame\names_results_final <- ames_final %>% \n                 collect_predictions()\n# View results\names_results_final\n\n# A tibble: 586 × 5\n   id               .pred  .row Sale_Price .config             \n   <chr>            <dbl> <int>      <dbl> <chr>               \n 1 train/test split  5.03     2       5.02 Preprocessor1_Model1\n 2 train/test split  5.19     3       5.24 Preprocessor1_Model1\n 3 train/test split  5.39    18       5.60 Preprocessor1_Model1\n 4 train/test split  5.13    26       5.15 Preprocessor1_Model1\n 5 train/test split  5.23    29       5.26 Preprocessor1_Model1\n 6 train/test split  4.99    30       4.98 Preprocessor1_Model1\n 7 train/test split  4.99    31       5.02 Preprocessor1_Model1\n 8 train/test split  4.98    32       4.94 Preprocessor1_Model1\n 9 train/test split  5.14    34       5.18 Preprocessor1_Model1\n10 train/test split  5.77    47       5.70 Preprocessor1_Model1\n# … with 576 more rows\n\n\nFinally, let’s use this data frame to make an R2 plot to visualize our model performance on the test data set:\n\nggplot(data = ames_results_final,\n       mapping = aes(x = .pred, y = Sale_Price)) +\n  geom_point(color = '#006EA1', alpha = 0.25) +\n  geom_abline(intercept = 0, slope = 1, color = 'black', linewidth=0.5, linetype=\"dotted\") +\n  labs(title = 'Linear Regression Results - Ames Test Set',\n       x = 'Predicted Selling Price',\n       y = 'Actual Selling Price')\n\n\n\n\n\n\n\n\n\n\nKey points\n\n\n\n\nThe workflows package enables a handy type of object that can bundle pre-processing and models together;\nYou don’t have to keep track of separate objects in your workspace;\nThe recipe prepping and model fitting can be executed using a single call to fit() instead of prep()-juice()-fit();\nThe recipe baking and model predictions are handled with a single call to predict() instead of bake()-predict();\nWorkflows are be able to evaluate different recipes and models at once (as we will see in Day 2 of this workshop);\n\nvfold_cv() creates folds for cross-validation;\n\nfit_resamples() fits models to resamples;\n\ncollect_metrics() obtains performance metrics from the results.\n\n\n\n\nAdapted from “Linear Regression and tidymodels”, available here.\nMax Kuhn and Julia Silge, “Tidy Modeling with R”, Version 1.0.0(2022-12-20)."
  },
  {
    "objectID": "100_regression/step2.html#build-a-simple-linear-regression-model-using-base-r",
    "href": "100_regression/step2.html#build-a-simple-linear-regression-model-using-base-r",
    "title": "Sydney Informatics Hub",
    "section": "Build a simple linear regression model using base R",
    "text": "Build a simple linear regression model using base R\n\nIn a linear model, we assume that there is a linear relationship between the input variable(s) and the output variable. This means that as the input variable(s) increase or decrease, the output variable changes in a straight line.\nImagine you have a scatter plot with your data points all over it. A linear model is like drawing a straight line through the scatter plot that best fits all the points. The slope and intercept of this line are chosen in such a way that the distance between the line and all the points is minimized. This line is then used to predict the output for new input values.\n\n\nExample of a linear model\n\n\nThe straight red dotted line represents the linear model equation \\(y=mx+c\\), where \\(c\\) is the y-intercept of the regression line, \\(m\\) is the slope of the regression line, and \\(y\\) is the expected value for y for the given \\(x\\) value.\n\n#fit a linear model\names_lm <- lm(Sale_Price ~ Gr_Liv_Area, data = ames_data)\n\n#Print the summary of the model\nsummary(ames_lm)\n\n\nCall:\nlm(formula = Sale_Price ~ Gr_Liv_Area, data = ames_data)\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.94258 -0.06622  0.01359  0.07298  0.39246 \nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 4.835e+00  7.406e-03  652.80   <2e-16 ***\nGr_Liv_Area 2.579e-04  4.714e-06   54.72   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nResidual standard error: 0.124 on 2923 degrees of freedom\nMultiple R-squared:  0.506, Adjusted R-squared:  0.5058 \nF-statistic:  2994 on 1 and 2923 DF,  p-value: < 2.2e-16\n\n\nR-squared value explains the variability of y with respect to x:\n\nvaries between 0 to 1 (0-100%);\nR-squared values closer to 0 mean the regression relationship is very low;\nR-squared values closer to 1 mean the regression relationship is very strong.\n\nLet’s plot our linear regression model:\n\nplot(ames_data$Gr_Liv_Area, ames_data$Sale_Price,\n     xlab=\"Gr_Liv_Area\",\n     ylab=\"Sale_Price\", \n     col = \"blue\")\nabline(ames_lm, col = \"red\")"
  },
  {
    "objectID": "100_regression/step2.html#build-a-linear-regression-model-using-tidymodels",
    "href": "100_regression/step2.html#build-a-linear-regression-model-using-tidymodels",
    "title": "Sydney Informatics Hub",
    "section": "Build a linear regression model using Tidymodels",
    "text": "Build a linear regression model using Tidymodels\n\nWhen you type library(tidymodels), you load a collection of packages for modeling and machine learning using tidyverse principles. All the packages are designed to be consistent, modular, and to support good modeling practices. The first thing we are going to practice is splitting your data into a training set and a testing set. The tidymodels package rsample has functions that help you specify training and testing sets.\n\nset.seed(42) #so we all get the same results\names_split <- ames_data %>%\n    initial_split(prop = 0.8,\n                  strata = Sale_Price) #stratification\n\names_train <- training(ames_split)\names_test <- testing(ames_split)\n\nsaveRDS(ames_train, \"../_models/ames_train.Rds\")\nsaveRDS(ames_test, \"../_models/ames_test.Rds\")\n\nStratified sampling would split within each quartile: \nThe code here takes an input data set and puts 80% of it into a training dataset and 20% of it into a testing dataset; it chooses the individual cases so that both sets are balanced in selling price.\nLet’s check if the distribution of the selling price is the same in the testing and training datasets:\n\names_train %>% \n  ggplot(aes(x = log(Sale_Price),  col = \"red\", fill = NULL)) + \n  geom_density() + theme_minimal() +\n  geom_line(data = ames_test,\n            stat = \"density\",\n            col = \"blue\") + theme(legend.position=\"none\")\n\n\n\n\nFeature engineering\n\nWe might want to modify our predictors columns for a few reasons:\n\nThe model requires them in a different format;\nThe model needs certain data qualities;\nThe outcome is better predicted when one or more columns are transformed in some way (a.k.a “feature engineering”).\n\n\nIn tidymodels, you can use the recipes package, an extensible framework for pipeable sequences of feature engineering steps that provide preprocessing tools to be applied to data.\n\nSome of these steps can include:\n\nScaling and centering numeric predictors;\nRemoving skewness from numeric variables;\nOne-hot and dummy variable encoding for categorical variables;\nRemoving correlated predictors and zero variance variables;\nImputing missing data.\n\n\nStatistical parameters for the steps can be estimated from an initial data set and then applied to other data sets.\n\n\nThe resulting processed output can be used as inputs for statistical or machine learning models.\n\n\names_rec <-\n  recipe(Sale_Price ~ ., data = ames_train) %>% #assigns columns to roles of “outcome” or “predictor” using the formula\n  step_other(all_nominal(), threshold = 0.01) %>% #useful when you have some factor levels with very few observations, all_nominal selects both characters and factors, pools infrequently occurring values (frequency less than 0.01) into an \"other\" category\n  step_nzv(all_predictors()) %>% #remove predictors that are highly sparse and unbalanced\n  step_center(all_numeric_predictors()) %>% #subtracts the column mean from predictors\n  step_scale(all_numeric_predictors()) %>% #divides by the standard deviation\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% #for any nominal predictor, make binary indicators\n  step_lincomb(all_numeric_predictors()) #remove redundancies in the predictors, if present\n\names_rec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 80\n\n\n\n\n\n── Operations \n\n\n• Collapsing factor levels for: all_nominal()\n\n\n• Sparse, unbalanced variable filter on: all_predictors()\n\n\n• Centering for: all_numeric_predictors()\n\n\n• Scaling for: all_numeric_predictors()\n\n\n• Dummy variables from: all_nominal_predictors()\n\n\n• Linear combination filter on: all_numeric_predictors()\n\n\nNote that each successive step() function adds a preprocessing step to our recipe object in the order that they are provided. The preprocessing recipe ames_rec has been defined but no values have been estimated.\n\n\nThe prep() function takes that defined object and computes everything so that the preprocessing steps can be executed. Note that This is done with the training data.\n\n\n\names_prep <- prep(ames_rec)\n\names_prep\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 80\n\n\n\n\n\n── Training information \n\n\nTraining data contained 2339 data points and no incomplete rows.\n\n\n\n\n\n── Operations \n\n\n• Collapsing factor levels for: MS_SubClass, MS_Zoning, Street, ... | Trained\n\n\n• Sparse, unbalanced variable filter removed: Street, Alley, ... | Trained\n\n\n• Centering for: Lot_Frontage, Lot_Area, Mas_Vnr_Area, ... | Trained\n\n\n• Scaling for: Lot_Frontage, Lot_Area, Mas_Vnr_Area, ... | Trained\n\n\n• Dummy variables from: MS_SubClass, MS_Zoning, Lot_Shape, ... | Trained\n\n\n• Linear combination filter removed: MS_Zoning_other, ... | Trained\n\n\nThe bake() and juice() functions both return data, not a preprocessing recipe object.\n\n\nThe bake() function takes a prepped recipe (one that has had all quantities estimated from training data) and applies it to new_data. That new_data could be the training data again or it could be the testing data (with the TRAINING parameters)\n\n\n\nbake(ames_prep, new_data = ames_test)\n\n# A tibble: 586 × 187\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1        0.675    0.172 -0.569    0.819   0.552 -0.657  -0.388   -0.689  -0.786\n 2        0.705    0.488  0.0527  -1.42   -0.298 -0.347   0.670    0.456  -0.786\n 3        0.916    0.145  1.45    -0.523  -0.298 -0.336   1.92     1.85   -0.786\n 4        0.224   -0.207 -0.569   -0.970  -0.298 -0.632   0.0242  -0.266  -0.786\n 5       -0.949   -0.516 -0.569   -0.523  -0.298 -0.466   0.850    0.477  -0.786\n 6       -1.10    -1.01   2.33     0.819  -0.298 -0.527  -1.33    -1.78    0.392\n 7       -1.10    -1.01   2.26     0.819  -0.298 -0.759  -1.23    -1.67    0.539\n 8       -1.10    -1.01   1.62     1.27   -0.298 -0.0770 -1.23    -1.67    0.539\n 9       -1.01    -0.943 -0.569   -1.42   -0.298 -0.495  -0.452   -0.797   0.618\n10        1.58     0.492  5.74    -0.523  -0.298  2.08    4.26     4.07   -0.786\n# … with 576 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\n\n\n\nThe juice() function is a nice little shortcut. When we juice() the recipe, we squeeze that training data back out, transformed in the ways we specified.\n\n\nLet’s compare the bake() and juice() outputs:\n\nbake(ames_prep, new_data = ames_train)\n\n# A tibble: 2,339 × 187\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       0.374   -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2       0.374    0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3      -0.137   -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4      -1.01    -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5      -0.0770  -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6      -0.227   -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7       0.374   -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8       0.314   -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9      -1.73    -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10      -1.73    -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\njuice(ames_prep) \n\n# A tibble: 2,339 × 187\n   Lot_Frontage Lot_Area Mas_V…¹ BsmtF…² BsmtF…³ Bsmt_…⁴ Total…⁵ First…⁶ Secon…⁷\n          <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1       0.374   -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2       0.374    0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3      -0.137   -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4      -1.01    -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5      -0.0770  -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6      -0.227   -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7       0.374   -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8       0.314   -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9      -1.73    -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10      -1.73    -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\n\nNote that the juice() output is the same as bake(ames_rep, new_data = ames_train) and is just a shortcut that we are going to use later.\n\n\n\n\n\n\nChallenge X\n\n\n\nDoes it make sense to apply these preprocessing steps to the test set?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNo, it doesn’t. You want the set test to look like new data that your model will see in the future, so you don’t want to mess with the class balance there; you want to see how your model will perform on imbalanced data, even if you have trained it on artificially balanced data.\n\n\n\nBuild the model\n\nIn tidymodels, you specify models using three concepts.\n\nModel type differentiates models such as logistic regression, decision tree models, and so forth;\nModel mode includes common options like regression and classification, some model types support either of these while some only have one mode;\nModel engine is the computational tool which will be used to fit the model.\n\nWe will specify the model using the parsnip package - Many functions have different interfaces and arguments names and parsnip standardizes the interface for fitting models as well as the return values.\n\n#a linear regression model specification\names_model <- linear_reg() %>% #pick a model\n  set_engine(\"lm\")           #set the engine\n                             #set_mode(\"regression\") we don't need this as the model linear_reg() only does regression\n\n#view model properties\names_model\n\nLinear Regression Model Specification (regression)\nComputational engine: lm \n\n\nNow we are ready to train our model object on the training data. We can do this using the fit() function from the parsnip package. The fit() function takes the following arguments:\n\na parnsip model object specification;\na model formula\na data frame with the training data\n\nThe code below trains our linear regression model on the prepped training data. In our formula, we have specified that Sale_Price is the response variable and included all the rest as our predictor variables.\n\names_fit <- ames_model %>%\n  fit(Sale_Price ~ .,\n      data=juice(ames_prep))\n\n# View lm_fit properties\names_fit\n\nparsnip model object\nCall:\nstats::lm(formula = Sale_Price ~ ., data = data)\nCoefficients:\n                                          (Intercept)  \n                                            4.225e+00  \n                                         Lot_Frontage  \n                                            1.510e-03  \n                                             Lot_Area  \n                                            5.634e-03  \n                                         Mas_Vnr_Area  \n                                            3.178e-03  \n                                         BsmtFin_SF_1  \n                                            2.910e-02  \n                                         BsmtFin_SF_2  \n                                           -2.438e-03  \n                                          Bsmt_Unf_SF  \n                                           -9.865e-03  \n                                        Total_Bsmt_SF  \n                                            3.052e-02  \n                                         First_Flr_SF  \n                                            4.657e-03  \n                                        Second_Flr_SF  \n                                            9.635e-03  \n                                          Gr_Liv_Area  \n                                            4.895e-02  \n                                       Bsmt_Full_Bath  \n                                            4.946e-03  \n                                       Bsmt_Half_Bath  \n                                            1.160e-03  \n                                            Full_Bath  \n                                            7.528e-03  \n                                            Half_Bath  \n                                            6.568e-03  \n                                        Bedroom_AbvGr  \n                                           -3.780e-03  \n                                        TotRms_AbvGrd  \n                                           -4.477e-05  \n                                           Fireplaces  \n                                            5.691e-03  \n                                          Garage_Cars  \n                                            8.626e-03  \n                                          Garage_Area  \n                                            6.286e-03  \n                                         Wood_Deck_SF  \n                                            1.943e-03  \n                                        Open_Porch_SF  \n                                            1.901e-03  \n                                              Mo_Sold  \n                                           -3.097e-04  \n                                            Year_Sold  \n                                           -2.016e-03  \n                                            Longitude  \n                                           -8.325e-03  \n                                             Latitude  \n                                           -4.980e-03  \n                                   Time_Since_Remodel  \n                                           -5.556e-03  \n                                            House_Age  \n                                           -1.929e-02  \n      MS_SubClass_One_Story_1946_and_Newer_All_Styles  \n                                            6.196e-03  \n                 MS_SubClass_One_Story_1945_and_Older  \n                                           -2.177e-02  \n     MS_SubClass_One_and_Half_Story_Finished_All_Ages  \n                                            2.813e-02  \n                 MS_SubClass_Two_Story_1946_and_Newer  \n                                           -1.093e-02  \n                 MS_SubClass_Two_Story_1945_and_Older  \n                                            1.847e-02  \n                      MS_SubClass_Split_or_Multilevel  \n                                           -2.027e-02  \n                              MS_SubClass_Split_Foyer  \n                                            3.816e-03  \n               MS_SubClass_Duplex_All_Styles_and_Ages  \n                                           -2.177e-03  \n             MS_SubClass_One_Story_PUD_1946_and_Newer  \n                                            2.046e-02  \n             MS_SubClass_Two_Story_PUD_1946_and_Newer  \n                                           -2.533e-02  \nMS_SubClass_Two_Family_conversion_All_Styles_and_Ages  \n                                            2.991e-03  \n                                    MS_SubClass_other  \n                                                   NA  \n               MS_Zoning_Floating_Village_Residential  \n                                            3.984e-02  \n                    MS_Zoning_Residential_Low_Density  \n                                            3.224e-02  \n                 MS_Zoning_Residential_Medium_Density  \n                                            2.443e-02  \n                                    Lot_Shape_Regular  \n                                            4.462e-03  \n                         Lot_Shape_Slightly_Irregular  \n                                            4.294e-03  \n                       Lot_Shape_Moderately_Irregular  \n                                            1.805e-02  \n                                    Lot_Config_Corner  \n                                            5.998e-03  \n                                   Lot_Config_CulDSac  \n                                            1.298e-02  \n                                       Lot_Config_FR2  \n                                           -5.176e-03  \n                                    Lot_Config_Inside  \n                                            3.934e-03  \n                              Neighborhood_North_Ames  \n                                           -1.547e-02  \n                           Neighborhood_College_Creek  \n                                           -3.736e-02  \n                                Neighborhood_Old_Town  \n                                           -3.894e-02  \n                                 Neighborhood_Edwards  \n                                           -4.494e-02  \n                                Neighborhood_Somerset  \n                                            1.495e-02  \n                      Neighborhood_Northridge_Heights  \n                                            1.344e-02  \n                                 Neighborhood_Gilbert  \n                                           -8.690e-03  \n                                  Neighborhood_Sawyer  \n                                           -2.252e-02  \n                          Neighborhood_Northwest_Ames  \n                                           -1.568e-02  \n                             Neighborhood_Sawyer_West  \n                                           -3.405e-02  \n                                Neighborhood_Mitchell  \n                                           -2.449e-02  \n                               Neighborhood_Brookside  \n                                           -1.037e-02  \n                                Neighborhood_Crawford  \n                                            1.911e-02  \n                  Neighborhood_Iowa_DOT_and_Rail_Road  \n                                           -4.515e-02  \n                              Neighborhood_Timberland  \n                                           -2.225e-02  \n                              Neighborhood_Northridge  \n                                            1.195e-02  \n                             Neighborhood_Stone_Brook  \n                                            3.834e-02  \n Neighborhood_South_and_West_of_Iowa_State_University  \n                                           -3.175e-02  \n                             Neighborhood_Clear_Creek  \n                                           -1.395e-02  \n                          Neighborhood_Meadow_Village  \n                                           -6.325e-02  \n                                   Condition_1_Artery  \n                                           -1.792e-02  \n                                    Condition_1_Feedr  \n                                           -1.227e-02  \n                                     Condition_1_Norm  \n                                            6.575e-03  \n                                     Condition_1_PosN  \n                                            1.180e-02  \n                                     Condition_1_RRAn  \n                                           -1.178e-02  \n                                     Bldg_Type_OneFam  \n                                            3.635e-02  \n                                   Bldg_Type_TwoFmCon  \n                                            2.470e-02  \n                                      Bldg_Type_Twnhs  \n                                           -1.657e-02  \n                         House_Style_One_and_Half_Fin  \n                                           -3.279e-02  \n                                House_Style_One_Story  \n                                           -9.496e-03  \n                                   House_Style_SFoyer  \n                                            5.423e-04  \n                                     House_Style_SLvl  \n                                            1.420e-02  \n                                House_Style_Two_Story  \n                                           -8.472e-03  \n                                    Overall_Qual_Fair  \n                                           -9.709e-03  \n                           Overall_Qual_Below_Average  \n                                           -7.711e-03  \n                                 Overall_Qual_Average  \n                                            1.465e-02  \n                           Overall_Qual_Above_Average  \n                                            2.453e-02  \n                                    Overall_Qual_Good  \n                                            3.288e-02  \n                               Overall_Qual_Very_Good  \n                                            5.065e-02  \n                               Overall_Qual_Excellent  \n                                            5.328e-02  \n                                    Overall_Cond_Fair  \n                                            8.424e-02  \n                           Overall_Cond_Below_Average  \n                                            1.386e-01  \n                                 Overall_Cond_Average  \n                                            1.647e-01  \n                           Overall_Cond_Above_Average  \n                                            1.786e-01  \n                                    Overall_Cond_Good  \n                                            1.976e-01  \n                               Overall_Cond_Very_Good  \n                                            2.004e-01  \n                               Overall_Cond_Excellent  \n                                            2.172e-01  \n                                     Roof_Style_Gable  \n                                            3.064e-03  \n                                       Roof_Style_Hip  \n                                            1.400e-03  \n                                 Exterior_1st_AsbShng  \n                                           -2.269e-02  \n                                 Exterior_1st_BrkFace  \n                                            1.762e-02  \n                                 Exterior_1st_CemntBd  \n                                           -6.648e-02  \n                                 Exterior_1st_HdBoard  \n                                           -2.029e-02  \n                                 Exterior_1st_MetalSd  \n                                           -9.188e-03  \n                                 Exterior_1st_Plywood  \n                                           -1.778e-02  \n                                  Exterior_1st_Stucco  \n                                           -2.030e-02  \n                                 Exterior_1st_VinylSd  \n                                           -3.227e-02  \n                                 Exterior_1st_Wd.Sdng  \n                                           -1.530e-02  \n                                 Exterior_1st_WdShing  \n                                           -2.727e-02  \n                                 Exterior_2nd_AsbShng  \n                                           -2.730e-02  \n                                 Exterior_2nd_BrkFace  \n                                           -2.295e-02  \n                                 Exterior_2nd_CmentBd  \n                                            4.882e-02  \n                                 Exterior_2nd_HdBoard  \n                                           -5.905e-03  \n                                 Exterior_2nd_MetalSd  \n                                           -5.823e-03  \n                                 Exterior_2nd_Plywood  \n                                           -7.550e-03  \n                                  Exterior_2nd_Stucco  \n                                            7.010e-03  \n                                 Exterior_2nd_VinylSd  \n                                            9.093e-03  \n                                 Exterior_2nd_Wd.Sdng  \n                                           -3.418e-03  \n                                 Exterior_2nd_Wd.Shng  \n                                            3.114e-03  \n                                 Mas_Vnr_Type_BrkFace  \n                                            1.391e-02  \n                                    Mas_Vnr_Type_None  \n                                            1.470e-02  \n                                   Mas_Vnr_Type_Stone  \n                                            2.233e-02  \n                                 Exter_Qual_Excellent  \n                                            4.355e-02  \n                                      Exter_Qual_Fair  \n                                           -1.018e-02  \n                                      Exter_Qual_Good  \n                                            7.081e-03  \n                                      Exter_Cond_Fair  \n                                           -5.441e-02  \n                                      Exter_Cond_Good  \n                                           -2.790e-02  \n                                   Exter_Cond_Typical  \n                                           -2.038e-02  \n                                    Foundation_BrkTil  \n                                           -2.178e-02  \n                                    Foundation_CBlock  \n                                           -1.965e-02  \n                                     Foundation_PConc  \n                                           -1.085e-02  \n                                      Foundation_Slab  \n                                            6.116e-05  \n                                  Bsmt_Qual_Excellent  \n                                            3.459e-02  \n                                       Bsmt_Qual_Fair  \n                                            6.404e-03  \n                                       Bsmt_Qual_Good  \n                                            2.045e-02  \n                                Bsmt_Qual_No_Basement  \n                                            2.428e-02  \n                                    Bsmt_Qual_Typical  \n                                            1.874e-02  \n                                     Bsmt_Exposure_Av  \n                                            3.624e-03  \n                                     Bsmt_Exposure_Gd  \n                                            2.669e-02  \n                                     Bsmt_Exposure_Mn  \n                                            5.688e-05  \n                                     Bsmt_Exposure_No  \n                                           -4.150e-03  \n                                   BsmtFin_Type_1_ALQ  \n                                            8.386e-02  \n                                   BsmtFin_Type_1_BLQ  \n                                            6.682e-02  \n                                   BsmtFin_Type_1_GLQ  \n                                            5.941e-02  \n                                   BsmtFin_Type_1_LwQ  \n                                            3.318e-02  \n                                   BsmtFin_Type_1_Rec  \n                                            7.956e-03  \n                                 Heating_QC_Excellent  \n                                            7.722e-01  \n                                      Heating_QC_Fair  \n                                            7.472e-01  \n                                      Heating_QC_Good  \n                                            7.654e-01  \n                                   Heating_QC_Typical  \n                                            7.598e-01  \n                                        Central_Air_N  \n                                           -2.408e-02  \n                                     Electrical_FuseA  \n                                           -1.545e-02  \n                                     Electrical_FuseF  \n                                           -1.968e-02  \n                                     Electrical_SBrkr  \n                                           -1.951e-02  \n                               Kitchen_Qual_Excellent  \n                                            3.178e-02  \n                                    Kitchen_Qual_Fair  \n                                           -3.273e-03  \n                                    Kitchen_Qual_Good  \n                                            5.608e-03  \n                               Fireplace_Qu_Excellent  \n                                           -1.090e-02  \n                                    Fireplace_Qu_Fair  \n                                           -5.742e-03  \n                                    Fireplace_Qu_Good  \n                                            3.799e-03  \n                            Fireplace_Qu_No_Fireplace  \n                                           -2.870e-03  \n                                    Fireplace_Qu_Poor  \n                                           -8.559e-03  \n                                   Garage_Type_Attchd  \n                                            2.717e-02  \n                                  Garage_Type_Basment  \n                                            1.841e-02  \n                                  Garage_Type_BuiltIn  \n                                            2.514e-02  \n                                   Garage_Type_Detchd  \n                                            2.309e-02  \n                                Garage_Type_No_Garage  \n                                            4.121e-04  \n                                    Garage_Finish_Fin  \n                                            9.351e-04  \n                              Garage_Finish_No_Garage  \n                                           -5.710e-03  \n                                    Garage_Finish_RFn  \n                                           -2.171e-03  \n                                     Garage_Qual_Fair  \n                                           -2.731e-02  \n                                  Garage_Qual_Typical  \n                                           -1.877e-02  \n                                     Garage_Cond_Fair  \n                                           -2.552e-02  \n                                  Garage_Cond_Typical  \n                                           -1.678e-03  \n                              Paved_Drive_Dirt_Gravel  \n                                           -4.599e-03  \n                         Paved_Drive_Partial_Pavement  \n                                           -7.736e-03  \n                                   Fence_Good_Privacy  \n                                           -4.646e-03  \n                                      Fence_Good_Wood  \n                                           -1.104e-02  \n                                Fence_Minimum_Privacy  \n                                           -1.837e-03  \n                                       Fence_No_Fence  \n                                           -3.494e-03  \n                                        Sale_Type_COD  \n                                           -1.792e-02  \n                                        Sale_Type_New  \n                                            1.829e-02  \n                                        Sale_Type_WD.  \n                                           -1.673e-02  \n                               Sale_Condition_Abnorml  \n                                           -4.424e-02  \n                                Sale_Condition_Family  \n                                           -2.159e-02  \n                                Sale_Condition_Normal  \n                                           -1.563e-03  \n                               Sale_Condition_Partial  \n                                           -2.112e-02  \n\n\nTo obtain the detailed results from our trained linear regression model in a data frame, we can use the tidy() and glance() functions directly on our trained parsnip model, ames_fit. - The tidy() function takes a linear regression object and returns a data frame of the estimated model coefficients and their associated F-statistics and p-values; - The glance() function will return performance metrics obtained on the training data such as the R2 value (r.squared) and the RMSE (sigma). - We can also use the vip() function to plot the variable importance for each predictor in our model. The importance value is determined based on the F-statistics and estimate coefficents in our trained model object.\n\n# Data frame of estimated coefficients\ntidy(ames_fit)\n\n# A tibble: 187 × 5\n   term          estimate std.error statistic   p.value\n   <chr>            <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)    4.22      0.0965     43.8   8.49e-300\n 2 Lot_Frontage   0.00151   0.00121     1.24  2.14e-  1\n 3 Lot_Area       0.00563   0.00129     4.35  1.42e-  5\n 4 Mas_Vnr_Area   0.00318   0.00168     1.89  5.90e-  2\n 5 BsmtFin_SF_1   0.0291    0.0248      1.17  2.41e-  1\n 6 BsmtFin_SF_2  -0.00244   0.00119    -2.05  4.03e-  2\n 7 Bsmt_Unf_SF   -0.00986   0.00209    -4.71  2.61e-  6\n 8 Total_Bsmt_SF  0.0305    0.00326     9.36  2.01e- 20\n 9 First_Flr_SF   0.00466   0.00910     0.512 6.09e-  1\n10 Second_Flr_SF  0.00963   0.0100      0.960 3.37e-  1\n# … with 177 more rows\n\n# Performance metrics on training data\nglance(ames_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.sq…¹  sigma stati…² p.value    df logLik    AIC    BIC devia…³\n      <dbl>      <dbl>  <dbl>   <dbl>   <dbl> <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n1     0.934      0.928 0.0479    164.       0   185  3884. -7395. -6318.    4.94\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\n# Plot variable importance\nvip(ames_fit)\n\n\n\n\nEvaluating the model\n\nTo assess the accuracy of our trained linear regression model, ames_fit, we must use it to make predictions on our test data, ames_test_proc. This is done with the predict() function from parnsip. This function takes two important arguments:\n\na trained parnsip model object;\nnew_data for which to generate predictions.\n\nThe code below uses the predict() function to generate a data frame with a single column, .pred, which contains the predicted Sale Price values on the ames_train data.\n\npredict(ames_fit, new_data = juice(ames_prep))\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 2,339 × 1\n   .pred\n   <dbl>\n 1  5.09\n 2  5.01\n 3  5.13\n 4  5.06\n 5  5.08\n 6  5.07\n 7  4.90\n 8  5.10\n 9  5.06\n10  5.16\n# … with 2,329 more rows\n\n\nGenerally it’s best to combine the test data set and the predictions into a single data frame. We create a data frame with the predictions on the ames_test data and then use bind_cols() to add the ames_test data to the results.\n\names_train_results <- predict(ames_fit, new_data = juice(ames_prep)) %>% \n  bind_cols(juice(ames_prep))\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n# View results\names_train_results\n\n# A tibble: 2,339 × 188\n   .pred Lot_F…¹ Lot_A…² Mas_V…³ BsmtF…⁴ BsmtF…⁵ Bsmt_…⁶ Total…⁷ First…⁸ Secon…⁹\n   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  5.09  0.374  -0.212   -0.569  -1.42    0.162  -1.27  -0.388   -0.726  -0.786\n 2  5.01  0.374   0.0383  -0.569  -1.42   -0.298  -0.288 -0.430   -0.774  -0.786\n 3  5.13 -0.137  -0.733   -0.569  -1.42   -0.298   0.341  0.0550  -0.231  -0.786\n 4  5.06 -1.01   -0.943   -0.569   1.27   -0.298   0.630 -0.497   -0.848  -0.786\n 5  5.08 -0.0770 -0.273   -0.569   1.27   -0.298   0.816 -0.303   -0.631  -0.786\n 6  5.07 -0.227  -0.359   -0.569  -1.42    0.416  -1.27  -0.714   -1.07   -0.786\n 7  4.90  0.374  -0.0453  -0.569   1.27   -0.298   0.584 -0.544   -0.382  -0.786\n 8  5.10  0.314  -0.149   -0.569   0.372  -0.298  -1.27  -2.48     0.427   0.579\n 9  5.06 -1.73   -0.0430  -0.391  -0.970  -0.298  -0.288 -0.388   -0.678  -0.786\n10  5.16 -1.73   -0.392   -0.569  -1.42   -0.298  -0.404 -0.0137  -0.308  -0.786\n# … with 2,329 more rows, 178 more variables: Gr_Liv_Area <dbl>,\n#   Bsmt_Full_Bath <dbl>, Bsmt_Half_Bath <dbl>, Full_Bath <dbl>,\n#   Half_Bath <dbl>, Bedroom_AbvGr <dbl>, TotRms_AbvGrd <dbl>,\n#   Fireplaces <dbl>, Garage_Cars <dbl>, Garage_Area <dbl>, Wood_Deck_SF <dbl>,\n#   Open_Porch_SF <dbl>, Mo_Sold <dbl>, Year_Sold <dbl>, Longitude <dbl>,\n#   Latitude <dbl>, Time_Since_Remodel <dbl>, House_Age <dbl>,\n#   Sale_Price <dbl>, MS_SubClass_One_Story_1946_and_Newer_All_Styles <dbl>, …\n\n\nNow we have the model results and the training data in a single data frame.\nMetrics for model performance\n\n\n\n\nR-squared (rsq): squared correlation between the predicted and observed values;\n\nRoot Mean Square Error (RMSE): difference between the predicted and observed values (loss of function);\n\n\nTo obtain the rmse and rsq values on our test set results, we can use the rmse() and rsq() functions. Both functions take the following arguments:\n\na data frame with columns that have the true values and predictions;\nthe column with the true response values;\nthe column with predicted values.\n\nIn the examples below we pass our ames_test_results to these functions to obtain these values for our test set. Results are always returned as a data frame with the following columns: .metric, .estimator, and .estimate.\n\n#RMSE on train set\ntrain_rmse <- rmse(ames_train_results, \n     truth = Sale_Price,\n     estimate = .pred)\n\n#rsq on train set\ntrain_rsq<- rsq(ames_train_results,\n    truth = Sale_Price,\n    estimate = .pred)\n\n\n\n\n\n\n\nChallenge X\n\n\n\nWe mentioned earlier that the bake() function takes a prepped recipe (ames_prep) and applies it to new_data. The new_data could be the training data again or it could be the testing data. We just evaluated our model on the training data, let’s try to apply the bake() and predict() functions on the test data and compare the results.\nInstructions\n\n#bake() test data\n\n#predict() selling price on the test data\n\n#combine the test data set and the predictions into a single data frame\n\n#RMSE on test set\n\n#rsq on test set\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#bake() test data\names_test_proc <- bake(ames_prep, new_data = ames_test)\n#predict() selling price on the test data\names_test_results <-predict(ames_fit, new_data = ames_test_proc)\n#combine the training data set and the predictions into a single data frame\names_test_results <- ames_test_results %>%\n  bind_cols(ames_test_proc)\n#RMSE on training set\ntest_rmse <- rmse(ames_test_results, \n     truth = Sale_Price,\n     estimate = .pred)\n#rsq on training set\ntest_rsq <- rsq(ames_test_results,\n    truth = Sale_Price,\n    estimate = .pred)\n\n\n\n\nLet’s have a look at all the metrics for both our training and test datasets:\n\n#plot metrics for training and test datasets\ntrain_rsq %>%\n  mutate(dataset = \"training\") %>%\n  bind_rows(train_rmse %>%\n              mutate(dataset = \"training\")) %>%\n  bind_rows(test_rsq %>%\n              mutate(dataset = \"test\") %>%\n              bind_rows(test_rmse %>%\n                          mutate(dataset = \"test\")))\n\n# A tibble: 4 × 4\n  .metric .estimator .estimate dataset \n  <chr>   <chr>          <dbl> <chr>   \n1 rsq     standard      0.934  training\n2 rmse    standard      0.0460 training\n3 rsq     standard      0.858  test    \n4 rmse    standard      0.0656 test    \n\n\nLet’s visualise the situation with an R2 plot:\n\names_test_results %>%\n  mutate(train = \"testing\") %>%\n  bind_rows(ames_train_results %>%\n              mutate(train = \"training\")) %>%\n  ggplot(aes(Sale_Price, .pred, color = train)) +\n  geom_abline(intercept = 0, slope = 1, color = \"black\", linewidth = 0.5, linetype=\"dotted\") +\n  geom_point(alpha = 0.15) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Actual Selling Price\",\n    y = \"Predicted Selling Price\",\n    color = \"Test/Training data\"\n  )\n\n\n\n\nThis is a plot that can be used for any regression model. It plots the actual values (Sale Prices) versus the model predictions (.pred) as a scatter plot. It also plot the line y = x through the origin. This line is a visually representation of the perfect model where all predicted values are equal to the true values in the test set. The farther the points are from this line, the worse the model fit. The reason this plot is called an R2 plot, is because the R2 is the squared correlation between the true and predicted values, which are plotted as paired in the plot.\nResampling\n\nYou just trained models one time on the whole training set and then evaluated them on the testing set. Statisticians have come up with a slew of approaches to evaluate models in better ways than this; many important ones fall under the category of resampling.\nWe can resample the training set to produce an estimate of how the model will perform.The idea of resampling is to create simulated data sets that can be used to estimate the performance of your model, say, because you want to compare models. You can create these resampled data sets instead of using either your training set (which can give overly optimistic results, especially for powerful ML algorithms) or your testing set (which is extremely valuable and can only be used once or at most twice). One of these resampling methods is cross-validation.\nCross-validation means taking your training set and randomly dividing it up evenly into subsets, sometimes called “folds”. A fold here means a group or subset or partition.\nYou use one of the folds for validation and the rest for training, then you repeat these steps with all the subsets and combine the results, usually by taking the mean. Cross-validation allows you to get a more accurate estimate of how your model will perform on new data.\n\n\n\n\n\n\nChallenge X\n\n\n\nWhen you implement 10-fold cross-validation repeated 5 times, you:\n\nrandomly divide your training data into 50 subsets and train on 49 at a time (assessing on the other subset), iterating through all 50 subsets for assessment.\nrandomly divide your training data into 10 subsets and train on 9 at a time (assessing on the other subset), iterating through all 10 subsets for assessment. Then you repeat that process 5 times.\nrandomly divide your training data into 5 subsets and train on 4 at a time (assessing on the other subset), iterating through all 5 subsets. Then you repeat that process 10 times.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSimulations and practical experience show that 10-fold cross-validation repeated 5 times is a great resampling approach for many situations. This approach involves randomly dividing your training data into 10 folds, or subsets or groups, and training on only 9 while using the other fold for assessment. You iterate through all 10 folds being used for assessment; this is one round of cross-validation. You can then repeat the whole process multiple, perhaps 5, times.\n\n\n\n\nset.seed(9)\n\names_folds <- vfold_cv(ames_train, v=10, repeats = 5, strata = Sale_Price)\n\nglimpse(ames_folds)\n\nRows: 50\nColumns: 3\n$ splits <list> [<vfold_split[2103 x 236 x 2339 x 81]>], [<vfold_split[2103 x …\n$ id     <chr> \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1…\n$ id2    <chr> \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06\", \"Fo…\n\n\nIn the next steps, we won’t not use prep() or bake(). The ames_rec recipe will be automatically applied in a later step using the workflow() and last_fit() functions.\nCreate a Workflow\n\nIn the previous section, we trained a linear regression model to the housing data step-by-step. In this section, we will go over how to combine all of the modeling steps into a single workflow.\nThe workflow package was designed to capture the entire modeling process and combine models and recipes into a single object. To create a workflow, we start with workflow() to create an empty workflow and then add out model and recipe with add_model() and add_recipe().\n\names_wf <- workflow() %>%\n  add_model(ames_model) %>% \n  add_recipe(ames_rec)\n\names_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n• step_other()\n• step_nzv()\n• step_center()\n• step_scale()\n• step_dummy()\n• step_lincomb()\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\nComputational engine: lm \n\n\nOnce we have created a set of resamples, we can use the function fit_resamples() to fit a model to each resample and compute performance metrics for each.\n\nset.seed(234)\names_res <- ames_wf %>%\n  fit_resamples(\n    ames_folds,\n    control = control_resamples(save_pred = TRUE)\n  )\n\n! Fold01, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold01, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold02, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold03, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold04, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold05, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold06, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold07, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold08, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold09, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n\n! Fold10, Repeat5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\nglimpse(ames_res)\n\nRows: 50\nColumns: 6\n$ splits       <list> [<vfold_split[2103 x 236 x 2339 x 81]>], [<vfold_split[2…\n$ id           <chr> \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"Repeat1\", \"R…\n$ id2          <chr> \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06…\n$ .metrics     <list> [<tbl_df[2 x 4]>], [<tbl_df[2 x 4]>], [<tbl_df[2 x 4]>],…\n$ .notes       <list> [<tbl_df[1 x 3]>], [<tbl_df[1 x 3]>], [<tbl_df[1 x 3]>],…\n$ .predictions <list> [<tbl_df[236 x 4]>], [<tbl_df[236 x 4]>], [<tbl_df[236 x…\n\nsaveRDS(ames_res, \"../_models/ames_res.rds\")\n\nThe column .metric contains the performance statistics created from the 10 assessment sets. These can be manually unnested but the tune package contains a number of simple functions that can extract these data:\n\n# Obtain performance metrics on resampled training data\names_res %>% collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.0540    50 0.00129 Preprocessor1_Model1\n2 rsq     standard   0.909     50 0.00368 Preprocessor1_Model1\n\n\n\n\nvfold_cv() creates folds for cross-validation;\n\nfit_resamples() fits models to resamples;\n\ncollect_metrics() obtains performance metrics from the results.\n\nWe can see that the regression relationship is very strong: 90.8% of the variability in the selling price can be explained by the predictors and, on average, each element in the predicted selling price differs from the actual selling price by 0.05.\nWe can reliably measure performance using only the training data.\nIf we wanted to try different model types for this data set, we could more confidently compare performance metrics computed using resampling to choose between models. Also, remember that at the end of our project, we return to our test set to estimate final model performance.\n\names_res %>%\n  collect_predictions() %>%\n  ggplot(aes(Sale_Price, .pred, color = id)) + \n  geom_abline(lty = 2, col = \"gray\", linewidth = 1.5) +\n  geom_point(alpha = 0.15) +\n  coord_obs_pred()\n\n\n\n\nBack to the testing data\n\nLet’s use the last_fit() function to evaluate once on the testing set:\n\n#Final fit on test dataset\names_final <- ames_wf %>%\n  last_fit(ames_split)\n\n! train/test split: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-deficient fit may be misleading\n\n# Obtain performance metrics on test data\ncollect_metrics(ames_final)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard      0.0656 Preprocessor1_Model1\n2 rsq     standard      0.858  Preprocessor1_Model1\n\n\nThe R2 and RMSE metrics are similar for both the training and testing datasets in our linear regression model. This is a good sign that the model is not over-fitting and can be used for making predictions on new data.\nWe can save the test set predictions by using the collect_predictions() function. This function returns a data frame which will have the response variables values from the test set and a column named .pred with the model predictions.\n\n# Obtain test set predictions data frame\names_results_final <- ames_final %>% \n                 collect_predictions()\n# View results\names_results_final\n\n# A tibble: 586 × 5\n   id               .pred  .row Sale_Price .config             \n   <chr>            <dbl> <int>      <dbl> <chr>               \n 1 train/test split  5.03     2       5.02 Preprocessor1_Model1\n 2 train/test split  5.19     3       5.24 Preprocessor1_Model1\n 3 train/test split  5.39    18       5.60 Preprocessor1_Model1\n 4 train/test split  5.13    26       5.15 Preprocessor1_Model1\n 5 train/test split  5.23    29       5.26 Preprocessor1_Model1\n 6 train/test split  4.99    30       4.98 Preprocessor1_Model1\n 7 train/test split  4.99    31       5.02 Preprocessor1_Model1\n 8 train/test split  4.98    32       4.94 Preprocessor1_Model1\n 9 train/test split  5.14    34       5.18 Preprocessor1_Model1\n10 train/test split  5.77    47       5.70 Preprocessor1_Model1\n# … with 576 more rows\n\n\nFinally, let’s use this data frame to make an R2 plot to visualize our model performance on the test data set:\n\nggplot(data = ames_results_final,\n       mapping = aes(x = .pred, y = Sale_Price)) +\n  geom_point(color = '#006EA1', alpha = 0.25) +\n  geom_abline(intercept = 0, slope = 1, color = 'black', linewidth=0.5, linetype=\"dotted\") +\n  labs(title = 'Linear Regression Results - Ames Test Set',\n       x = 'Predicted Selling Price',\n       y = 'Actual Selling Price')"
  },
  {
    "objectID": "Tidymodels_tips&tricks.R.html",
    "href": "Tidymodels_tips&tricks.R.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "https://usemodels.tidymodels.org devtools::install_github(“tidymodels/usemodels”)\nThe usemodels package is a helpful way of quickly creating code snippets to fit models using the tidymodels framework. Given a simple formula and a data set, the use_* functions can create code that appropriate for the data (given the model). The package includes these templates:\n\nlibrary(usemodels)\nls(\"package:usemodels\", pattern = \"use_\")\n\n [1] \"use_bag_tree_rpart\"   \"use_C5.0\"             \"use_cubist\"          \n [4] \"use_dbarts\"           \"use_earth\"            \"use_glmnet\"          \n [7] \"use_kernlab_svm_poly\" \"use_kernlab_svm_rbf\"  \"use_kknn\"            \n[10] \"use_mgcv\"             \"use_mixOmics\"         \"use_nnet\"            \n[13] \"use_ranger\"           \"use_rpart\"            \"use_xgboost\"         \n[16] \"use_xrf\""
  },
  {
    "objectID": "Tidymodels_tips&tricks.html",
    "href": "Tidymodels_tips&tricks.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "https://usemodels.tidymodels.org devtools::install_github(“tidymodels/usemodels”)\nThe usemodels package is a helpful way of quickly creating code snippets to fit models using the tidymodels framework. Given a simple formula and a data set, the use_* functions can create code that appropriate for the data (given the model). The package includes these templates:\n\nlibrary(usemodels)\nls(\"package:usemodels\", pattern = \"use_\")\n\n [1] \"use_bag_tree_rpart\"   \"use_C5.0\"             \"use_cubist\"          \n [4] \"use_dbarts\"           \"use_earth\"            \"use_glmnet\"          \n [7] \"use_kernlab_svm_poly\" \"use_kernlab_svm_rbf\"  \"use_kknn\"            \n[10] \"use_mgcv\"             \"use_mixOmics\"         \"use_nnet\"            \n[13] \"use_ranger\"           \"use_rpart\"            \"use_xgboost\"         \n[16] \"use_xrf\""
  },
  {
    "objectID": "Tidymodels_tips&tricks.qmd.html",
    "href": "Tidymodels_tips&tricks.qmd.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "https://usemodels.tidymodels.org devtools::install_github(“tidymodels/usemodels”)\nThe usemodels package is a helpful way of quickly creating code snippets to fit models using the tidymodels framework. Given a simple formula and a data set, the use_* functions can create code that appropriate for the data (given the model). The package includes these templates:\n\nlibrary(usemodels)\nls(\"package:usemodels\", pattern = \"use_\")\n\n [1] \"use_bag_tree_rpart\"   \"use_C5.0\"             \"use_cubist\"          \n [4] \"use_dbarts\"           \"use_earth\"            \"use_glmnet\"          \n [7] \"use_kernlab_svm_poly\" \"use_kernlab_svm_rbf\"  \"use_kknn\"            \n[10] \"use_mgcv\"             \"use_mixOmics\"         \"use_nnet\"            \n[13] \"use_ranger\"           \"use_rpart\"            \"use_xgboost\"         \n[16] \"use_xrf\""
  },
  {
    "objectID": "Tidymodels_tips_tricks.html",
    "href": "Tidymodels_tips_tricks.html",
    "title": "Sydney Informatics Hub",
    "section": "",
    "text": "The usemodels package is a helpful way of quickly creating code snippets to fit models using the tidymodels framework. Given a simple formula and a data set, the use_* functions can create code that appropriate for the data (given the model). The package includes these templates:\n\nlibrary(usemodels)\nls(\"package:usemodels\", pattern = \"use_\")\n\n [1] \"use_bag_tree_rpart\"   \"use_C5.0\"             \"use_cubist\"          \n [4] \"use_dbarts\"           \"use_earth\"            \"use_glmnet\"          \n [7] \"use_kernlab_svm_poly\" \"use_kernlab_svm_rbf\"  \"use_kknn\"            \n[10] \"use_mgcv\"             \"use_mixOmics\"         \"use_nnet\"            \n[13] \"use_ranger\"           \"use_rpart\"            \"use_xgboost\"         \n[16] \"use_xrf\""
  },
  {
    "objectID": "Slides.html#who-are-you",
    "href": "Slides.html#who-are-you",
    "title": "1 - Introduction",
    "section": "Who are you?",
    "text": "Who are you?\n\nYou can use the magrittr %>% or base R |> pipe\nYou are familiar with functions from dplyr, tidyr, ggplot2\nYou have exposure to basic statistical concepts\nYou do not need intermediate or expert familiarity with modeling or ML"
  },
  {
    "objectID": "Slides.html#who-am-i",
    "href": "Slides.html#who-am-i",
    "title": "1 - Introduction",
    "section": "Who am I?",
    "text": "Who am I?\n\n\n\n\n @juliasilge\n @juliasilge\n youtube.com/juliasilge\n juliasilge.com\n\n\n\nMany thanks to RStudio tidymodels team, Alison Hill, and Allison Horst for their role in creating these materials!"
  },
  {
    "objectID": "Slides.html#plan-for-this-workshop",
    "href": "Slides.html#plan-for-this-workshop",
    "title": "1 - Introduction",
    "section": "Plan for this workshop",
    "text": "Plan for this workshop\n\nYour data budget\nWhat makes a model\nEvaluating models\nFeature engineering\nTuning hyperparameters\nWrapping up!"
  },
  {
    "objectID": "Slides.html#what-is-machine-learning",
    "href": "Slides.html#what-is-machine-learning",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nhttps://xkcd.com/1838/"
  },
  {
    "objectID": "Slides.html#what-is-machine-learning-1",
    "href": "Slides.html#what-is-machine-learning-1",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nIllustration credit: https://vas3k.com/blog/machine_learning/"
  },
  {
    "objectID": "Slides.html#what-is-machine-learning-2",
    "href": "Slides.html#what-is-machine-learning-2",
    "title": "1 - Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?\n\n\nIllustration credit: https://vas3k.com/blog/machine_learning/"
  },
  {
    "objectID": "Slides.html#your-turn",
    "href": "Slides.html#your-turn",
    "title": "1 - Introduction",
    "section": "Your turn",
    "text": "Your turn\n\n\nHow are statistics and machine learning related?\nHow are they similar? Different?\n\n\n\n−+\n03:00\n\n\n\n\nthe “two cultures”\nmodel first vs. data first\ninference vs. prediction"
  },
  {
    "objectID": "Slides.html#what-is-tidymodels",
    "href": "Slides.html#what-is-tidymodels",
    "title": "1 - Introduction",
    "section": "What is tidymodels?",
    "text": "What is tidymodels?\n\nlibrary(tidymodels)\n#> ── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n#> ✔ broom        1.0.3     ✔ recipes      1.0.5\n#> ✔ dials        1.1.0     ✔ rsample      1.1.1\n#> ✔ dplyr        1.1.0     ✔ tibble       3.1.8\n#> ✔ ggplot2      3.4.1     ✔ tidyr        1.3.0\n#> ✔ infer        1.0.4     ✔ tune         1.0.1\n#> ✔ modeldata    1.1.0     ✔ workflows    1.1.3\n#> ✔ parsnip      1.0.4     ✔ workflowsets 1.0.0\n#> ✔ purrr        1.0.1     ✔ yardstick    1.1.0\n#> ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n#> ✖ purrr::discard() masks scales::discard()\n#> ✖ dplyr::filter()  masks stats::filter()\n#> ✖ dplyr::lag()     masks stats::lag()\n#> ✖ recipes::step()  masks stats::step()\n#> • Search for functions across packages at https://www.tidymodels.org/find/"
  },
  {
    "objectID": "Slides.html#lets-install-some-packages",
    "href": "Slides.html#lets-install-some-packages",
    "title": "1 - Introduction",
    "section": "Let’s install some packages",
    "text": "Let’s install some packages\n\ninstall.packages(c(\"doParallel\", \"ranger\", \"rpart\", \n                   \"rpart.plot\", \"tidymodels\", \"tidyverse\",\n                   \"vetiver\", \"xgboost\"))"
  },
  {
    "objectID": "slides/Intro.html#code-of-conduct",
    "href": "slides/Intro.html#code-of-conduct",
    "title": "1 - Introduction",
    "section": "Code of conduct",
    "text": "Code of conduct\nWe expect all attendees of our training to follow the University of Sydney’s Staff and Student Codes of Conduct, including the Bullying, harassment and discrimination prevention policy.\nIn order to foster a positive and professional learning environment we encourage the following kinds of behaviours at all our events and platforms:\n\nUse welcoming and inclusive language;\nBe respectful of different viewpoints and experiences;\nGracefully accept constructive criticism;\nFocus on what is best for the community;\nShow courtesy and respect towards other community members.\n\nOur full CoC, with incident reporting guidelines, is available here.\n\n\nhttps://pages.github.sydney.edu.au/informatics/lessons_mlr_tidymodels/"
  },
  {
    "objectID": "slides/Intro.html#examples-of-unacceptable-behaviour",
    "href": "slides/Intro.html#examples-of-unacceptable-behaviour",
    "title": "Introduction",
    "section": "(Examples of) Unacceptable behaviour",
    "text": "(Examples of) Unacceptable behaviour\n\nSustained disruption of talks, events or communications\nWritten/verbal comments which have the effect of excluding people on the basis of membership of any specific group\nCausing someone to fear for their safety, such as through stalking, following, or intimidation\nViolent threats or language directed against another person\nThe display of sexual or violent images\nUnwelcome sexual attention; non-consensual or unwelcome physical contact\nInsults or put downs; excessive swearing\nSexist, racist, homophobic, transphobic, ableist, or exclusionary jokes\nIncitement to violence, suicide, or self-harm\nContinuing to initiate interaction (including photography or recording) with someone after being asked to stop\nPublication of private communication without consent\n\n\n\n\n\nWi-Fi network name\nUniSydney\n\n\n\n\nWi-Fi password\nyour UniKey password"
  },
  {
    "objectID": "slides/Intro.html#who-are-you",
    "href": "slides/Intro.html#who-are-you",
    "title": "Introduction",
    "section": "Who are you?",
    "text": "Who are you?\n\nYou can use the magrittr %>% or base R |> pipe\nYou are familiar with functions from dplyr, tidyr, ggplot2\nYou do not need intermediate or expert familiarity with modeling or ML"
  },
  {
    "objectID": "slides/Intro.html#who-are-we",
    "href": "slides/Intro.html#who-are-we",
    "title": "Introduction",
    "section": "Who are we?",
    "text": "Who are we?\n\n\n\n\n @juliasilge\n @juliasilge\n youtube.com/juliasilge\n juliasilge.com\n\n\n\nMany thanks to RStudio tidymodels team, Alison Hill, and Allison Horst for their role in creating these materials!"
  },
  {
    "objectID": "slides/Intro.html#plan-for-this-workshop",
    "href": "slides/Intro.html#plan-for-this-workshop",
    "title": "Introduction",
    "section": "Plan for this workshop",
    "text": "Plan for this workshop\n\nYour data budget\nWhat makes a model\nEvaluating models\nFeature engineering\nTuning hyperparameters\nWrapping up!"
  },
  {
    "objectID": "slides/Intro.html#what-is-machine-learning",
    "href": "slides/Intro.html#what-is-machine-learning",
    "title": "Introduction",
    "section": "What is machine learning?",
    "text": "What is machine learning?"
  },
  {
    "objectID": "slides/Intro.html#section-2",
    "href": "slides/Intro.html#section-2",
    "title": "Introduction",
    "section": "",
    "text": "https://pages.github.sydney.edu.au/informatics/lessons_mlr_tidymodels/"
  },
  {
    "objectID": "100_regression/step1.html#the-ames-housing-dataset",
    "href": "100_regression/step1.html#the-ames-housing-dataset",
    "title": "Sydney Informatics Hub",
    "section": "The Ames housing dataset",
    "text": "The Ames housing dataset\n\n\n\n\n\n\nLearning objective:\n\n\n\n\nUse Tidyverse functions for exploratory data analysis (EDA);\nExplore the Ames Housing dataset.\n\n\n\n\n\nFirst, let’s load the required packages. We will use the tidyverse for general data processing and visualisation.\n\nlibrary(tidyverse)\nlibrary(naniar) # for visualising missing data\nlibrary(GGally) # for EDA\nlibrary(ggcorrplot)\nlibrary(AmesHousing)\nlibrary(plotly) # dynamic visualisations\nlibrary(bestNormalize)\nlibrary(qs)\ntheme_set(theme_minimal())\n\nWe will use the Ames housing data to explore different ML approaches to regression. This dataset was “designed” by Dean De Cock as an alternative to the “classic” Boston housing dataset, and has been extensively used in ML teaching. It is also available from kaggle as part of its advanced regression practice competition.\nThe Ames Housing Data Documentation file describes the independent variables presented in the data. This includes:\n\n20 continuous variables relate to various area dimensions for each observation;\n14 discrete variables, which typically quantify the number of items occurring within the house;\n23 ordinal, 23 nominal categorical variables, with 2 (STREET: gravel or paved) - 28 (NEIGHBORHOOD) classes;\n\nWe will explore both the “uncleaned” data available from kaggle/UCI, and the processed data available in the AmesHousing package in R, for which documentation is available here. It can be useful for understanding what each of the independent variables mean.\n\nameshousing <- AmesHousing::make_ames()\n\n# Read in the uncleaned data. \nameshousing_uncleaned <- AmesHousing::ames_raw"
  }
]